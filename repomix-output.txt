This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-15T08:33:56.077Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
.devcontainer/
  devcontainer.json
.github/
  workflows/
    ci.yml
    codeql.yml
    release.yml
  FUNDING.yml
  renovate.json5
bin/
  repofm.cjs
  repofm.js
docs/
  auto-commit-documentation.md
  code-context-management-documentation.md
  comprehensive-test-plan-for-repofm.md
  feature-auto-commit-documentation.md
  gitignore-support-documentation.md
  release-notes-v0.2.0.md
  repofm-enhanced-auto-commit-documentation.md
  repofm-New-Features-Implementation-Plan.md
src/
  cli/
    actions/
      defaultAction.ts
      initAction.ts
      migrationAction.ts
      remoteAction.ts
      versionAction.ts
    commands/
      context.js
    cliPrint.ts
    cliRun.ts
    cliSpinner.ts
  config/
    configLoad.ts
    configSchema.ts
    defaultIgnore.ts
    globalDirectory.ts
    loadConfig.ts
  core/
    file/
      fileCollect.ts
      fileManipulate.ts
      filePathSort.ts
      fileProcess.ts
      fileSearch.ts
      fileTreeGenerate.ts
      fileTypes.ts
      packageJsonParse.ts
      permissionCheck.ts
    output/
      outputStyles/
        markdownStyle.ts
        plainStyle.ts
        xmlStyle.ts
      outputGenerate.ts
      outputGeneratorTypes.ts
      outputStyleDecorate.ts
    security/
      securityCheck.ts
    tokenCount/
      tokenCount.ts
      TokenCounter.ts
    packager.ts
  features/
    autoCommit/
      contentAnalyzer.js
      enhancedTemplates.js
      fileTypes.js
      index.js
      interactivePrompts.js
      interactiveUI.js
      templates.js
      visualInterface.js
    contextManager/
      index.js
    contextManager.js
    gitHistory.js
    repoMigration.js
  shared/
    errorHandle.ts
    logger.ts
    processConcurrency.ts
    types.ts
  types/
    config.ts
  utils/
    gitignore.js
    logger.ts
    stringUtils.ts
  cli.js
  index.ts
supabase/
  db/
    git_his.sql
  .env.example
  .gitignore
  config.toml
  supabase_install.md
tests/
  cli/
    actions/
      defaultAction.test.ts
      initAction.test.ts
      migrationAction.test.ts
      remoteAction.test.ts
      versionAction.test.ts
    cliRun.test.ts
  config/
    configLoad.test.ts
    configSchema.test.ts
    globalDirectory.ts
  core/
    file/
      fileCollect.test.ts
      fileManipulate.test.ts
      filePathSort.test.ts
      fileProcess.test.ts
      fileSearch.edge.test.ts
      fileSearch.test.ts
      fileTreeGenerate.test.ts
      packageJsonParse.test.ts
      permissionCheck.test.ts
    output/
      outputStyles/
        markdownStyle.test.ts
        plainStyle.test.ts
        xmlStyle.test.ts
      outputGenerate.test.ts
    tokenCount/
      tokenCount.test.ts
    packager.test.ts
  integration-tests/
    fixtures/
      packager/
        inputs/
          simple-project/
            build/
              test.js
            resources/
              .repofmignore
              data.txt
              ignored-data.txt
            src/
              build/
                test.js
              index.js
              utils.js
            .repofmignore
            package.json
            README.md
            repofm.config.json
        outputs/
          simple-project-output.txt
          simple-project-output.xml
    packager.test.ts
  shared/
    errorHandle.test.ts
    logger.test.ts
  testing/
    testUtils.ts
.codecov.yml
.editorconfig
.env.example
.gitignore
.node-version
.npmignore
.repofmignore
.secretlintrc.json
.tool-versions
biome.json
CODE_OF_CONDUCT.md
CONTRIBUTING.md
LICENSE
package.json
README.md
repofm.config.json
SECURITY.md
tsconfig.build.json
tsconfig.json
vitest.config.ts

================================================================
Repository Files
================================================================

================
File: .devcontainer/devcontainer.json
================
{
	"name": "repofm",
	"image": "mcr.microsoft.com/devcontainers/typescript-node:1-22-bullseye",
	"runArgs": ["--name", "repofm-devcontainer"],
	"postCreateCommand": "npm install"
}

================
File: .github/workflows/ci.yml
================
name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
    steps:
      - uses: actions/checkout@v4
      # ... add your build steps here

  lint-biome:
    name: Lint Biome
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version-file: .tool-versions
    - run: npm ci
    - run: npm run lint-biome && git diff --exit-code

  lint-ts:
    name: Lint TypeScript
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version-file: .tool-versions
    - run: npm ci
    - run: npm run lint-ts

  lint-secretlint:
    name: Lint Secretlint
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version-file: .tool-versions
    - run: npm ci
    - run: npm run lint-secretlint

  lint-renovate-config:
    name: Lint Renovate config
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version-file: .tool-versions
    - name: Validate Renovate config
      run: npx --yes --package renovate -- renovate-config-validator --strict

  lint-action:
    name: Lint GitHub Actions
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: docker://rhysd/actionlint:latest
        with:
          args: "-color"

  check-npm-audit:
    name: Check npm audit
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version-file: .tool-versions
      - run: npm audit

  check-typos:
    name: Check typos
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: crate-ci/typos@master

  test:
    name: Test
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        node-version: [16.x, 18.x, 20.x, 22.x, 23.x]
    runs-on: ${{ matrix.os }}
    steps:
    - uses: actions/checkout@v4
    - name: Use Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
    - run: npm ci
    - run: npm run test --reporter=verbose
      env:
        CI_OS: ${{ runner.os }}

  test-coverage:
    name: Test coverage
    needs: test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version-file: .tool-versions
        cache: npm
    - run: npm ci
    - run: npm run test-coverage -- --reporter=verbose
      env:
        CI_OS: ${{ runner.os }}
    - uses: actions/upload-artifact@v4
      with:
        name: test-coverage
        path: coverage/
    - uses: codecov/codecov-action@v4
      with:
        fail_ci_if_error: true
        directory: ./coverage
      env:
        CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  build-and-run:
    name: Build and run
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        node-version: [16.x, 18.x, 20.x, 22.x, 23.x]
    runs-on: ${{ matrix.os }}
    steps:
    - uses: actions/checkout@v4
    - name: Use Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
    - run: npm ci
    - run: npm run build
    - run: node bin/repofm
    - name: Upload build artifact
      uses: actions/upload-artifact@v4
      with:
        name: repofm-output-${{ matrix.os }}-${{ matrix.node-version }}.txt
        path: repofm-output.txt

================
File: .github/workflows/codeql.yml
================
name: "CodeQL"

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '25 11 * * 0'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    permissions:
      security-events: write
      packages: read
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        - language: javascript-typescript
          build-mode: none
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}

    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"

================
File: .github/workflows/release.yml
================
name: release

on:
  release:
    types:
      - created

jobs:
  homebrew:
    runs-on: macos-latest
    steps:
      - name: Set up Homebrew
        uses: Homebrew/actions/setup-homebrew@master
        with:
          test-bot: false

      - name: Configure Git user
        uses: Homebrew/actions/git-user-config@master

      - name: Bump packages
        uses: Homebrew/actions/bump-packages@master
        with:
          token: ${{ secrets.COMMITTER_TOKEN }}
          formulae: repofm

================
File: .github/FUNDING.yml
================
github: chenxingqiang

================
File: .github/renovate.json5
================
{
  "$schema": "https://docs.renovatebot.com/renovate-schema.json",
  "extends": [
    "config:recommended",
    "schedule:weekly",
    'group:allNonMajor'
  ],
  "rangeStrategy": "bump",
  "dependencyDashboard": false,
  "labels": ["dependencies", "renovate"],
  "packageRules": [
    {
      matchDepTypes: ['peerDependencies'],
      enabled: false,
    },
  ],
  "ignoreDeps": [
    "node",
  ]
}

================
File: bin/repofm.cjs
================
#!/usr/bin/env node
'use strict';

(async () => {
  const { run } = await import('../lib/cli/cliRun.js');
  run();
})();

================
File: bin/repofm.js
================
#!/usr/bin/env node

/*
Add this file so we can use `node bin/repofm` or `node bin/repofm.js`
instead of `node bin/repofm.cjs`.

This file should only used for development.
*/

'use strict';

import { run } from '../lib/cli/cliRun.js';

run();

================
File: docs/auto-commit-documentation.md
================
# Enhanced Auto-Commit Configuration

## Configuration Schema

Add to your `repofm.config.json`:

```json
{
  "autoCommit": {
    "ui": {
      "showTimeline": true,
      "showDiff": true,
      "colorOutput": true,
      "icons": true,
      "useEmoji": true
    },
    "commit": {
      "separateByDefault": true,
      "pushByDefault": true,
      "requireConfirmation": true,
      "breakingChangePrompt": true,
      "conventionalCommits": true
    },
    "analysis": {
      "checkBreakingChanges": true,
      "suggestScope": true,
      "detectFileTypes": true,
      "scanForKeywords": true,
      "maxDiffLines": 500
    },
    "templates": {
      "feature": {
        "add": "feat({}): add {} functionality",
        "update": "feat({}): update {} implementation",
        // ... other templates
      },
      // ... other template categories
    },
    "fileTypes": {
      "react": {
        "pattern": "\\.jsx?$",
        "folders": ["components", "pages"],
        "keywords": ["React", "useState"]
      },
      // ... other file types
    },
    "customPatterns": {
      "jira": "([A-Z]+-\\d+)",
      "version": "(v\\d+\\.\\d+\\.\\d+)"
    }
  }
}
```

## Usage Examples

### 1. Basic Auto-Commit with Timeline

```bash
repofm auto-commit --timeline

# Output:
# 📦 Changes Summary
# ─────────────────────
# ✨ Added    src/components/Button.jsx
# 📝 Modified src/styles/main.css
# ...
```

### 2. Interactive Commit with File Selection

```bash
repofm auto-commit --interactive

# Shows:
# 🔍 Select Files to Commit
# □ src/components/Button.jsx
# □ src/styles/main.css
# ...
```

### 3. Smart Commit Message Generation

```bash
repofm auto-commit --smart-messages

# Analyzes files and suggests:
# feat(ui): implement responsive Button component
# style: update main stylesheet with new theme colors
```

## Feature Details

### Enhanced File Type Detection

The system now recognizes:

- Framework-specific files (React, Vue, Angular)
- Build configurations (webpack, vite, etc.)
- Test files (unit, e2e, integration)
- Documentation (markdown, JSDoc, TypeDoc)
- Style files (CSS, SCSS, Less)
- Configuration files (JSON, YAML)
- API definitions (OpenAPI, GraphQL)

### Interactive Features

1. **Visual File Selection**
   - Checkbox-based file selection
   - File grouping by type
   - Change preview
   - Diff visualization

2. **Smart Message Generation**
   - Template-based suggestions
   - Scope detection
   - Breaking change detection
   - Conventional commit format

3. **Timeline View**
   - Chronological change display
   - File type indicators
   - Change summary
   - Related files grouping

### Commit Templates

Templates are available for various types:

1. **Features**

```
feat(scope): add new feature
feat(scope): implement functionality
feat(scope): enhance capabilities
```

2. **Bug Fixes**

```
fix(scope): resolve issue
fix(scope): address bug
fix(scope): patch vulnerability
```

3. **Documentation**

```
docs(scope): add documentation
docs(scope): update examples
docs(api): revise API docs
```

4. **Styling**

```
style(scope): update styles
style(ui): enhance layout
style(theme): revise colors
```

### Best Practices

1. **Commit Organization**

```bash
   # Group related changes
   repofm auto-commit --group-by type

   # Separate different types
   repofm auto-commit --separate
   ```

2. **Message Quality**

   ```bash
   # Use conventional commits
   repofm auto-commit --conventional

   # Include scope
   repofm auto-commit --scope ui
   ```

3. **Review Process**

```bash
   # Show diff before commit
   repofm auto-commit --preview

   # Review timeline
   repofm auto-commit --timeline
   ```

================
File: docs/code-context-management-documentation.md
================
# Code Context Management Documentation

The Code Context Management feature allows you to extract, analyze, and maintain contextual information about your code. This document covers usage patterns and examples for different scenarios.

## Configuration

Add the following to your `repofm.config.json`:

```json
{
  "context": {
    "outputFormat": "markdown",
    "maxDepth": 2,
    "includeImports": true,
    "includeExports": true,
    "maxContextLines": 100,
    "excludePatterns": [
      "node_modules",
      ".git"
    ],
    "cacheEnabled": true,
    "cachePath": ".repofm/context-cache"
  }
}
```

## CLI Usage Examples

### 1. Extract Function Context

```bash
# Get context for a specific function
repofm context extract --target "handleSubmit" --type function --file src/components/Form.js

# Get deeper context analysis
repofm context extract --target "handleSubmit" --type function --file src/components/Form.js --depth 2

# Save context to file
repofm context extract --target "handleSubmit" --type function --file src/components/Form.js --save context.md
```

Example output:

```markdown
# Code Context: handleSubmit

## Definition
```javascript
function handleSubmit(event) {
  event.preventDefault();
  // ... function implementation
}
```

## Dependencies

- validateForm (./utils/validation.js)
- submitData (./api/submit.js)

## Callers

- SubmitButton (./components/SubmitButton.js:15)
- FormWrapper (./components/FormWrapper.js:42)

## Related Tests

- Form.test.js
  - "should handle submission correctly"
  - "should validate before submit"

```

### 2. Extract File Context

```bash
# Get context for an entire file
repofm context extract --target src/components/Form.js --type file

# Include specific depth of imports and exports
repofm context extract --target src/components/Form.js --type file --depth 2 --include-imports --include-exports
```

### 3. Extract Character Context

```bash
# Get context for a specific position in code
repofm context extract --target "150:10" --type character --file src/components/Form.js
```

### 4. Search Within Contexts

```bash
# Search for specific patterns
repofm context search --query "handleSubmit" --path src/components

# Search with type filter
repofm context search --query "handleSubmit" --type function --json
```

### 5. Cache Management

```bash
# List cached contexts
repofm context cache --list

# Clear cache
repofm context cache --clear

# Rebuild cache
repofm context cache --rebuild
```

## API Usage

You can also use the Code Context Manager programmatically:

```javascript
import { CodeContextManager } from 'repofm';

const manager = new CodeContextManager({
  outputFormat: 'markdown',
  maxDepth: 2
});

// Get function context
const context = await manager.getContext({
  target: 'handleSubmit',
  type: 'function',
  file: 'src/components/Form.js',
  depth: 2
});

// Search contexts
const results = await manager.searchContext({
  query: 'handleSubmit',
  path: 'src/components'
});
```

## Output Formats

### Markdown Format

- Function definitions with syntax highlighting
- Dependency trees
- Usage examples
- Related test cases
- Import/Export analysis

### XML Format

```xml
<codeContext>
  <target>handleSubmit</target>
  <type>function</type>
  <content>
    <definition><![CDATA[
      function handleSubmit(event) {
        // ... function implementation
      }
    ]]></definition>
    <dependencies>
      <dependency path="./utils/validation.js">validateForm</dependency>
      <dependency path="./api/submit.js">submitData</dependency>
    </dependencies>
  </content>
</codeContext>
```

### Plain Text Format

```
Target: handleSubmit
Type: function
File: src/components/Form.js

Definition:
function handleSubmit(event) {
  // ... function implementation
}

Dependencies:
- validateForm (./utils/validation.js)
- submitData (./api/submit.js)
```

## Best Practices

1. **Cache Management**
   - Regularly rebuild cache for large codebases
   - Clear cache when switching branches
   - Use `--depth` judiciously as higher depths increase analysis time

2. **Search Optimization**
   - Use specific paths to limit search scope
   - Combine with type filters for precise results
   - Use JSON output for programmatic processing

3. **Context Extraction**
   - Start with function-level context for specific analyses
   - Use file-level context for overview and dependencies
   - Use character-level context for precise reference lookups

4. **Output Format Selection**
   - Use Markdown for human-readable documentation
   - Use XML for structured data processing
   - Use JSON for programmatic integration

================
File: docs/comprehensive-test-plan-for-repofm.md
================
# Comprehensive Test Plan for repofm

## 1. Unit Tests

### 1.1 Core Functionality Tests

- **File Processing**
  - `fileCollect.test.ts`
    - [ ] Test file collection with different encodings
    - [ ] Test handling of binary files
    - [ ] Test error handling for unreadable files
    - [ ] Test concurrent file processing
    - [ ] Test handling of large files
    - [ ] Test handling of different line endings (CRLF/LF)
  
  - `fileManipulate.test.ts`
    - [ ] Test comment removal for all supported languages
    - [ ] Test empty line removal
    - [ ] Test line number addition
    - [ ] Test handling of nested comments
    - [ ] Test handling of comment-like strings
    - [ ] Test handling of multi-line comments
    - [ ] Test handling of docstrings

  - `fileProcess.test.ts`
    - [ ] Test processing of multiple files concurrently
    - [ ] Test file content transformation
    - [ ] Test error handling during processing
    - [ ] Test processing with different configurations
    - [ ] Test memory usage with large files

### 1.2 Configuration Tests

- **Config Loading**
  - `configLoad.test.ts`
    - [ ] Test loading local config
    - [ ] Test loading global config
    - [ ] Test config validation
    - [ ] Test config merging
    - [ ] Test environment variable substitution
    - [ ] Test default values
    - [ ] Test invalid config handling

### 1.3 Security Tests

- **Security Checks**
  - `securityCheck.test.ts`
    - [ ] Test detection of API keys
    - [ ] Test detection of passwords
    - [ ] Test detection of private keys
    - [ ] Test detection of tokens
    - [ ] Test handling of false positives
    - [ ] Test custom security patterns
    - [ ] Test security report generation

### 1.4 Output Generation Tests

- **Output Formats**
  - `outputGenerate.test.ts`
    - [ ] Test plain text output
    - [ ] Test XML output
    - [ ] Test markdown output
    - [ ] Test output with custom header
    - [ ] Test output with instructions
    - [ ] Test output file structure
    - [ ] Test output file encoding

### 1.5 File Pattern Tests

- **Pattern Matching**
  - `fileSearch.test.ts`
    - [ ] Test gitignore pattern matching
    - [ ] Test custom ignore patterns
    - [ ] Test include patterns
    - [ ] Test pattern priority
    - [ ] Test nested gitignore files
    - [ ] Test glob pattern matching
    - [ ] Test pattern validation

## 2. Integration Tests

### 2.1 End-to-End Workflows

- **Complete Workflows**
  - `packager.test.ts`
    - [ ] Test complete repository packing
    - [ ] Test remote repository processing
    - [ ] Test with different output formats
    - [ ] Test with security checks enabled/disabled
    - [ ] Test with custom configurations
    - [ ] Test clipboard integration
    - [ ] Test progress reporting

### 2.2 CLI Integration

- **Command Line Interface**
  - `cli.test.ts`
    - [ ] Test all command line options
    - [ ] Test help command
    - [ ] Test version command
    - [ ] Test init command
    - [ ] Test error reporting
    - [ ] Test verbose output
    - [ ] Test interactive features

## 3. Edge Case Tests

### 3.1 Error Handling

- **Error Scenarios**
  - [ ] Test with invalid file paths
  - [ ] Test with permission denied
  - [ ] Test with disk full
  - [ ] Test with memory limits
  - [ ] Test with corrupt configurations
  - [ ] Test with network failures
  - [ ] Test with concurrent access

### 3.2 Performance Tests

- **Performance Scenarios**
  - [ ] Test with large repositories (>1GB)
  - [ ] Test with many small files (>10,000)
  - [ ] Test memory usage patterns
  - [ ] Test CPU usage patterns
  - [ ] Test concurrent operations
  - [ ] Test with limited resources
  - [ ] Test startup performance

## 4. Environment Tests

### 4.1 Platform Compatibility

- **Operating Systems**
  - [ ] Test on Windows
  - [ ] Test on macOS
  - [ ] Test on Linux
  - [ ] Test on different Node.js versions
  - [ ] Test path handling across platforms
  - [ ] Test file encoding across platforms
  - [ ] Test line ending handling

### 4.2 Node.js Version Compatibility

- **Version Support**
  - [ ] Test with Node.js 16.x
  - [ ] Test with Node.js 18.x
  - [ ] Test with Node.js 20.x
  - [ ] Test with Node.js 22.x
  - [ ] Test with Node.js 23.x
  - [ ] Test npm compatibility
  - [ ] Test yarn compatibility

## 5. Feature-Specific Tests

### 5.1 Auto-Commit Feature

- **Auto-Commit Functionality**
  - [ ] Test commit message generation
  - [ ] Test file analysis
  - [ ] Test timeline generation
  - [ ] Test interactive UI
  - [ ] Test template system
  - [ ] Test conventional commits
  - [ ] Test breaking change detection

### 5.2 Context Management

- **Context Analysis**
  - [ ] Test context extraction
  - [ ] Test dependency analysis
  - [ ] Test scope detection
  - [ ] Test cache management
  - [ ] Test context depth control
  - [ ] Test context formatting
  - [ ] Test context search

### 5.3 Git History

- **History Tracking**
  - [ ] Test command tracking
  - [ ] Test repository metadata
  - [ ] Test dashboard generation
  - [ ] Test time range filtering
  - [ ] Test data persistence
  - [ ] Test history analysis
  - [ ] Test metrics calculation

### 5.4 Repository Migration

- **Migration Features**
  - [ ] Test repository search
  - [ ] Test repository cloning
  - [ ] Test repository creation
  - [ ] Test push operations
  - [ ] Test error handling
  - [ ] Test progress tracking
  - [ ] Test cleanup operations

## Implementation Guidelines

1. **Test Organization**
   - Use descriptive test names
   - Group related tests together
   - Use beforeEach/afterEach for setup/cleanup
   - Mock external dependencies
   - Use fixtures for test data

2. **Test Coverage**
   - Aim for >80% code coverage
   - Focus on critical paths
   - Include edge cases
   - Test error conditions
   - Test configuration variations

3. **Testing Tools**
   - Vitest for unit and integration tests
   - Coverage reporting with v8
   - Mock file system operations
   - Mock network operations
   - Use fixtures for test data

4. **Best Practices**
   - Write independent tests
   - Use meaningful assertions
   - Clean up test resources
   - Document test scenarios
   - Follow AAA pattern (Arrange-Act-Assert)

## Test Execution

1. **Local Development**

```bash
# Run all tests
npm test

# Run tests with coverage
npm run test-coverage

# Run specific test file
npm test tests/core/file/fileCollect.test.ts
```

2. **CI/CD Pipeline**

```bash
# Full test suite
npm run test

# Coverage reports
npm run test-coverage

# Linting
npm run lint
```

## Maintenance

1. **Regular Updates**
   - Update test cases for new features
   - Review and update test data
   - Maintain test documentation
   - Monitor test performance
   - Update mock data

2. **Coverage Monitoring**
   - Track coverage trends
   - Identify untested code
   - Add missing test cases
   - Review test quality
   - Update test strategies

## Notes

1. This test plan covers both existing and planned features of repofm.
2. Tests should be added incrementally, prioritizing core functionality.
3. Each test category should have its own directory and test files.
4. Use appropriate mocking strategies for external dependencies.
5. Maintain test fixtures separate from test code.

================
File: docs/feature-auto-commit-documentation.md
================
# Auto Commit Feature Documentation

## Overview

The Auto Commit feature provides intelligent, automated git commit management with smart message generation and timeline-based suggestions.

## Configuration

Add to your `repofm.config.json`:

```json
{
  "autoCommit": {
    "includePush": true,
    "separateCommits": true,
    "generateTimeline": true,
    "commitTypes": {
      "js": "feat",
      "ts": "feat",
      "css": "style",
      "md": "docs",
      "test.js": "test"
    },
    "defaultType": "chore"
  }
}
```

## Command Line Usage

### Basic Usage

```bash
# Simple auto-commit
repofm auto-commit

# Commit and push
repofm auto-commit --push

# Commit files separately
repofm auto-commit --separate

# Show timeline before committing
repofm auto-commit --timeline

# Skip confirmation prompts
repofm auto-commit --yes

# Provide custom message for bulk commit
repofm auto-commit --message "feat: implement new feature"
```

### Options

- `-s, --separate`: Commit files separately
- `-p, --push`: Push changes after commit
- `-m, --message <message>`: Custom commit message
- `-t, --timeline`: Show timeline of changes
- `-y, --yes`: Skip confirmation prompts

## Features

### 1. Timeline-Based Analysis

```bash
repofm auto-commit --timeline

# Output:
Timeline of changes:
[2024-11-14 10:30:15] src/components/Button.js
[2024-11-14 10:35:22] src/styles/main.css
[2024-11-14 10:40:18] docs/README.md
```

### 2. Smart Commit Messages

The feature automatically generates appropriate commit messages based on:

- File type
- Changes content
- File location
- Commit conventions

Examples:

```
feat: update Button component implementation
style: refine main stylesheet
docs: update README documentation
test: add unit tests for auth module
fix: resolve navigation issue
```

### 3. Interactive Mode

Without the `--yes` flag, the tool provides interactive prompts:

```bash
repofm auto-commit

? Do you want to proceed with the commit? (Y/n)
? Commit files separately? (Y/n)
? Push changes after commit? (Y/n)
```

### 4. Batch Processing

```bash
# Commit all changes with a single message
repofm auto-commit -m "feat: implement user authentication"

# Commit files separately with smart messages
repofm auto-commit --separate
```

## Best Practices

1. **Review Timeline First**

```bash
   # Check changes timeline before committing
   repofm auto-commit --timeline
   ```

2. **Separate Commits for Different Types**

   ```bash
   # Use separate commits for better organization
   repofm auto-commit --separate
   ```

3. **Custom Messages for Major Changes**

```bash
   # Provide explicit message for significant changes
   repofm auto-commit -m "feat(auth): implement OAuth2 login"
   ```

## Common Patterns

### 1. Quick Updates

```bash
# Quick commit and push
repofm auto-commit -y -p
```

### 2. Detailed Review

```bash
# Review changes and commit separately
repofm auto-commit -t -s
```

### 3. Batch Changes

```bash
# Commit related changes together
repofm auto-commit -m "refactor: update component architecture"
```

## Tips

1. **Commit Message Conventions**
   - The tool follows conventional commit standards
   - Messages are structured as `type(scope): description`
   - Types include: feat, fix, docs, style, refactor, test, chore

2. **File Organization**
   - Group related changes for better commit organization
   - Use separate commits for different types of changes
   - Consider the timeline when organizing commits

3. **Push Strategy**
   - The tool automatically pulls before pushing
   - Use `--push` for immediate remote updates
   - Consider CI/CD triggers when pushing

4. **Timeline Analysis**
   - Use timeline view to understand change patterns
   - Group changes by time periods
   - Identify related modifications

================
File: docs/gitignore-support-documentation.md
================
# GitIgnore Support Documentation

## Overview

The GitIgnore support feature allows you to automatically respect `.gitignore` rules across all context operations. This feature can be configured globally and overridden per command.

## Configuration

Add these settings to your `repofm.config.json`:

```json
{
  "context": {
    "respectGitIgnore": true,
    "customIgnores": [
      "*.log",
      "temp/",
      "private/"
    ]
  }
}
```

## Usage

### Command Line Options

```bash
# Disable gitignore support for a specific command
repofm context extract --target "src/" --type file --respect-gitignore false

# Add custom ignore patterns
repofm context extract --target "src/" --type file --custom-ignore "*.log" "temp/*"

# Show which files are being ignored
repofm context extract --target "src/" --type file --show-ignored
```

### Global Configuration

You can set up global ignore patterns that will be combined with your `.gitignore` rules:

```json
{
  "context": {
    "respectGitIgnore": true,
    "customIgnores": [
      "*.log",
      "*.tmp",
      "node_modules/",
      "build/",
      "dist/",
      ".env*",
      "coverage/",
      "*.test.js"
    ]
  }
}
```

## Features

1. **Automatic .gitignore Detection**
   - Automatically loads all `.gitignore` files in the project
   - Supports nested `.gitignore` files
   - Respects global git ignore rules

2. **Custom Ignore Patterns**
   - Add custom patterns via configuration
   - Override patterns via command line
   - Support for glob patterns

3. **Performance Optimization**
   - Caches ignore rules for better performance
   - Minimal overhead on context operations
   - Efficient path filtering

## Examples

### 1. Basic Usage

```bash
# Extract context while respecting .gitignore
repofm context extract --target src/components --type file

# The command will automatically ignore files that match .gitignore patterns
```

### 2. Custom Ignore Patterns

```bash
# Add temporary ignore patterns
repofm context extract --target src/ --type file \
  --custom-ignore "*.spec.js" "*.test.js" "**/__tests__/*"
```

### 3. Showing Ignored Files

```bash
# Show which files are being ignored
repofm context extract --target src/ --type file --show-ignored

# Output will include:
# Ignored: src/components/__tests__/
# Ignored: src/components/*.test.js
# ...
```

### 4. Ignoring in Specific Directories

Create a `.gitignore` file in any directory:

```plaintext
# src/components/.gitignore
__tests__/
*.test.js
*.spec.js
```

The context manager will automatically respect these rules when processing files in that directory.

## Best Practices

1. **Project Organization**
   - Place `.gitignore` files strategically in subdirectories
   - Use custom ignore patterns for temporary exclusions
   - Document project-specific ignore patterns

2. **Performance**
   - Use specific paths when possible to limit scope
   - Consider disabling gitignore support for quick operations
   - Cache ignore rules when working with large codebases

3. **Maintenance**
   - Regularly review and update ignore patterns
   - Document custom ignore patterns in project documentation
   - Use consistent patterns across team members

## Common Use Cases

1. **Excluding Test Files**

```json
{
  "context": {
    "customIgnores": [
      "**/*.test.js",
      "**/*.spec.js",
      "**/__tests__/*",
      "**/test/*"
    ]
  }
}
```

2. **Excluding Build Artifacts**

```json
{
  "context": {
    "customIgnores": [
      "dist/",
      "build/",
      ".next/",
      "out/",
      ".cache/"
    ]
  }
}
```

3. **Excluding Development Files**

```json
{
  "context": {
    "customIgnores": [
      ".env*",
      "*.log",
      "*.tmp",
      ".vscode/",
      ".idea/"
    ]
  }
}
```

================
File: docs/release-notes-v0.2.0.md
================
# Release Notes v0.2.0

This major release introduces three powerful new features to repofm: GitHub repository migration, Git command history tracking, and enhanced code context management. These additions significantly expand repofm's capabilities in managing and analyzing code repositories.

## What's New

### GitHub Repository Migration (#100)

- Added functionality to search and migrate repositories from specific GitHub users:
  - Search repositories by username
  - Clone repositories with custom naming
  - Optional local cloning
  - Automated repository creation and migration
  - Flexible target account selection

### Git Command History Tracking (#101)

- Implemented comprehensive Git command tracking:
  - Tracks clone, commit, and push operations
  - Project-based command grouping
  - Local Supabase integration for data persistence
  - Interactive dashboard for activity visualization
  - Date-based filtering and organization

### Enhanced Code Context Management (#102)

- Added dynamic code context management:
  - Support for function-level context queries
  - File-level context extraction
  - Character-level precision
  - Multiple output formats (plain, markdown, XML)
  - Context depth configuration

## How to Use

### Repository Migration

```bash
repofm migrate-repo -u sourceUser -n newName -o targetOrg --clone
```

### Git History Dashboard

```bash
repofm git-dashboard --range 7d
```

### Context Management

```bash
repofm context -t "functionName" -y function -d 2 -f markdown
```

## Configuration

Update your `repofm.config.json` with the new settings:

```json
{
  "github": {
    "token": "YOUR_GITHUB_TOKEN"
  },
  "supabase": {
    "url": "YOUR_SUPABASE_URL",
    "key": "YOUR_SUPABASE_KEY"
  },
  "context": {
    "outputFormat": "markdown",
    "maxDepth": 2
  }
}
```

## How to Update

To update to the latest version, run:

```bash
npm update -g repofm
```

---

As always, we appreciate your feedback and contributions to make repofm even better! If you encounter any issues or have suggestions regarding these new features, please let us know through our GitHub issues.

================
File: docs/repofm-enhanced-auto-commit-documentation.md
================
# repofm Enhanced Auto-Commit

## 概述

Enhanced Auto-Commit 是 repofm 的一个强大功能，它提供了智能的提交管理、代码分析和团队协作功能。本文档详细介绍了所有可用功能及其使用方法。

## 功能特性

### 1. 智能提交管理

#### 1.1 文件分析与分类

```bash
# 查看变更文件的智能分析
repofm commit analyze

# 按类型分组显示变更
repofm commit list --group-by type

# 显示详细的文件分析
repofm commit analyze --detailed
```

输出示例：

```
📊 Changes Analysis
├── 🔵 Components (3 files)
│   ├── src/components/Button.jsx
│   ├── src/components/Form.tsx
│   └── src/components/Modal.tsx
├── 🎨 Styles (2 files)
│   ├── src/styles/main.scss
│   └── src/styles/components.css
└── 📝 Documentation (1 file)
    └── docs/API.md
```

#### 1.2 智能提交消息生成

```bash
# 使用AI辅助生成提交消息
repofm commit message --ai

# 基于模板生成提交消息
repofm commit message --template feature

# 交互式消息构建
repofm commit message --interactive
```

消息模板示例：

```
feat(ui): implement responsive Button component
- Add new design tokens
- Implement mobile-first approach
- Add accessibility features

BREAKING CHANGE: Button API has been updated
- `size` prop now accepts 'sm' | 'md' | 'lg'
- Removed deprecated `width` prop
```

### 2. 增强的交互功能

#### 2.1 可视化差异查看

```bash
# 启动交互式差异查看器
repofm commit diff

# 查看特定文件的变更
repofm commit diff src/components/Button.jsx

# 并排对比模式
repofm commit diff --side-by-side
```

#### 2.2 分阶段提交

```bash
# 交互式暂存
repofm commit stage

# 选择性暂存代码块
repofm commit stage --interactive

# 编辑暂存块
repofm commit stage --edit
```

### 3. 团队协作功能

#### 3.1 Issue 追踪集成

```bash
# 链接到 Jira issue
repofm commit --jira PROJ-123

# 链接到 GitHub issue
repofm commit --issue #456

# 自动生成 issue 链接
repofm commit --link-issues
```

配置示例：

```json
{
  "issueTracking": {
    "jira": {
      "url": "https://your-company.atlassian.net",
      "projectKey": "PROJ"
    },
    "github": {
      "repo": "owner/repo"
    }
  }
}
```

#### 3.2 代码审查集成

```bash
# 创建拉取请求
repofm commit --create-pr

# 添加审查者
repofm commit --reviewers @john @jane

# 自动标签
repofm commit --labels feature,ui
```

### 4. 代码分析功能

#### 4.1 代码质量检查

```bash
# 运行代码质量检查
repofm commit analyze --lint

# 检查潜在问题
repofm commit analyze --potential-issues

# 性能影响分析
repofm commit analyze --performance
```

分析报告示例：

```
🔍 Code Analysis Report
├── Quality Metrics
│   ├── Complexity: Low
│   ├── Maintainability: A
│   └── Test Coverage: 85%
├── Potential Issues
│   ├── Warning: Unused variable in Button.jsx
│   └── Info: Consider memoization in Form.tsx
└── Performance Impact
    ├── Bundle Size: +0.5kb
    └── Runtime: Minimal impact
```

#### 4.2 依赖分析

```bash
# 检查依赖影响
repofm commit analyze --dependencies

# 查看依赖图
repofm commit analyze --dep-graph

# 安全漏洞检查
repofm commit analyze --security
```

### 5. Git 历史可视化

```bash
# 查看提交历史图表
repofm commit history --graph

# 分析提交模式
repofm commit history --patterns

# 生成变更报告
repofm commit history --report
```

## 配置选项

完整的配置示例：

```json
{
  "autoCommit": {
    "ui": {
      "useEmoji": true,
      "showHints": true,
      "detailedDiff": true,
      "theme": "dark"
    },
    "commit": {
      "conventionalCommits": true,
      "scope": {
        "required": true,
        "suggestions": ["ui", "api", "core"]
      },
      "validation": {
        "messageLength": {
          "header": 72,
          "description": 500
        }
      }
    },
    "analysis": {
      "ai": {
        "enabled": true,
        "model": "gpt-4"
      },
      "linting": {
        "enabled": true,
        "config": ".eslintrc"
      }
    },
    "integration": {
      "jira": {
        "enabled": true,
        "required": false
      },
      "github": {
        "enabled": true,
        "autolink": true
      }
    },
    "templates": {
      "feature": {
        "add": "feat({}): add {} functionality",
        "update": "feat({}): update {} implementation"
      }
    }
  }
}
```

## 使用最佳实践

### 1. 提交消息

- 使用约定式提交规范
- 包含明确的范围
- 提供清晰的描述
- 标注破坏性变更

### 2. 代码审查

- 使用交互式暂存进行逻辑分组
- 添加适当的审查者
- 包含测试覆盖
- 链接相关问题

### 3. 团队协作

- 保持issue追踪更新
- 使用适当的标签
- 遵循团队约定
- 提供充分的上下文

### 4. 代码质量

- 定期运行代码分析
- 关注性能影响
- 维护依赖健康
- 处理安全问题

## 常见问题解决

1. **提交消息格式错误**

```bash
# 检查提交消息格式
repofm commit verify-message

# 自动修复格式问题
repofm commit fix-message
```

2. **合并冲突处理**

```bash
# 交互式合并工具
repofm commit merge --interactive

# 查看冲突详情
repofm commit conflicts
```

3. **性能问题**

```bash
# 优化大型仓库性能
repofm commit --optimize

# 清理缓存
repofm commit clean-cache
```

## 扩展和集成

### 1. 自定义插件

```javascript
// custom-plugin.js
module.exports = {
  name: 'custom-commit-plugin',
  hooks: {
    beforeCommit: async (context) => {
      // 自定义逻辑
    }
  }
};
```

### 2. CI/CD 集成

```yaml
# .github/workflows/commit-check.yml
name: Commit Check
on: [push]
jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Verify Commit
        run: repofm commit verify
```

## 更新日志

### v2.0.0

- ✨ 添加 AI 辅助提交消息生成
- 🎨 改进可视化差异查看器
- 🔗 增加 Jira/GitHub 集成
- 📊 新增代码分析功能
- 🤝 添加团队协作特性

## 后续规划

1. **AI 增强**
   - 更智能的代码分析
   - 自动问题检测
   - 提交消息优化

2. **团队功能**
   - 团队配置同步
   - 代码审查工作流
   - 自动化报告

3. **性能优化**
   - 更快的文件分析
   - 增量缓存
   - 并行处理

================
File: docs/repofm-New-Features-Implementation-Plan.md
================
# repofm Feature Implementation Plan

## 1. GitHub Repository Migration Feature

### Overview

Add functionality to search and clone repositories from a specific GitHub user, then optionally clone locally and push to a specified account with a new name.

### Implementation Details

```javascript
// src/features/repoMigration.js
import { Octokit } from '@octokit/rest';
import simpleGit from 'simple-git';

export class RepoMigrationService {
  constructor(config) {
    this.octokit = new Octokit({ auth: config.githubToken });
    this.git = simpleGit();
  }

  async searchUserRepos(username) {
    try {
      const { data } = await this.octokit.repos.listForUser({
        username,
        sort: 'updated',
        per_page: 100
      });
      return data.map(repo => ({
        name: repo.name,
        description: repo.description,
        url: repo.clone_url,
        stars: repo.stargazers_count,
        language: repo.language
      }));
    } catch (error) {
      throw new Error(`Failed to fetch repositories: ${error.message}`);
    }
  }

  async migrateRepository({
    sourceRepo,
    targetName,
    targetOwner,
    cloneLocally,
    localPath
  }) {
    try {
      // Clone repository
      await this.git.clone(sourceRepo.url, localPath);

      if (cloneLocally) {
        // If user wants to keep local copy, we're done
        return { success: true, path: localPath };
      }

      // Create new repository
      const { data: newRepo } = await this.octokit.repos.createForAuthenticatedUser({
        name: targetName,
        private: true
      });

      // Push to new repository
      await this.git.cwd(localPath)
        .removeRemote('origin')
        .addRemote('origin', newRepo.clone_url)
        .push(['--all']);

      return {
        success: true,
        newRepoUrl: newRepo.html_url,
        localPath: cloneLocally ? localPath : null
      };
    } catch (error) {
      throw new Error(`Migration failed: ${error.message}`);
    }
  }
}
```

## 2. Git Command History Tracking

### Overview

Track global Git command history, focusing on clone, commit, and push operations. Store data in Supabase and provide a dashboard view.

### Database Schema (Supabase)

```sql
-- Git command history table
CREATE TABLE git_command_history (
  id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
  command_type TEXT NOT NULL,
  repository_path TEXT NOT NULL,
  repository_name TEXT NOT NULL,
  command_details JSONB NOT NULL,
  executed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
  user_id TEXT NOT NULL
);

-- Repository metadata table
CREATE TABLE repository_metadata (
  id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
  repository_path TEXT UNIQUE NOT NULL,
  repository_name TEXT NOT NULL,
  last_activity TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
  total_commits INTEGER DEFAULT 0,
  total_pushes INTEGER DEFAULT 0
);
```

### Implementation

```javascript
// src/features/gitHistory.js
import { createClient } from '@supabase/supabase-js';
import { execSync } from 'child_process';

export class GitHistoryTracker {
  constructor(config) {
    this.supabase = createClient(config.supabaseUrl, config.supabaseKey);
  }

  async trackCommand(command, repoPath) {
    const repoName = this.getRepoName(repoPath);
    const commandType = this.parseCommandType(command);

    await this.supabase
      .from('git_command_history')
      .insert({
        command_type: commandType,
        repository_path: repoPath,
        repository_name: repoName,
        command_details: {
          full_command: command,
          timestamp: new Date().toISOString()
        }
      });

    await this.updateRepositoryMetadata(repoPath, commandType);
  }

  async getDashboardData(timeRange = '7d') {
    const { data, error } = await this.supabase
      .from('git_command_history')
      .select(`
        command_type,
        repository_name,
        command_details,
        executed_at
      `)
      .gte('executed_at', new Date(Date.now() - this.parseTimeRange(timeRange)))
      .order('executed_at', { ascending: false });

    if (error) throw error;
    return this.formatDashboardData(data);
  }
}
```

## 3. Code Context Management

### Overview

Implement dynamic management of code context information with support for function, file, and character-level queries. Output in plain, markdown, or XML format.

### Implementation

```javascript
// src/features/contextManager.js
import { parse } from '@babel/parser';
import traverse from '@babel/traverse';
import * as fs from 'fs/promises';

export class CodeContextManager {
  constructor(config) {
    this.outputFormat = config.outputFormat || 'markdown';
  }

  async getContext({
    target,
    type,
    depth = 1,
    includeImports = true
  }) {
    const context = await this.extractContext(target, type, depth);
    return this.formatOutput(context);
  }

  async extractContext(target, type, depth) {
    switch (type) {
      case 'function':
        return this.getFunctionContext(target, depth);
      case 'file':
        return this.getFileContext(target, depth);
      case 'character':
        return this.getCharacterContext(target, depth);
      default:
        throw new Error(`Unsupported context type: ${type}`);
    }
  }

  formatOutput(context) {
    switch (this.outputFormat) {
      case 'markdown':
        return this.toMarkdown(context);
      case 'xml':
        return this.toXML(context);
      default:
        return this.toPlainText(context);
    }
  }
}
```

## Configuration Updates

Add the following to `repofm.config.json`:

```json
{
  "github": {
    "token": "YOUR_GITHUB_TOKEN"
  },
  "supabase": {
    "url": "YOUR_SUPABASE_URL",
    "key": "YOUR_SUPABASE_KEY"
  },
  "context": {
    "outputFormat": "markdown",
    "maxDepth": 2,
    "includeImports": true
  }
}
```

## CLI Commands

Add these new commands to the CLI:

```javascript
// src/cli.js
program
  .command('migrate-repo')
  .description('Search and migrate repositories from a GitHub user')
  .option('-u, --user <username>', 'Source GitHub username')
  .option('-n, --name <name>', 'New repository name')
  .option('-o, --owner <owner>', 'Target owner/organization')
  .option('-c, --clone', 'Clone repository locally')
  .action(async (options) => {
    const service = new RepoMigrationService(config);
    await service.migrateRepository(options);
  });

program
  .command('git-dashboard')
  .description('Show Git activity dashboard')
  .option('-r, --range <range>', 'Time range (e.g., 7d, 30d)', '7d')
  .action(async (options) => {
    const tracker = new GitHistoryTracker(config);
    const data = await tracker.getDashboardData(options.range);
    console.log(formatDashboard(data));
  });

program
  .command('context')
  .description('Get code context')
  .option('-t, --target <target>', 'Target (function name, file path, or character position)')
  .option('-y, --type <type>', 'Context type (function, file, character)')
  .option('-d, --depth <depth>', 'Context depth', '1')
  .option('-f, --format <format>', 'Output format (plain, markdown, xml)', 'markdown')
  .action(async (options) => {
    const manager = new CodeContextManager({ outputFormat: options.format });
    const context = await manager.getContext(options);
    console.log(context);
  });
```

================
File: src/cli/actions/defaultAction.ts
================
import { globby } from 'globby';
import * as fs from 'node:fs/promises';
import { logger } from '../../shared/logger.js';
import type { Config } from '../../types/config.js';
import { generateOutput } from '../../core/output/outputGenerate.js';

export async function runDefaultAction(directory: string, config: Config): Promise<void> {
  try {
    // Extract ignore patterns
    const ignorePatterns = Array.isArray(config.ignore)
      ? config.ignore
      : config.ignore.customPatterns;

    // Get file list
    const files = await globby(config.include, {
      ignore: ignorePatterns,
      dot: true,
      gitignore: true,
      cwd: directory
    });

    // Process file contents
    const fileContents = await Promise.all(
      files.map(async (filePath) => {
        const content = await fs.readFile(filePath, 'utf8');
        return { path: filePath, content };
      })
    );

    // Generate output
    const output = await generateOutput(directory, config, fileContents, files);

    // Write output file
    await fs.writeFile(config.output.filePath, output, 'utf8');
    logger.success(`Generated file structure at ${config.output.filePath}`);
  } catch (error) {
    logger.error('Error running default action:', error);
  }
}

================
File: src/cli/actions/initAction.ts
================
import fs from 'node:fs/promises';
import path from 'node:path';
import * as prompts from '@clack/prompts';
import pc from 'picocolors';
import {
  type repofmConfigFile,
  type repofmOutputStyle,
  defaultConfig,
  defaultFilePathMap,
} from '../../config/configSchema.js';
import { getGlobalDirectory } from '../../config/globalDirectory.js';
import { logger } from '../../shared/logger.js';

const onCancelOperation = () => {
  prompts.cancel('Initialization cancelled.');
  process.exit(0);
};

export const runInitAction = async (rootDir: string, isGlobal: boolean): Promise<void> => {
  prompts.intro(pc.bold(`Welcome to repofm ${isGlobal ? 'Global ' : ''}Configuration!`));

  try {
    // Step 1: Ask if user wants to create a config file
    const isCreatedConfig = await createConfigFile(rootDir, isGlobal);

    // Step 2: Ask if user wants to create a .repofmignore file
    const isCreatedIgnoreFile = await createIgnoreFile(rootDir, isGlobal);

    if (!isCreatedConfig && !isCreatedIgnoreFile) {
      prompts.outro(
        pc.yellow('No files were created. You can run this command again when you need to create configuration files.'),
      );
    } else {
      prompts.outro(pc.green('Initialization complete! You can now use repofm with your specified settings.'));
    }
  } catch (error) {
    logger.error('An error occurred during initialization:', error);
  }
};

export async function createConfigFile(rootDir: string, isGlobal: boolean): Promise<boolean> {
  const isCancelled = false;

  const configPath = isGlobal
    ? path.resolve(getGlobalDirectory(), 'repofm.config.json')
    : path.resolve(rootDir, 'repofm.config.json');

  const isCreateConfig = await prompts.confirm({
    message: `Do you want to create a ${isGlobal ? 'global ' : ''}${pc.green('repofm.config.json')} file?`,
  });
  if (!isCreateConfig) {
    prompts.log.info(`Skipping ${pc.green('repofm.config.json')} file creation.`);
    return false;
  }
  if (prompts.isCancel(isCreateConfig)) {
    onCancelOperation();
    return false;
  }

  let isConfigFileExists = false;
  try {
    await fs.access(configPath);
    isConfigFileExists = true;
  } catch {
    // File doesn't exist, so we can proceed
  }

  if (isConfigFileExists) {
    const isOverwrite = await prompts.confirm({
      message: `A ${isGlobal ? 'global ' : ''}${pc.green('repofm.config.json')} file already exists. Do you want to overwrite it?`,
    });
    if (!isOverwrite) {
      prompts.log.info(`Skipping ${pc.green('repofm.config.json')} file creation.`);
      return false;
    }
    if (prompts.isCancel(isOverwrite)) {
      onCancelOperation();
      return false;
    }
  }

  const options = await prompts.group(
    {
      outputStyle: () => {
        if (isCancelled) {
          return;
        }
        return prompts.select({
          message: 'Output style:',
          options: [
            { value: 'plain', label: 'Plain', hint: 'Simple text format' },
            { value: 'xml', label: 'XML', hint: 'Structured XML format' },
            { value: 'markdown', label: 'Markdown', hint: 'Markdown format' },
          ],
          initialValue: defaultConfig.output.style,
        });
      },
      outputFilePath: ({ results }) => {
        if (isCancelled) {
          return;
        }
        const defaultFilePath = defaultFilePathMap[results.outputStyle as repofmOutputStyle];
        return prompts.text({
          message: 'Output file path:',
          initialValue: defaultFilePath,
          validate: (value) => (value.length === 0 ? 'Output file path is required' : undefined),
        });
      },
    },
    {
      onCancel: onCancelOperation,
    },
  );

  const config: repofmConfigFile = {
    ...defaultConfig,
    output: {
      ...defaultConfig.output,
      filePath: options.outputFilePath as string,
      style: options.outputStyle as repofmOutputStyle,
    },
  };

  await fs.mkdir(path.dirname(configPath), { recursive: true });
  await fs.writeFile(configPath, JSON.stringify(config, null, 2));

  const relativeConfigPath = path.relative(rootDir, configPath);

  prompts.log.success(
    pc.green(`${isGlobal ? 'Global config' : 'Config'} file created!\n`) + pc.dim(`Path: ${relativeConfigPath}`),
  );

  return true;
}

export async function createIgnoreFile(rootDir: string, isGlobal: boolean): Promise<boolean> {
  if (isGlobal) {
    prompts.log.info(`Skipping ${pc.green('.repofmignore')} file creation for global configuration.`);
    return false;
  }

  const ignorePath = path.resolve(rootDir, '.repofmignore');
  const createIgnore = await prompts.confirm({
    message: `Do you want to create a ${pc.green('.repofmignore')} file?`,
  });
  if (!createIgnore) {
    prompts.log.info(`Skipping ${pc.green('.repofmignore')} file creation.`);
    return false;
  }
  if (prompts.isCancel(createIgnore)) {
    onCancelOperation();
    return false;
  }

  let isIgnoreFileExists = false;
  try {
    await fs.access(ignorePath);
    isIgnoreFileExists = true;
  } catch {
    // File doesn't exist, so we can proceed
  }

  if (isIgnoreFileExists) {
    const overwrite = await prompts.confirm({
      message: `A ${pc.green('.repofmignore')} file already exists. Do you want to overwrite it?`,
    });

    if (!overwrite) {
      prompts.log.info(`${pc.green('.repofmignore')} file creation skipped. Existing file will not be modified.`);
      return false;
    }
  }

  const defaultIgnoreContent = `# Add patterns to ignore here, one per line
# Example:
# *.log
# tmp/
`;

  await fs.writeFile(ignorePath, defaultIgnoreContent);
  prompts.log.success(
    pc.green('Created .repofmignore file!\n') + pc.dim(`Path: ${path.relative(rootDir, ignorePath)}`),
  );

  return true;
}

================
File: src/cli/actions/migrationAction.ts
================
import * as fs from 'node:fs/promises';
import path from 'node:path';
import * as prompts from '@clack/prompts';
import pc from 'picocolors';
import { getGlobalDirectory } from '../../config/globalDirectory.js';
import { logger } from '../../shared/logger.js';

interface MigrationPaths {
  oldConfigPath: string;
  newConfigPath: string;
  oldIgnorePath: string;
  newIgnorePath: string;
  oldInstructionPath: string;
  newInstructionPath: string;
  oldOutputPaths: string[];
  newOutputPaths: string[];
  oldGlobalConfigPath: string;
  newGlobalConfigPath: string;
}

interface MigrationResult {
  configMigrated: boolean;
  ignoreMigrated: boolean;
  instructionMigrated: boolean;
  outputFilesMigrated: string[];
  globalConfigMigrated: boolean;
  error?: Error;
}

/**
 * Check if a file exists at the given path
 */
const fileExists = async (filePath: string): Promise<boolean> => {
  try {
    await fs.access(filePath);
    return true;
  } catch {
    return false;
  }
};

/**
 * Replace all occurrences of 'repofm' with 'repofm' in a string
 */
const replaceRepofmString = (content: string): string => {
  if (!content.includes('repofm') && !content.includes('Repofm')) {
    return content;
  }

  let result = content;
  if (content.includes('repofm')) {
    result = result.replace(/repofm/g, 'repofm');
  }
  if (content.includes('Repofm')) {
    result = result.replace(/Repofm/g, 'repofm');
  }
  return result;
};

/**
 * Update file content by replacing 'repofm' with 'repofm'
 */
const updateFileContent = async (filePath: string): Promise<boolean> => {
  const content = await fs.readFile(filePath, 'utf8');
  const updatedContent = replaceRepofmString(content);

  // Check if content needs to be updated
  if (content !== updatedContent) {
    await fs.writeFile(filePath, updatedContent, 'utf8');
    const relativePath = path.relative(process.cwd(), filePath);
    logger.log(`Updated repofm references in ${pc.cyan(relativePath)}`);
    return true;
  }

  return false;
};

/**
 * Parse JSON content, update instructionFilePath if exists
 */
const updateInstructionPath = (content: string): string => {
  try {
    const config = JSON.parse(content);
    if (config.output?.instructionFilePath) {
      config.output.instructionFilePath = config.output.instructionFilePath.replace('repofm', 'repofm');
    }
    // Also update output.filePath if it exists
    if (config.output?.filePath) {
      config.output.filePath = config.output.filePath.replace('repofm', 'repofm');
    }
    return JSON.stringify(config, null, 2);
  } catch {
    return content;
  }
};

/**
 * Get output file paths pairs
 */
const getOutputFilePaths = (rootDir: string): { oldPaths: string[]; newPaths: string[] } => {
  const extensions = ['.txt', '.xml', '.md'];
  const oldPaths = extensions.map((ext) => path.join(rootDir, `repofm-output${ext}`));
  const newPaths = extensions.map((ext) => path.join(rootDir, `repofm-output${ext}`));
  return { oldPaths, newPaths };
};

/**
 * Migrate a single file from old path to new path
 */
const migrateFile = async (
  oldPath: string,
  newPath: string,
  description: string,
  isConfig = false,
): Promise<boolean> => {
  if (!(await fileExists(oldPath))) {
    return false;
  }

  const exists = await fileExists(newPath);
  if (exists) {
    const shouldOverwrite = await prompts.confirm({
      message: `${description} already exists at ${newPath}. Do you want to overwrite it?`,
    });

    if (prompts.isCancel(shouldOverwrite) || !shouldOverwrite) {
      logger.info(`Skipping migration of ${description}`);
      return false;
    }
  }

  try {
    // Read and update content
    let content = await fs.readFile(oldPath, 'utf8');
    content = replaceRepofmString(content);

    // For config files, also update instructionFilePath and output.filePath
    if (isConfig) {
      content = updateInstructionPath(content);
    }

    // Ensure the target directory exists
    await fs.mkdir(path.dirname(newPath), { recursive: true });

    // Write to new file
    await fs.writeFile(newPath, content, 'utf8');

    // Remove old file
    await fs.unlink(oldPath);

    const relativeOldPath = path.relative(process.cwd(), oldPath);
    const relativeNewPath = path.relative(process.cwd(), newPath);

    logger.log(`Renamed ${description} from ${relativeOldPath} to ${relativeNewPath}`);
    return true;
  } catch (error) {
    logger.error(`Failed to migrate ${description}:`, error);
    return false;
  }
};

/**
 * Update content of gitignore and repofmignore files
 */
const updateIgnoreFiles = async (rootDir: string): Promise<void> => {
  const gitignorePath = path.join(rootDir, '.gitignore');
  const repofmignorePath = path.join(rootDir, '.repofmignore');

  if (await fileExists(gitignorePath)) {
    const updated = await updateFileContent(gitignorePath);
    if (!updated) {
      logger.debug('No changes needed in .gitignore');
    }
  }

  if (await fileExists(repofmignorePath)) {
    const updated = await updateFileContent(repofmignorePath);
    if (!updated) {
      logger.debug('No changes needed in .repofmignore');
    }
  }
};

/**
 * Get all migration related file paths
 */
const getMigrationPaths = (rootDir: string): MigrationPaths => {
  const { oldPaths: oldOutputPaths, newPaths: newOutputPaths } = getOutputFilePaths(rootDir);
  const oldGlobalDirectory = path.join(process.env.HOME || '', '.config', 'repofm');
  const newGlobalDirectory = getGlobalDirectory();

  return {
    oldConfigPath: path.join(rootDir, 'repofm.config.json'),
    newConfigPath: path.join(rootDir, 'repofm.config.json'),
    oldIgnorePath: path.join(rootDir, '.repofmignore'),
    newIgnorePath: path.join(rootDir, '.repofmignore'),
    oldInstructionPath: path.join(rootDir, 'repofm-instruction.md'),
    newInstructionPath: path.join(rootDir, 'repofm-instruction.md'),
    oldOutputPaths,
    newOutputPaths,
    oldGlobalConfigPath: path.join(oldGlobalDirectory, 'repofm.config.json'),
    newGlobalConfigPath: path.join(newGlobalDirectory, 'repofm.config.json'),
  };
};

/**
 * Migrate output files
 */
const migrateOutputFiles = async (oldPaths: string[], newPaths: string[]): Promise<string[]> => {
  const migratedFiles: string[] = [];

  for (let i = 0; i < oldPaths.length; i++) {
    const oldPath = oldPaths[i];
    const newPath = newPaths[i];
    const ext = path.extname(oldPath);

    if (await migrateFile(oldPath, newPath, `Output file (${ext})`)) {
      migratedFiles.push(newPath);
    }
  }

  return migratedFiles;
};

export const runMigrationAction = async (rootDir: string): Promise<MigrationResult> => {
  const result: MigrationResult = {
    configMigrated: false,
    ignoreMigrated: false,
    instructionMigrated: false,
    outputFilesMigrated: [],
    globalConfigMigrated: false,
  };

  try {
    const paths = getMigrationPaths(rootDir);

    // Check if migration is needed
    const hasOldConfig = await fileExists(paths.oldConfigPath);
    const hasOldIgnore = await fileExists(paths.oldIgnorePath);
    const hasOldInstruction = await fileExists(paths.oldInstructionPath);
    const hasOldGlobalConfig = await fileExists(paths.oldGlobalConfigPath);
    const hasOldOutput = await Promise.all(paths.oldOutputPaths.map(fileExists)).then((results) =>
      results.some((exists) => exists),
    );

    if (!hasOldConfig && !hasOldIgnore && !hasOldInstruction && !hasOldOutput && !hasOldGlobalConfig) {
      logger.debug('No Repofm files found to migrate.');
      return result;
    }

    // Show migration notice based on what needs to be migrated
    let migrationMessage = `Found ${pc.green('Repofm')} `;
    const items = [];
    if (hasOldConfig || hasOldIgnore || hasOldInstruction || hasOldOutput) items.push('local configuration');
    if (hasOldGlobalConfig) items.push('global configuration');
    migrationMessage += `${items.join(' and ')}. Would you like to migrate to ${pc.green('repofm')}?`;

    // Confirm migration with user
    const shouldMigrate = await prompts.confirm({
      message: migrationMessage,
    });

    if (prompts.isCancel(shouldMigrate) || !shouldMigrate) {
      logger.info('Migration cancelled.');
      return result;
    }

    // Show migration notice
    logger.info(pc.cyan('\nMigrating from Repofm to repofm...'));
    logger.log('');

    // Migrate config file
    if (hasOldConfig) {
      result.configMigrated = await migrateFile(paths.oldConfigPath, paths.newConfigPath, 'Configuration file', true);
    }

    // Migrate global config file
    if (hasOldGlobalConfig) {
      result.globalConfigMigrated = await migrateFile(
        paths.oldGlobalConfigPath,
        paths.newGlobalConfigPath,
        'Global configuration file',
        true,
      );
    }

    // Migrate ignore file
    if (hasOldIgnore) {
      result.ignoreMigrated = await migrateFile(paths.oldIgnorePath, paths.newIgnorePath, 'Ignore file');
    }

    // Migrate instruction file
    if (hasOldInstruction) {
      result.instructionMigrated = await migrateFile(
        paths.oldInstructionPath,
        paths.newInstructionPath,
        'Instruction file',
      );
    }

    // Migrate output files
    if (hasOldOutput) {
      result.outputFilesMigrated = await migrateOutputFiles(paths.oldOutputPaths, paths.newOutputPaths);
    }

    // Update content in gitignore and repofmignore
    await updateIgnoreFiles(rootDir);

    // Show success message
    if (
      result.configMigrated ||
      result.ignoreMigrated ||
      result.instructionMigrated ||
      result.outputFilesMigrated.length > 0 ||
      result.globalConfigMigrated
    ) {
      logger.log('');
      logger.success('✔ Migration completed successfully!');
      logger.log('');
      logger.info(
        'You can now use repofm commands as usual. The old Repofm files have been migrated to the new format.',
      );
      logger.log('');
    }

    return result;
  } catch (error) {
    if (error instanceof Error) {
      result.error = error;
    } else {
      result.error = new Error(String(error));
    }
    logger.error('An error occurred during migration:', error);
    return result;
  }
};

================
File: src/cli/actions/remoteAction.ts
================
import { exec } from 'node:child_process';
import * as fs from 'node:fs/promises';
import os from 'node:os';
import path from 'node:path';
import { promisify } from 'node:util';
import pc from 'picocolors';
import { repofmError } from '../../shared/errorHandle.js';
import { logger } from '../../shared/logger.js';
import type { CliOptions } from '../cliRun.js';
import Spinner from '../cliSpinner.js';
import { runDefaultAction } from './defaultAction.js';

const execAsync = promisify(exec);

export const runRemoteAction = async (repoUrl: string, options: CliOptions): Promise<void> => {
  const gitInstalled = await checkGitInstallation();
  if (!gitInstalled) {
    throw new repofmError('Git is not installed or not in the system PATH.');
  }

  const formattedUrl = formatGitUrl(repoUrl);
  const tempDir = await createTempDirectory();
  const spinner = new Spinner('Cloning repository...');

  try {
    spinner.start();
    await cloneRepository(formattedUrl, tempDir);
    spinner.succeed('Repository cloned successfully!');
    logger.log('');

    await runDefaultAction(tempDir, {
      include: ['**/*'],
      ignore: [],
      output: {
        filePath: options.output || 'repofm-output.txt',
        style: options.style || 'plain',
        removeComments: false,
        removeEmptyLines: false,
        topFilesLength: options.topFilesLen || 10,
        showLineNumbers: options.outputShowLineNumbers || false,
        copyToClipboard: options.copy || false
      },
      security: {
        enableSecurityCheck: true
      }
    });
  } finally {
    // Clean up the temporary directory
    await cleanupTempDirectory(tempDir);
  }
};

export const formatGitUrl = (url: string): string => {
  // If the URL is in the format owner/repo, convert it to a GitHub URL
  if (/^[a-zA-Z0-9_-]+\/[a-zA-Z0-9_-]+$/.test(url)) {
    logger.trace(`Formatting GitHub shorthand: ${url}`);
    return `https://github.com/${url}.git`;
  }

  // Add .git to HTTPS URLs if missing
  if (url.startsWith('https://') && !url.endsWith('.git')) {
    logger.trace(`Adding .git to HTTPS URL: ${url}`);
    return `${url}.git`;
  }

  return url;
};

const createTempDirectory = async (): Promise<string> => {
  const tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'repofm-'));
  logger.trace(`Created temporary directory. (path: ${pc.dim(tempDir)})`);
  return tempDir;
};

const cloneRepository = async (url: string, directory: string): Promise<void> => {
  logger.log(`Clone repository: ${url} to temporary directory. ${pc.dim(`path: ${directory}`)}`);
  logger.log('');

  try {
    await execAsync(`git clone --depth 1 ${url} ${directory}`);
  } catch (error) {
    throw new repofmError(`Failed to clone repository: ${(error as Error).message}`);
  }
};

const cleanupTempDirectory = async (directory: string): Promise<void> => {
  logger.trace(`Cleaning up temporary directory: ${directory}`);
  await fs.rm(directory, { recursive: true, force: true });
};

const checkGitInstallation = async (): Promise<boolean> => {
  try {
    const result = await execAsync('git --version');
    if (result.stderr) {
      return false;
    }
    return true;
  } catch (error) {
    logger.debug('Git is not installed:', (error as Error).message);
    return false;
  }
};

const copyOutputToCurrentDirectory = async (
  sourceDir: string,
  targetDir: string,
  outputFileName: string,
): Promise<void> => {
  const sourcePath = path.join(sourceDir, outputFileName);
  const targetPath = path.join(targetDir, outputFileName);

  try {
    logger.trace(`Copying output file from: ${sourcePath} to: ${targetPath}`);
    await fs.copyFile(sourcePath, targetPath);
  } catch (error) {
    throw new repofmError(`Failed to copy output file: ${(error as Error).message}`);
  }
};

================
File: src/cli/actions/versionAction.ts
================
import { getVersion } from '../../core/file/packageJsonParse.js';
import { logger } from '../../shared/logger.js';

export const runVersionAction = async (): Promise<void> => {
  const version = await getVersion();
  logger.log(version);
};

================
File: src/cli/commands/context.js
================
// src/cli/commands/context.js
import { Command } from 'commander'
import chalk from 'chalk'
import ora from 'ora'
import { CodeContextManager } from '../../features/contextManager'
import { loadConfig } from '../config'
import { resolveFilePath, validatePath } from '../utils'

export function registerContextCommands(program) {
    const contextCommand = new Command('context').description('Manage and extract code context information')

    // Command to extract context
    contextCommand
        .command('extract')
        .description('Extract context for a specific code element')
        .option('-t, --target <target>', 'Target element (function name, file path, or character position)')
        .option('-y, --type <type>', 'Context type (function, file, character)', 'function')
        .option('-f, --file <file>', 'Source file path (required for function and character types)')
        .option('-d, --depth <depth>', 'Context analysis depth', '1')
        .option('-o, --output <format>', 'Output format (markdown, xml, plain)', 'markdown')
        .option('-s, --save <path>', 'Save output to file')
        .option('--include-imports', 'Include import statements', true)
        .option('--include-exports', 'Include export statements', true)
        .option('--max-lines <lines>', 'Maximum context lines', '100')
        .action(async (options) => {
            const spinner = ora('Extracting code context...').start()
            try {
                const config = await loadConfig()
                const manager = new CodeContextManager({
                    ...config.context,
                    outputFormat: options.output,
                    maxDepth: parseInt(options.depth),
                    includeImports: options.includeImports,
                    includeExports: options.includeExports,
                    maxContextLines: parseInt(options.maxLines)
                })

                // Validate inputs
                if (!options.target) {
                    throw new Error('Target is required')
                }

                if (['function', 'character'].includes(options.type) && !options.file) {
                    throw new Error('File path is required for function and character context types')
                }

                // Resolve file path if provided
                const filePath = options.file ? resolveFilePath(options.file) : null
                if (filePath) {
                    await validatePath(filePath)
                }

                // Extract context
                const context = await manager.getContext({
                    target: options.target,
                    type: options.type,
                    depth: parseInt(options.depth),
                    file: filePath
                })

                // Handle output
                if (options.save) {
                    const outputPath = resolveFilePath(options.save)
                    await fs.writeFile(outputPath, context)
                    spinner.succeed(`Context saved to ${chalk.green(outputPath)}`)
                } else {
                    spinner.stop()
                    console.log(context)
                }
            } catch (error) {
                spinner.fail(chalk.red(`Failed to extract context: ${error.message}`))
                process.exit(1)
            }
        })
    // Add global options for gitignore support
    contextCommand
        .option('--respect-gitignore <boolean>', 'Respect .gitignore rules', true)
        .option('--custom-ignore <patterns...>', 'Additional ignore patterns')
        .hook('preAction', async (thisCommand) => {
            const options = thisCommand.opts()
            const config = await loadConfig()

            // Update config with gitignore options
            config.context = {
                ...config.context,
                respectGitIgnore: options.respectGitignore !== 'false',
                customIgnores: options.customIgnore || []
            }

            // Initialize GitIgnoreHandler
            const manager = new CodeContextManager(config.context)
            await manager.initialize()
        })

    // Command to search within contexts
    contextCommand
        .command('search')
        .description('Search within extracted contexts')
        .option('-q, --query <query>', 'Search query')
        .option('-p, --path <path>', 'Path to search in')
        .option('-t, --type <type>', 'Limit search to context type (function, file, character)')
        .option('--json', 'Output results as JSON')
        .action(async (options) => {
            const spinner = ora('Searching contexts...').start()
            try {
                const config = await loadConfig()
                const manager = new CodeContextManager(config.context)

                const results = await manager.searchContext({
                    query: options.query,
                    path: options.path,
                    type: options.type
                })

                spinner.stop()
                if (options.json) {
                    console.log(JSON.stringify(results, null, 2))
                } else {
                    console.log(formatSearchResults(results))
                }
            } catch (error) {
                spinner.fail(chalk.red(`Search failed: ${error.message}`))
                process.exit(1)
            }
        })

    // Command to manage context cache
    contextCommand
        .command('cache')
        .description('Manage context cache')
        .option('--clear', 'Clear context cache')
        .option('--list', 'List cached contexts')
        .option('--rebuild', 'Rebuild context cache')
        .action(async (options) => {
            const spinner = ora('Managing context cache...').start()
            try {
                const config = await loadConfig()
                const manager = new CodeContextManager(config.context)

                if (options.clear) {
                    await manager.clearCache()
                    spinner.succeed('Context cache cleared')
                } else if (options.list) {
                    const cached = await manager.listCachedContexts()
                    spinner.stop()
                    console.log(formatCacheList(cached))
                } else if (options.rebuild) {
                    await manager.rebuildCache()
                    spinner.succeed('Context cache rebuilt')
                }
            } catch (error) {
                spinner.fail(chalk.red(`Cache operation failed: ${error.message}`))
                process.exit(1)
            }
        })

    return contextCommand
}

// Helper functions for formatting output
function formatSearchResults(results) {
    let output = chalk.bold('\nSearch Results:\n')

    results.forEach((result, index) => {
        output += `\n${chalk.cyan(`[${index + 1}] ${result.type}: ${result.target}`)}\n`
        output += `${chalk.gray('File:')} ${result.file}\n`
        output += `${chalk.gray('Match:')} ${highlightMatch(result.match)}\n`
        if (result.context) {
            output += `${chalk.gray('Context:')}\n${indent(result.context)}\n`
        }
    })

    return output
}

function formatCacheList(cached) {
    let output = chalk.bold('\nCached Contexts:\n')

    Object.entries(cached).forEach(([type, items]) => {
        output += `\n${chalk.cyan(type)}:\n`
        items.forEach((item) => {
            output += `  - ${item.target} (${chalk.gray(item.file)})\n`
        })
    })

    return output
}

function indent(text, spaces = 2) {
    return text
        .split('\n')
        .map((line) => ' '.repeat(spaces) + line)
        .join('\n')
}

function highlightMatch(text) {
    // Implementation of text highlighting
    return text
}

================
File: src/cli/cliPrint.ts
================
import path from 'node:path';
import pc from 'picocolors';
import type { repofmConfigMerged } from '../config/configSchema.js';
import type { SuspiciousFileResult } from '../core/security/securityCheck.js';
import { logger } from '../shared/logger.js';

export const printSummary = (
  totalFiles: number,
  totalCharacters: number,
  totalTokens: number,
  outputPath: string,
  suspiciousFilesResults: SuspiciousFileResult[],
  config: repofmConfigMerged,
) => {
  let securityCheckMessage = '';
  if (config.security.enableSecurityCheck) {
    if (suspiciousFilesResults.length > 0) {
      securityCheckMessage = pc.yellow(`${suspiciousFilesResults.length} suspicious file(s) detected and excluded`);
    } else {
      securityCheckMessage = pc.white('✔ No suspicious files detected');
    }
  } else {
    securityCheckMessage = pc.dim('Security check disabled');
  }

  logger.log(pc.white('📊 Pack Summary:'));
  logger.log(pc.dim('────────────────'));
  logger.log(`${pc.white('  Total Files:')} ${pc.white(totalFiles.toString())}`);
  logger.log(`${pc.white('  Total Chars:')} ${pc.white(totalCharacters.toString())}`);
  logger.log(`${pc.white(' Total Tokens:')} ${pc.white(totalTokens.toString())}`);
  logger.log(`${pc.white('       Output:')} ${pc.white(outputPath)}`);
  logger.log(`${pc.white('     Security:')} ${pc.white(securityCheckMessage)}`);
};

export const printSecurityCheck = (
  rootDir: string,
  suspiciousFilesResults: SuspiciousFileResult[],
  config: repofmConfigMerged,
) => {
  if (!config.security.enableSecurityCheck) {
    return;
  }

  logger.log(pc.white('🔎 Security Check:'));
  logger.log(pc.dim('──────────────────'));

  if (suspiciousFilesResults.length === 0) {
    logger.log(`${pc.green('✔')} ${pc.white('No suspicious files detected.')}`);
  } else {
    logger.log(pc.yellow(`${suspiciousFilesResults.length} suspicious file(s) detected and excluded from the output:`));
    suspiciousFilesResults.forEach((suspiciousFilesResult, index) => {
      const relativeFilePath = path.relative(rootDir, suspiciousFilesResult.filePath);
      logger.log(`${pc.white(`${index + 1}.`)} ${pc.white(relativeFilePath)}`);
      logger.log(pc.dim(`   - ${suspiciousFilesResult.messages.join('\n   - ')}`));
    });
    logger.log(pc.yellow('\nThese files have been excluded from the output for security reasons.'));
    logger.log(pc.yellow('Please review these files for potential sensitive information.'));
  }
};

export const printTopFiles = (
  fileCharCounts: Record<string, number>,
  fileTokenCounts: Record<string, number>,
  topFilesLength: number,
) => {
  logger.log(pc.white(`📈 Top ${topFilesLength} Files by Character Count and Token Count:`));
  logger.log(pc.dim('──────────────────────────────────────────────────────'));

  const topFiles = Object.entries(fileCharCounts)
    .sort((a, b) => b[1] - a[1])
    .slice(0, topFilesLength);

  topFiles.forEach(([filePath, charCount], index) => {
    const tokenCount = fileTokenCounts[filePath];
    const indexString = `${index + 1}.`.padEnd(3, ' ');
    logger.log(
      `${pc.white(`${indexString}`)} ${pc.white(filePath)} ${pc.dim(`(${charCount} chars, ${tokenCount} tokens)`)}`,
    );
  });
};

export const printCompletion = () => {
  logger.log(pc.green('🎉 All Done!'));
  logger.log(pc.white('Your repository has been successfully packed.'));
};

================
File: src/cli/cliRun.ts
================
import process from 'node:process';
import { type OptionValues, program } from 'commander';
import pc from 'picocolors';
import type { repofmOutputStyle } from '../config/configSchema.js';
import { getVersion } from '../core/file/packageJsonParse.js';
import { handleError } from '../shared/errorHandle.js';
import { logger } from '../shared/logger.js';
import { runDefaultAction } from './actions/defaultAction.js';
import { runInitAction } from './actions/initAction.js';
import { runRemoteAction } from './actions/remoteAction.js';
import { runVersionAction } from './actions/versionAction.js';

export interface CliOptions extends OptionValues {
  version?: boolean;
  output?: string;
  include?: string;
  ignore?: string;
  config?: string;
  copy?: boolean;
  verbose?: boolean;
  topFilesLen?: number;
  outputShowLineNumbers?: boolean;
  style?: repofmOutputStyle;
  init?: boolean;
  global?: boolean;
  remote?: string;
}

export async function run() {
  try {
    const version = await getVersion();

    program
      .description('repofm - Pack your repository into a single AI-friendly file')
      .arguments('[directory]')
      .option('-v, --version', 'show version information')
      .option('-o, --output <file>', 'specify the output file name')
      .option('--include <patterns>', 'list of include patterns (comma-separated)')
      .option('-i, --ignore <patterns>', 'additional ignore patterns (comma-separated)')
      .option('-c, --config <path>', 'path to a custom config file')
      .option('--copy', 'copy generated output to system clipboard')
      .option('--top-files-len <number>', 'specify the number of top files to display', Number.parseInt)
      .option('--output-show-line-numbers', 'add line numbers to each line in the output')
      .option('--style <type>', 'specify the output style (plain, xml, markdown)')
      .option('--verbose', 'enable verbose logging for detailed output')
      .option('--init', 'initialize a new repofm.config.json file')
      .option('--global', 'use global configuration (only applicable with --init)')
      .option('--remote <url>', 'process a remote Git repository')
      .action((directory = '.', options: CliOptions = {}) => executeAction(directory, process.cwd(), options));

    await program.parseAsync(process.argv);
  } catch (error) {
    handleError(error);
  }
}

const executeAction = async (directory: string, cwd: string, options: CliOptions) => {
  logger.setVerbose(options.verbose || false);

  if (options.version) {
    await runVersionAction();
    return;
  }

  const version = await getVersion();
  logger.log(pc.dim(`\n📦 repofm v${version}\n`));

  if (options.init) {
    await runInitAction(cwd, options.global || false);
    return;
  }

  if (options.remote) {
    await runRemoteAction(options.remote, options);
    return;
  }

  await runDefaultAction(directory, {
    include: options.include ? options.include.split(',') : ['**/*'],
    ignore: options.ignore ? options.ignore.split(',') : [],
    output: {
      filePath: options.output || 'repofm-output.txt',
      style: options.style || 'plain',
      removeComments: false,
      removeEmptyLines: false,
      topFilesLength: options.topFilesLen || 10,
      showLineNumbers: options.outputShowLineNumbers || false,
      copyToClipboard: options.copy || false
    },
    security: {
      enableSecurityCheck: true
    }
  });
};

================
File: src/cli/cliSpinner.ts
================
import cliSpinners from 'cli-spinners';
import logUpdate from 'log-update';
import pc from 'picocolors';

class Spinner {
  private spinner = cliSpinners.dots;
  private message: string;
  private currentFrame = 0;
  private interval: ReturnType<typeof setInterval> | null = null;

  constructor(message: string) {
    this.message = message;
  }

  start(): void {
    const frames = this.spinner.frames;
    const framesLength = frames.length;
    this.interval = setInterval(() => {
      this.currentFrame++;
      const frame = frames[this.currentFrame % framesLength];
      logUpdate(`${pc.cyan(frame)} ${this.message}`);
    }, this.spinner.interval);
  }

  update(message: string): void {
    this.message = message;
  }

  stop(finalMessage: string): void {
    if (this.interval) {
      clearInterval(this.interval);
      this.interval = null;
    }
    logUpdate(finalMessage);
    logUpdate.done();
  }

  succeed(message: string): void {
    this.stop(`${pc.green('✔')} ${message}`);
  }

  fail(message: string): void {
    this.stop(`${pc.red('✖')} ${message}`);
  }
}

export default Spinner;

================
File: src/config/configLoad.ts
================
import * as fs from 'node:fs/promises';
import path from 'node:path';
import { z } from 'zod';
import { repofmError, rethrowValidationErrorIfZodError } from '../shared/errorHandle.js';
import { logger } from '../shared/logger.js';
import {
  type repofmConfigCli,
  type repofmConfigFile,
  type repofmConfigMerged,
  defaultConfig,
  defaultFilePathMap,
  repofmConfigFileSchema,
  repofmConfigMergedSchema,
} from './configSchema.js';
import { getGlobalDirectory } from './globalDirectory.js';

const defaultConfigPath = 'repofm.config.json';

const getGlobalConfigPath = () => {
  return path.join(getGlobalDirectory(), 'repofm.config.json');
};

export const loadFileConfig = async (rootDir: string, argConfigPath: string | null): Promise<repofmConfigFile> => {
  let useDefaultConfig = false;
  let configPath = argConfigPath;
  if (!configPath) {
    useDefaultConfig = true;
    configPath = defaultConfigPath;
  }

  const fullPath = path.resolve(rootDir, configPath);

  logger.trace('Loading local config from:', fullPath);

  // Check local file existence
  const isLocalFileExists = await fs
    .stat(fullPath)
    .then((stats) => stats.isFile())
    .catch(() => false);

  if (isLocalFileExists) {
    return await loadAndValidateConfig(fullPath);
  }

  if (useDefaultConfig) {
    // Try to load global config
    const globalConfigPath = getGlobalConfigPath();
    logger.trace('Loading global config from:', globalConfigPath);

    const isGlobalFileExists = await fs
      .stat(globalConfigPath)
      .then((stats) => stats.isFile())
      .catch(() => false);

    if (isGlobalFileExists) {
      return await loadAndValidateConfig(globalConfigPath);
    }

    logger.note(
      `No custom config found at ${configPath} or global config at ${globalConfigPath}.\nYou can add a config file for additional settings. Please check https://github.com/chenxingqiang/repofm for more information.`,
    );
    return {};
  }
  throw new repofmError(`Config file not found at ${configPath}`);
};

const loadAndValidateConfig = async (filePath: string): Promise<repofmConfigFile> => {
  try {
    const fileContent = await fs.readFile(filePath, 'utf-8');
    const config = JSON.parse(fileContent);
    return repofmConfigFileSchema.parse(config);
  } catch (error) {
    rethrowValidationErrorIfZodError(error, 'Invalid config schema');
    if (error instanceof SyntaxError) {
      throw new repofmError(`Invalid JSON in config file ${filePath}: ${error.message}`);
    }
    if (error instanceof Error) {
      throw new repofmError(`Error loading config from ${filePath}: ${error.message}`);
    }
    throw new repofmError(`Error loading config from ${filePath}`);
  }
};

export const mergeConfigs = (
  cwd: string,
  fileConfig: repofmConfigFile,
  cliConfig: repofmConfigCli,
): repofmConfigMerged => {
  logger.trace('Default config:', defaultConfig);

  const baseConfig = defaultConfig;

  // If the output file path is not provided in the config file or CLI, use the default file path for the style
  if (cliConfig.output?.filePath == null && fileConfig.output?.filePath == null) {
    const style = cliConfig.output?.style || fileConfig.output?.style || baseConfig.output.style;
    baseConfig.output.filePath = defaultFilePathMap[style];

    logger.trace('Default output file path is set to:', baseConfig.output.filePath);
  }

  const mergedConfig = {
    cwd,
    output: {
      ...baseConfig.output,
      ...fileConfig.output,
      ...cliConfig.output,
    },
    include: [...(baseConfig.include || []), ...(fileConfig.include || []), ...(cliConfig.include || [])],
    ignore: {
      ...baseConfig.ignore,
      ...fileConfig.ignore,
      ...cliConfig.ignore,
      customPatterns: [
        ...(baseConfig.ignore.customPatterns || []),
        ...(fileConfig.ignore?.customPatterns || []),
        ...(cliConfig.ignore?.customPatterns || []),
      ],
    },
    security: {
      ...baseConfig.security,
      ...fileConfig.security,
      ...cliConfig.security,
    },
  };

  try {
    return repofmConfigMergedSchema.parse(mergedConfig);
  } catch (error) {
    rethrowValidationErrorIfZodError(error, 'Invalid merged config');
    throw error;
  }
};

================
File: src/config/configSchema.ts
================
import { z } from 'zod';

// Output style enum
export const repofmOutputStyleSchema = z.enum(['plain', 'xml', 'markdown']);
export type repofmOutputStyle = z.infer<typeof repofmOutputStyleSchema>;

// Default values map
export const defaultFilePathMap: Record<repofmOutputStyle, string> = {
  plain: 'repofm-output.txt',
  markdown: 'repofm-output.md',
  xml: 'repofm-output.xml',
} as const;

// Base config schema
export const repofmConfigBaseSchema = z.object({
  output: z
    .object({
      filePath: z.string().optional(),
      style: repofmOutputStyleSchema.optional(),
      headerText: z.string().optional(),
      instructionFilePath: z.string().optional(),
      removeComments: z.boolean().optional(),
      removeEmptyLines: z.boolean().optional(),
      topFilesLength: z.number().optional(),
      showLineNumbers: z.boolean().optional(),
      copyToClipboard: z.boolean().optional(),
    })
    .optional(),
  include: z.array(z.string()).optional(),
  ignore: z
    .object({
      useGitignore: z.boolean().optional(),
      useDefaultPatterns: z.boolean().optional(),
      customPatterns: z.array(z.string()).optional(),
    })
    .optional(),
  security: z
    .object({
      enableSecurityCheck: z.boolean().optional(),
    })
    .optional(),
});

// Default config schema with default values
export const repofmConfigDefaultSchema = z.object({
  output: z
    .object({
      filePath: z.string().default(defaultFilePathMap.plain),
      style: repofmOutputStyleSchema.default('plain'),
      headerText: z.string().optional(),
      instructionFilePath: z.string().optional(),
      removeComments: z.boolean().default(false),
      removeEmptyLines: z.boolean().default(false),
      topFilesLength: z.number().int().min(0).default(5),
      showLineNumbers: z.boolean().default(false),
      copyToClipboard: z.boolean().default(false),
    })
    .default({}),
  include: z.array(z.string()).default([]),
  ignore: z
    .object({
      useGitignore: z.boolean().default(true),
      useDefaultPatterns: z.boolean().default(true),
      customPatterns: z.array(z.string()).default([]),
    })
    .default({}),
  security: z
    .object({
      enableSecurityCheck: z.boolean().default(true),
    })
    .default({}),
});

export const repofmConfigFileSchema = repofmConfigBaseSchema;

export const repofmConfigCliSchema = repofmConfigBaseSchema;

export const repofmConfigMergedSchema = repofmConfigDefaultSchema
  .and(repofmConfigFileSchema)
  .and(repofmConfigCliSchema)
  .and(
    z.object({
      cwd: z.string(),
    }),
  );

export type repofmConfigDefault = z.infer<typeof repofmConfigDefaultSchema>;
export type repofmConfigFile = z.infer<typeof repofmConfigFileSchema>;
export type repofmConfigCli = z.infer<typeof repofmConfigCliSchema>;
export type repofmConfigMerged = z.infer<typeof repofmConfigMergedSchema>;

export const defaultConfig = repofmConfigDefaultSchema.parse({});

================
File: src/config/defaultIgnore.ts
================
export const defaultIgnoreList = [
  // Version control
  '.git/**',
  '.hg/**',
  '.hgignore',
  '.svn/**',

  // Dependency directories
  'node_modules/**',
  '**/node_modules/**',
  'bower_components/**',
  '**/bower_components/**',
  'jspm_packages/**',
  '**/jspm_packages/**',
  'vendor/**',
  '.bundle/**',
  '.gradle/**',
  'target/**',

  // Logs
  'logs/**',
  '**/*.log',
  '**/npm-debug.log*',
  '**/yarn-debug.log*',
  '**/yarn-error.log*',

  // Runtime data
  'pids/**',
  '*.pid',
  '*.seed',
  '*.pid.lock',

  // Directory for instrumented libs generated by jscoverage/JSCover
  'lib-cov/**',

  // Coverage directory used by tools like istanbul
  'coverage/**',

  // nyc test coverage
  '.nyc_output/**',

  // Grunt intermediate storage
  '.grunt/**',

  // node-waf configuration
  '.lock-wscript',

  // Compiled binary addons
  'build/Release/**',

  // TypeScript v1 declaration files
  'typings/**',

  // Optional npm cache directory
  '**/.npm/**',

  // Optional eslint cache
  '.eslintcache',

  // Optional REPL history
  '.node_repl_history',

  // Output of 'npm pack'
  '*.tgz',

  // Yarn files
  '**/.yarn/**',

  // Yarn Integrity file
  '**/.yarn-integrity',

  // dotenv environment variables file
  '.env',

  // next.js build output
  '.next/**',

  // nuxt.js build output
  '.nuxt/**',

  // vuepress build output
  '.vuepress/dist/**',

  // Serverless directories
  '.serverless/**',

  // FuseBox cache
  '.fusebox/**',

  // DynamoDB Local files
  '.dynamodb/**',

  // TypeScript output
  'dist/**',

  // OS generated files
  '**/.DS_Store',
  '**/Thumbs.db',

  // Editor directories and files
  '.idea/**',
  '.vscode/**',
  '**/*.swp',
  '**/*.swo',
  '**/*.swn',
  '**/*.bak',

  // Package manager locks
  '**/package-lock.json',
  '**/yarn.lock',
  '**/pnpm-lock.yaml',

  // Build outputs
  'build/**',
  'out/**',

  // Temporary files
  'tmp/**',
  'temp/**',

  // repofm output
  'repofm-output.*',
  'repofm-output.*', // Legacy

  // Essential Python-related entries
  '**/__pycache__/**',
  '**/*.py[cod]',
  '**/venv/**',
  '**/.venv/**',
  '**/.pytest_cache/**',
  '**/.mypy_cache/**',
  '**/.ipynb_checkpoints/**',
  '**/Pipfile.lock',
  '**/poetry.lock',
];

================
File: src/config/globalDirectory.ts
================
import os from 'node:os';
import path from 'node:path';

export const getGlobalDirectory = () => {
  if (process.platform === 'win32') {
    const localAppData = process.env.LOCALAPPDATA || path.join(os.homedir(), 'AppData', 'Local');
    return path.join(localAppData, 'repofm');
  }

  if (process.env.XDG_CONFIG_HOME) {
    return path.join(process.env.XDG_CONFIG_HOME, 'repofm');
  }

  return path.join(os.homedir(), '.config', 'repofm');
};

================
File: src/config/loadConfig.ts
================
import dotenv from 'dotenv';
import { z } from 'zod';

// Load environment variables
dotenv.config();

export function loadConfig() {
  // Load base config
  const config = require('../repofm.config.json');

  // Inject environment variables
  return {
    ...config,
    github: {
      token: process.env.GITHUB_TOKEN || '',
    },
    supabase: {
      url: process.env.SUPABASE_URL || '',
      key: process.env.SUPABASE_KEY || '',
    }
  };
}

================
File: src/core/file/fileCollect.ts
================
import * as fs from 'node:fs/promises';
import path from 'node:path';
import iconv from 'iconv-lite';
import { isBinary } from 'istextorbinary';
import jschardet from 'jschardet';
import pMap from 'p-map';
import { logger } from '../../shared/logger.js';
import { getProcessConcurrency } from '../../shared/processConcurrency.js';
import type { RawFile } from './fileTypes.js';

export const collectFiles = async (filePaths: string[], rootDir: string): Promise<RawFile[]> => {
  const rawFiles = await pMap(
    filePaths,
    async (filePath) => {
      const fullPath = path.resolve(rootDir, filePath);
      const content = await readRawFile(fullPath);
      if (content) {
        return { path: filePath, content };
      }
      return null;
    },
    {
      concurrency: getProcessConcurrency(),
    },
  );

  return rawFiles.filter((file): file is RawFile => file != null);
};

const readRawFile = async (filePath: string): Promise<string | null> => {
  if (isBinary(filePath)) {
    logger.debug(`Skipping binary file: ${filePath}`);
    return null;
  }

  logger.trace(`Processing file: ${filePath}`);

  try {
    const buffer = await fs.readFile(filePath);

    if (isBinary(null, buffer)) {
      logger.debug(`Skipping binary file (content check): ${filePath}`);
      return null;
    }

    const encoding = jschardet.detect(buffer).encoding || 'utf-8';
    const content = iconv.decode(buffer, encoding);

    return content;
  } catch (error) {
    logger.warn(`Failed to read file: ${filePath}`, error);
    return null;
  }
};

================
File: src/core/file/fileManipulate.ts
================
import path from 'node:path';
import strip from 'strip-comments';

interface FileManipulator {
  removeComments(content: string): string;
  removeEmptyLines(content: string): string;
}

const rtrimLines = (content: string): string =>
  content
    .split('\n')
    .map((line) => line.trimEnd())
    .join('\n');

class BaseManipulator implements FileManipulator {
  removeComments(content: string): string {
    return content;
  }

  removeEmptyLines(content: string): string {
    return content
      .split('\n')
      .filter((line) => line.trim() !== '')
      .join('\n');
  }
}

class StripCommentsManipulator extends BaseManipulator {
  private language: string;

  constructor(language: string) {
    super();
    this.language = language;
  }

  removeComments(content: string): string {
    const result = strip(content, {
      language: this.language,
      preserveNewlines: true,
    });
    return rtrimLines(result);
  }
}

class PythonManipulator extends BaseManipulator {
  removeDocStrings(content: string): string {
    if (!content) return '';
    const lines = content.split('\n');

    let result = '';

    let buffer = '';
    let quoteType: '' | "'" | '"' = '';
    let tripleQuotes = 0;

    const doubleQuoteRegex = /^\s*(?<!\\)(?:""")\s*(?:\n)?[\s\S]*?(?<!("""))(?<!\\)(?:""")/gm;
    const singleQuoteRegex = /^\s*(?<!\\)(?:''')\s*(?:\n)?[\s\S]*?(?<!('''))(?<!\\)(?:''')/gm;

    const sz = lines.length;
    for (let i = 0; i < sz; i++) {
      const line = lines[i] + (i !== sz - 1 ? '\n' : '');
      buffer += line;
      if (quoteType === '') {
        const indexSingle = line.search(/(?<![\"])(?<!\\)'''(?![\"])/g);
        const indexDouble = line.search(/(?<![\'])(?<!\\)"""(?![\'])/g);
        if (indexSingle !== -1 && (indexDouble === -1 || indexSingle < indexDouble)) {
          quoteType = "'";
        } else if (indexDouble !== -1 && (indexSingle === -1 || indexDouble < indexSingle)) {
          quoteType = '"';
        }
      }
      if (quoteType === "'") {
        tripleQuotes += (line.match(/(?<![\"])(?<!\\)'''(?!["])/g) || []).length;
      }
      if (quoteType === '"') {
        tripleQuotes += (line.match(/(?<![\'])(?<!\\)"""(?![\'])/g) || []).length;
      }

      if (tripleQuotes % 2 === 0) {
        const docstringRegex = quoteType === '"' ? doubleQuoteRegex : singleQuoteRegex;
        buffer = buffer.replace(docstringRegex, '');
        result += buffer;
        buffer = '';
        tripleQuotes = 0;
        quoteType = '';
      }
    }

    result += buffer;
    return result;
  }

  removeHashComments(content: string): string {
    const searchInPairs = (pairs: [number, number][], hashIndex: number): boolean => {
      return pairs.some(([start, end]) => hashIndex > start && hashIndex < end);
    };

    let result = '';
    const pairs: [number, number][] = [];
    let prevQuote = 0;
    while (prevQuote < content.length) {
      const openingQuote = content.slice(prevQuote + 1).search(/(?<!\\)(?:"|'|'''|""")/g) + prevQuote + 1;
      if (openingQuote === prevQuote) break;

      let closingQuote = -1;
      if (content.startsWith('"""', openingQuote) || content.startsWith("'''", openingQuote)) {
        const quoteType = content.slice(openingQuote, openingQuote + 3);
        closingQuote = content.indexOf(quoteType, openingQuote + 3);
      } else {
        const quoteType = content[openingQuote];
        closingQuote = content.indexOf(quoteType, openingQuote + 1);
      }

      if (closingQuote === -1) break;
      pairs.push([openingQuote, closingQuote]);
      prevQuote = closingQuote;
    }
    let prevHash = 0;
    while (prevHash < content.length) {
      const hashIndex = content.slice(prevHash).search(/(?<!\\)#/g) + prevHash;
      if (hashIndex === prevHash - 1) {
        result += content.slice(prevHash);
        break;
      }

      const isInsideString = searchInPairs(pairs, hashIndex);
      const nextNewLine = content.indexOf('\n', hashIndex);

      if (!isInsideString) {
        if (nextNewLine === -1) {
          result += content.slice(prevHash);
          break;
        }
        result += `${content.slice(prevHash, hashIndex)}\n`;
      } else {
        if (nextNewLine === -1) {
          result += content.slice(prevHash);
          break;
        }
        result += `${content.slice(prevHash, nextNewLine)}\n`;
      }

      prevHash = nextNewLine + 1;
    }
    return result;
  }

  removeComments(content: string): string {
    let result = this.removeDocStrings(content);
    result = this.removeHashComments(result);
    return rtrimLines(result);
  }
}

class CompositeManipulator extends BaseManipulator {
  private manipulators: FileManipulator[];

  constructor(...manipulators: FileManipulator[]) {
    super();
    this.manipulators = manipulators;
  }

  removeComments(content: string): string {
    return this.manipulators.reduce((acc, manipulator) => manipulator.removeComments(acc), content);
  }
}

const manipulators: Record<string, FileManipulator> = {
  '.c': new StripCommentsManipulator('c'),
  '.cs': new StripCommentsManipulator('csharp'),
  '.css': new StripCommentsManipulator('css'),
  '.dart': new StripCommentsManipulator('c'),
  '.go': new StripCommentsManipulator('c'),
  '.html': new StripCommentsManipulator('html'),
  '.java': new StripCommentsManipulator('java'),
  '.js': new StripCommentsManipulator('javascript'),
  '.jsx': new StripCommentsManipulator('javascript'),
  '.kt': new StripCommentsManipulator('c'),
  '.less': new StripCommentsManipulator('less'),
  '.php': new StripCommentsManipulator('php'),
  '.rb': new StripCommentsManipulator('ruby'),
  '.rs': new StripCommentsManipulator('c'),
  '.sass': new StripCommentsManipulator('sass'),
  '.scss': new StripCommentsManipulator('sass'),
  '.sh': new StripCommentsManipulator('perl'),
  '.sql': new StripCommentsManipulator('sql'),
  '.swift': new StripCommentsManipulator('swift'),
  '.ts': new StripCommentsManipulator('javascript'),
  '.tsx': new StripCommentsManipulator('javascript'),
  '.xml': new StripCommentsManipulator('xml'),
  '.yaml': new StripCommentsManipulator('perl'),
  '.yml': new StripCommentsManipulator('perl'),

  '.py': new PythonManipulator(),

  '.vue': new CompositeManipulator(
    new StripCommentsManipulator('html'),
    new StripCommentsManipulator('css'),
    new StripCommentsManipulator('javascript'),
  ),
  '.svelte': new CompositeManipulator(
    new StripCommentsManipulator('html'),
    new StripCommentsManipulator('css'),
    new StripCommentsManipulator('javascript'),
  ),
};

export const getFileManipulator = (filePath: string): FileManipulator | null => {
  const ext = path.extname(filePath);
  return manipulators[ext] || null;
};

================
File: src/core/file/filePathSort.ts
================
import path from 'node:path';

export const sortPaths = (filePaths: string[]): string[] =>
  filePaths.sort((a, b) => {
    const partsA = a.split(path.sep);
    const partsB = b.split(path.sep);

    for (let i = 0; i < Math.min(partsA.length, partsB.length); i++) {
      if (partsA[i] !== partsB[i]) {
        const isLastA = i === partsA.length - 1;
        const isLastB = i === partsB.length - 1;

        if (!isLastA && isLastB) return -1; // Directory
        if (isLastA && !isLastB) return 1; // File

        return partsA[i].localeCompare(partsB[i]); // Alphabetical order
      }
    }

    // Sort by length if all parts are equal
    return partsA.length - partsB.length;
  });

================
File: src/core/file/fileProcess.ts
================
import pMap from 'p-map';
import type { repofmConfigMerged } from '../../config/configSchema.js';
import { getProcessConcurrency } from '../../shared/processConcurrency.js';
import { getFileManipulator } from './fileManipulate.js';
import type { ProcessedFile, RawFile } from './fileTypes.js';

export const processFiles = async (rawFiles: RawFile[], config: repofmConfigMerged): Promise<ProcessedFile[]> => {
  return pMap(
    rawFiles,
    async (rawFile) => ({
      path: rawFile.path,
      content: await processContent(rawFile.content, rawFile.path, config),
    }),
    {
      concurrency: getProcessConcurrency(),
    },
  );
};

export const processContent = async (
  content: string,
  filePath: string,
  config: repofmConfigMerged,
): Promise<string> => {
  let processedContent = content;
  const manipulator = getFileManipulator(filePath);

  if (config.output.removeComments && manipulator) {
    processedContent = manipulator.removeComments(processedContent);
  }

  if (config.output.removeEmptyLines && manipulator) {
    processedContent = manipulator.removeEmptyLines(processedContent);
  }

  processedContent = processedContent.trim();

  if (config.output.showLineNumbers) {
    const lines = processedContent.split('\n');
    const padding = lines.length.toString().length;
    const numberedLines = lines.map((line, index) => `${(index + 1).toString().padStart(padding)}: ${line}`);
    processedContent = numberedLines.join('\n');
  }

  return processedContent;
};

================
File: src/core/file/fileSearch.ts
================
import { glob } from 'glob';
import * as fs from 'node:fs/promises';
import * as path from 'node:path';
import type { repofmConfigMerged } from '../../config/configSchema.js';
import { defaultIgnoreList } from '../../config/defaultIgnore.js';
import { logger } from '../../shared/logger.js';
import { sortPaths } from './filePathSort.js';
import { PermissionError, checkDirectoryPermissions } from './permissionCheck.js';

export interface SearchConfig {
  patterns?: string[];
  ignore?: {
    patterns?: string[];
    useGitignore?: boolean;
    useDefaultPatterns?: boolean;
    customPatterns?: string[];
  };
  followSymlinks?: boolean;
  dot?: boolean;
}

export const searchFiles = async (rootDir: string, config: SearchConfig): Promise<string[]> => {
  try {
    // Prepare ignore patterns
    let ignorePatterns = [
      ...(config.ignore?.patterns || []),
      ...(config.ignore?.customPatterns || [])
    ];

    // Add .gitignore patterns if enabled
    if (config.ignore?.useGitignore) {
      try {
        const gitignorePath = path.join(rootDir, '.gitignore');
        const gitignoreContent = await fs.readFile(gitignorePath, 'utf-8');
        const gitignorePatterns = gitignoreContent
          .split('\n')
          .filter(line => line && !line.startsWith('#'));
        ignorePatterns = [...ignorePatterns, ...gitignorePatterns];
      } catch {
        // .gitignore not found or not readable - continue without it
      }
    }

    const files = await glob(config.patterns || ['**/*'], {
      ignore: ignorePatterns,
      dot: config.dot,
      follow: config.followSymlinks,
      cwd: rootDir,
    });

    // Filter out directories and verify file access
    const validFiles = await Promise.all(
      files.map(async (file: string) => {
        try {
          await fs.access(path.join(rootDir, file));
          return file;
        } catch {
          return null;
        }
      })
    );

    return validFiles.filter((file): file is string => file !== null);
  } catch (error) {
    throw error;
  }
};

export const parseIgnoreContent = (content: string): string[] => {
  if (!content) return [];

  return content.split('\n').reduce<string[]>((acc, line) => {
    const trimmedLine = line.trim();
    if (trimmedLine && !trimmedLine.startsWith('#')) {
      acc.push(trimmedLine);
    }
    return acc;
  }, []);
};

export const getIgnoreFilePatterns = async (config: repofmConfigMerged): Promise<string[]> => {
  const ignoreFilePatterns: string[] = [];

  if (config.ignore.useGitignore) {
    ignoreFilePatterns.push('**/.gitignore');
  }

  ignoreFilePatterns.push('**/.repofmignore');

  return ignoreFilePatterns;
};

export const getIgnorePatterns = async (rootDir: string, config: repofmConfigMerged): Promise<string[]> => {
  const ignorePatterns = new Set<string>();

  // Add default ignore patterns
  if (config.ignore.useDefaultPatterns) {
    logger.trace('Adding default ignore patterns');
    for (const pattern of defaultIgnoreList) {
      ignorePatterns.add(pattern);
    }
  }

  // Add repofm output file
  if (config.output.filePath) {
    logger.trace('Adding output file to ignore patterns:', config.output.filePath);
    ignorePatterns.add(config.output.filePath);
  }

  // Add custom ignore patterns
  if (config.ignore.customPatterns) {
    logger.trace('Adding custom ignore patterns:', config.ignore.customPatterns);
    for (const pattern of config.ignore.customPatterns) {
      ignorePatterns.add(pattern);
    }
  }

  return Array.from(ignorePatterns);
};

================
File: src/core/file/fileTreeGenerate.ts
================
import path from 'node:path';

interface TreeNode {
  name: string;
  children: TreeNode[];
  isDirectory: boolean;
}

const createTreeNode = (name: string, isDirectory: boolean): TreeNode => ({ name, children: [], isDirectory });

export const generateFileTree = (files: string[]): TreeNode => {
  const root: TreeNode = createTreeNode('root', true);

  for (const file of files) {
    const parts = file.split(path.sep);
    let currentNode = root;

    for (let i = 0; i < parts.length; i++) {
      const part = parts[i];
      const isLastPart = i === parts.length - 1;
      let child = currentNode.children.find((c) => c.name === part);

      if (!child) {
        const isDirectory = !isLastPart || part.endsWith('/');
        child = createTreeNode(part, isDirectory);
        currentNode.children.push(child);
      }

      currentNode = child;
    }
  }

  return root;
};

export const generateTreeString = (files: string[]): string => {
  const tree: Record<string, boolean> = {};

  files.forEach(file => {
    const parts = file.split('/');
    let current = '';

    for (let i = 0; i < parts.length; i++) {
      const part = parts[i];
      if (!part) continue;

      const path = current ? `${current}/${part}` : part;
      const isDirectory = i < parts.length - 1 || file.endsWith('/');

      tree[path] = isDirectory;
      current = path;
    }
  });

  const buildString = (prefix = ''): string => {
    const entries = Object.entries(tree)
      .filter(([path]) => {
        const parentPath = path.split('/').slice(0, -1).join('/');
        return !parentPath || tree[parentPath];
      })
      .map(([path, isDir]) => ({
        name: path.split('/').pop()!,
        path,
        isDirectory: isDir
      }));

    entries.sort((a, b) => {
      if (a.isDirectory !== b.isDirectory) {
        return a.isDirectory ? -1 : 1;
      }
      return a.name.localeCompare(b.name);
    });

    return entries
      .filter(entry => {
        const parentPath = entry.path.split('/').slice(0, -1).join('/');
        return !parentPath || prefix;
      })
      .map(entry => {
        const line = `${prefix}${entry.name}${entry.isDirectory ? '/' : ''}`;
        if (entry.isDirectory) {
          const nextPrefix = `${prefix}  `;
          const children = buildString(nextPrefix);
          return children ? `${line}\n${children}` : line;
        }
        return line;
      })
      .join('\n');
  };

  const result = buildString();
  return result || '';
};

================
File: src/core/file/fileTypes.ts
================
export interface RawFile {
  path: string;
  content: string;
}

export interface ProcessedFile {
  path: string;
  content: string;
}

================
File: src/core/file/packageJsonParse.ts
================
import * as fs from 'node:fs/promises';
import * as path from 'node:path';
import { fileURLToPath } from 'node:url';
import { logger } from '../../utils/logger.js';

let cachedVersion: string | null = null;

export const getPackageVersion = async (pkgPath: string): Promise<string> => {
  if (cachedVersion !== null) {
    return cachedVersion;
  }

  try {
    const content = await fs.readFile(pkgPath, 'utf-8');
    const pkg = JSON.parse(content);

    if (pkg.version === undefined) {
      logger.warn('Version field not found in package.json');
      cachedVersion = 'unknown';
      return 'unknown';
}

    // Return raw version string without validation
    cachedVersion = String(pkg.version);
    return cachedVersion;
  } catch (error: unknown) {
    if (error instanceof Error) {
      if ('code' in error && error.code === 'ENOENT') {
        logger.warn('Package.json not found');
      } else if ('code' in error && error.code === 'EACCES') {
        logger.error('Permission denied accessing package.json');
      } else {
        logger.error('Error reading package.json:', error);
      }
    }
    cachedVersion = 'unknown';
    return 'unknown';
  }
};

export const getPackageJsonPath = (): string => {
  const dirName = fileURLToPath(new URL('.', import.meta.url));
  return path.resolve(dirName, '../../../package.json');
};

export const getVersion = async (): Promise<string> => {
  const pkgPath = getPackageJsonPath();
  return getPackageVersion(pkgPath);
};

export const clearVersionCache = (): void => {
  cachedVersion = null;
};

================
File: src/core/file/permissionCheck.ts
================
import { constants } from 'node:fs';
import * as fs from 'node:fs/promises';
import { platform } from 'node:os';
import { logger } from '../../shared/logger.js';

export interface PermissionCheckResult {
  hasPermission: boolean;
  error?: Error;
  details?: {
    read?: boolean;
    write?: boolean;
    execute?: boolean;
  };
}

export class PermissionError extends Error {
  constructor(
    message: string,
    public readonly path: string,
    public readonly code?: string,
  ) {
    super(message);
    this.name = 'PermissionError';
  }
}

export async function checkDirectoryPermissions(dirPath: string): Promise<PermissionCheckResult> {
  try {
    // First try to read directory contents
    await fs.readdir(dirPath);

    // Check specific permissions
    const details = {
      read: false,
      write: false,
      execute: false,
    };

    try {
      await fs.access(dirPath, constants.R_OK);
      details.read = true;
    } catch {}

    try {
      await fs.access(dirPath, constants.W_OK);
      details.write = true;
    } catch {}

    try {
      await fs.access(dirPath, constants.X_OK);
      details.execute = true;
    } catch {}

    const hasAllPermissions = details.read && details.write && details.execute;

    if (!hasAllPermissions) {
      return {
        hasPermission: false,
        details,
      };
    }

    return {
      hasPermission: true,
      details,
    };
  } catch (error) {
    if (error instanceof Error && 'code' in error) {
      switch (error.code) {
        case 'EPERM':
        case 'EACCES':
        case 'EISDIR':
          return {
            hasPermission: false,
            error: new PermissionError(getMacOSPermissionMessage(dirPath, error.code), dirPath, error.code),
          };
        default:
          logger.debug('Directory permission check error:', error);
          return {
            hasPermission: false,
            error: error as Error,
          };
      }
    }
    return {
      hasPermission: false,
      error: error instanceof Error ? error : new Error(String(error)),
    };
  }
}

function getMacOSPermissionMessage(dirPath: string, errorCode?: string): string {
  if (platform() === 'darwin') {
    return `Permission denied: Cannot access '${dirPath}', error code: ${errorCode}.

This error often occurs when macOS security restrictions prevent access to the directory.
To fix this:

1. Open System Settings
2. Navigate to Privacy & Security > Files and Folders
3. Find your terminal app (Terminal.app, iTerm2, VS Code, etc.)
4. Grant necessary folder access permissions

If your terminal app is not listed:
- Try running repofm command again
- When prompted by macOS, click "Allow"
- Restart your terminal app if needed
`;
  }

  return `Permission denied: Cannot access '${dirPath}'`;
}

================
File: src/core/output/outputStyles/markdownStyle.ts
================
import Handlebars from 'handlebars';

export const getMarkdownTemplate = () => {
  return /* md */ `
{{{generationHeader}}}

# File Summary

## Purpose
{{{summaryPurpose}}}

## File Format
{{{summaryFileFormat}}}
4. Multiple file entries, each consisting of:
  a. A header with the file path (## File: path/to/file)
  b. The full contents of the file in a code block

## Usage Guidelines
{{{summaryUsageGuidelines}}}

## Notes
{{{summaryNotes}}}

## Additional Info
{{#if headerText}}
### User Provided Header
{{{headerText}}}
{{/if}}

{{{summaryAdditionalInfo}}}

# Repository Structure
\`\`\`
{{{treeString}}}
\`\`\`

# Repository Files

{{#each processedFiles}}
## File: {{{this.path}}}
\`\`\`{{{getFileExtension this.path}}}
{{{this.content}}}
\`\`\`

{{/each}}

{{#if instruction}}
# Instruction
{{{instruction}}}
{{/if}}
`;
};

Handlebars.registerHelper('getFileExtension', (filePath) => {
  const extension = filePath.split('.').pop()?.toLowerCase();
  switch (extension) {
    case 'js':
    case 'jsx':
      return 'javascript';
    case 'ts':
    case 'tsx':
      return 'typescript';
    case 'vue':
      return 'vue';
    case 'py':
      return 'python';
    case 'rb':
      return 'ruby';
    case 'java':
      return 'java';
    case 'c':
    case 'cpp':
      return 'cpp';
    case 'cs':
      return 'csharp';
    case 'go':
      return 'go';
    case 'rs':
      return 'rust';
    case 'php':
      return 'php';
    case 'swift':
      return 'swift';
    case 'kt':
      return 'kotlin';
    case 'scala':
      return 'scala';
    case 'html':
      return 'html';
    case 'css':
      return 'css';
    case 'scss':
    case 'sass':
      return 'scss';
    case 'json':
      return 'json';
    case 'json5':
      return 'json5';
    case 'xml':
      return 'xml';
    case 'yaml':
    case 'yml':
      return 'yaml';
    case 'md':
      return 'markdown';
    case 'sh':
    case 'bash':
      return 'bash';
    case 'sql':
      return 'sql';
    case 'dockerfile':
      return 'dockerfile';
    case 'dart':
      return 'dart';
    case 'fs':
    case 'fsx':
      return 'fsharp';
    case 'r':
      return 'r';
    case 'pl':
    case 'pm':
      return 'perl';
    case 'lua':
      return 'lua';
    case 'groovy':
      return 'groovy';
    case 'hs':
      return 'haskell';
    case 'ex':
    case 'exs':
      return 'elixir';
    case 'erl':
      return 'erlang';
    case 'clj':
    case 'cljs':
      return 'clojure';
    case 'ps1':
      return 'powershell';
    case 'vb':
      return 'vb';
    case 'coffee':
      return 'coffeescript';
    case 'tf':
    case 'tfvars':
      return 'hcl';
    case 'proto':
      return 'protobuf';
    case 'pug':
      return 'pug';
    case 'graphql':
    case 'gql':
      return 'graphql';
    case 'toml':
      return 'toml';
    default:
      return '';
  }
});

================
File: src/core/output/outputStyles/plainStyle.ts
================
const PLAIN_SEPARATOR = '='.repeat(16);
const PLAIN_LONG_SEPARATOR = '='.repeat(64);

export const getPlainTemplate = () => {
  return `
{{{generationHeader}}}

${PLAIN_LONG_SEPARATOR}
File Summary
${PLAIN_LONG_SEPARATOR}

Purpose:
--------
{{{summaryPurpose}}}

File Format:
------------
{{{summaryFileFormat}}}
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
{{{summaryUsageGuidelines}}}

Notes:
------
{{{summaryNotes}}}

Additional Info:
----------------
{{#if headerText}}
User Provided Header:
-----------------------
{{{headerText}}}
{{/if}}

{{{summaryAdditionalInfo}}}

${PLAIN_LONG_SEPARATOR}
Repository Structure
${PLAIN_LONG_SEPARATOR}
{{{treeString}}}

${PLAIN_LONG_SEPARATOR}
Repository Files
${PLAIN_LONG_SEPARATOR}

{{#each processedFiles}}
${PLAIN_SEPARATOR}
File: {{{this.path}}}
${PLAIN_SEPARATOR}
{{{this.content}}}

{{/each}}

{{#if instruction}}
${PLAIN_LONG_SEPARATOR}
Instruction
${PLAIN_LONG_SEPARATOR}
{{{instruction}}}
{{/if}}

`;
};

================
File: src/core/output/outputStyles/xmlStyle.ts
================
export const getXmlTemplate = () => {
  return /* xml */ `
{{{generationHeader}}}

<file_summary>
This section contains a summary of this file.

<purpose>
{{{summaryPurpose}}}
</purpose>

<file_format>
{{{summaryFileFormat}}}
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
{{{summaryUsageGuidelines}}}
</usage_guidelines>

<notes>
{{{summaryNotes}}}
</notes>

<additional_info>
{{#if headerText}}
<user_provided_header>
{{{headerText}}}
</user_provided_header>
{{/if}}

{{{summaryAdditionalInfo}}}
</additional_info>

</file_summary>

<repository_structure>
{{{treeString}}}
</repository_structure>

<repository_files>
This section contains the contents of the repository's files.

{{#each processedFiles}}
<file path="{{{this.path}}}">
{{{this.content}}}
</file>

{{/each}}
</repository_files>

{{#if instruction}}
<instruction>
{{{instruction}}}
</instruction>
{{/if}}
`;
};

================
File: src/core/output/outputGenerate.ts
================
import fs from 'node:fs/promises';
import path from 'node:path';
import type { Config } from '../../types/config.js';
import { repofmError } from '../../shared/errorHandle.js';
import { generateTreeString } from '../file/fileTreeGenerate.js';
import type { OutputGeneratorContext } from './outputGeneratorTypes.js';
import { escapeHtml } from '../../utils/stringUtils.js';

const LANGUAGE_MAP: Record<string, string> = {
  'js': 'javascript',
  'jsx': 'javascript',
  'ts': 'typescript',
  'tsx': 'typescript',
  'md': 'markdown',
  'py': 'python',
  // Add more mappings as needed
};

export const buildOutputGeneratorContext = async (
  rootDir: string,
  config: Config,
  allPaths: string[],
  processedFiles: Array<{ path: string; content: string }> = []
): Promise<OutputGeneratorContext> => {
  let instruction = '';
  if (config.output.instructionFilePath) {
    try {
      instruction = await fs.readFile(config.output.instructionFilePath, 'utf8');
    } catch (error) {
      if (error instanceof Error) {
        throw new repofmError(`Failed to read instruction file: ${error.message}`);
      } else {
        throw new repofmError(`Failed to read instruction file: Unknown error occurred`);
      }
    }
  }

  // Get unique directories from file paths
  const directories = Array.from(new Set(
    allPaths.map(filePath => path.dirname(filePath))
      .filter(dir => dir !== '.')
      .sort()
  ));

  return {
    config,
    instruction,
    processedFiles,
    directories,
    rootDir
  };
};

export const generateOutput = async (
  rootDir: string,
  config: Config,
  files: Array<{ path: string; content: string }>,
  specialFiles: string[] = []
): Promise<string> => {
  const context = await buildOutputGeneratorContext(rootDir, config, specialFiles, files);
  let output = '';

  // Add header sections based on style
  switch (config.output.style) {
    case 'markdown':
      output += '# File Summary\n\n';
      if (context.instruction) {
        output += `${context.instruction}\n\n`;
      }
      output += '# Repository Structure\n\n';
      for (const dir of context.directories) {
        output += `- ${dir}/\n`;
      }
      output += '\n';
      if (config.output.headerText) {
        output += `# ${config.output.headerText}\n\n`;
      }
      output += '# Repository Files\n\n';
      break;
    case 'xml':
      output += '<?xml version="1.0" encoding="UTF-8"?>\n';
      output += '<file_summary>\n';
      if (context.instruction) {
        output += `  <instructions>${escapeHtml(context.instruction)}</instructions>\n`;
      }
      output += '  <repository_structure>\n';
      for (const dir of context.directories) {
        output += `    <directory>${escapeHtml(dir)}</directory>\n`;
      }
      if (config.output.headerText) {
        output += `    <header>${escapeHtml(config.output.headerText)}</header>\n`;
      }
      output += '  </repository_structure>\n';
      output += '  <repository_files>\n';
      break;
    default: // plain
      output += 'File Summary\n\n';
      if (context.instruction) {
        output += `${context.instruction}\n\n`;
      }
      output += 'Repository Structure\n\n';
      for (const dir of context.directories) {
        output += `${dir}/\n`;
      }
      output += '\n';
      if (config.output.headerText) {
        output += `${config.output.headerText}\n\n`;
      }
      output += 'Repository Files\n\n';
  }

  // Process files
  for (const file of files) {
    const isSpecial = specialFiles.includes(file.path);
    let content = file.content;
    const filePath = file.path;

    switch (config.output.style) {
      case 'markdown':
        output += `## File: ${filePath}\n\n`;
        const extension = path.extname(filePath).slice(1);
        const language = LANGUAGE_MAP[extension] || extension;
        output += '```' + language + '\n' + content + '\n```\n\n';
        break;
      case 'xml':
        output += `    <file path="${escapeHtml(filePath)}">\n`;
        output += `      <content>${escapeHtml(content)}</content>\n`;
        output += '    </file>\n';
        break;
      default:
        output += `File: ${filePath}\n${content}\n\n`;
    }
  }

  // Close sections based on style
  if (config.output.style === 'xml') {
    output += '  </repository_files>\n';
    output += '</file_summary>\n';
  }

  return output;
};

================
File: src/core/output/outputGeneratorTypes.ts
================
import type { repofmConfigMerged } from '../../config/configSchema.js';
import type { ProcessedFile } from '../file/fileTypes.js';
import type { Config } from '../../types/config.js';

export interface OutputGeneratorContext {
  config: Config;
  instruction: string;
  processedFiles: Array<{ path: string; content: string }>;
  directories: string[];
  rootDir: string;
}

================
File: src/core/output/outputStyleDecorate.ts
================
import type { repofmConfigMerged } from '../../config/configSchema.js';

export const generateHeader = (generationDate: string): string => {
  return `
This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by repofm on: ${generationDate}
`.trim();
};

export const generateSummaryPurpose = (): string => {
  return `
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
`.trim();
};

export const generateSummaryFileFormat = (): string => {
  return `
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
`.trim();
};

export const generateSummaryUsageGuidelines = (config: repofmConfigMerged, repositoryInstruction: string): string => {
  return `
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
${config.output.headerText ? '- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.' : ''}
${repositoryInstruction ? '- Pay special attention to the Repository Instruction. These contain important context and guidelines specific to this project.' : ''}
`.trim();
};

export const generateSummaryNotes = (config: repofmConfigMerged): string => {
  return `
- Some files may have been excluded based on .gitignore rules and repofm's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
${config.output.removeComments ? '- Code comments have been removed.\n' : ''}
${config.output.showLineNumbers ? '- Line numbers have been added to the beginning of each line.\n' : ''}
`.trim();
};

export const generateSummaryAdditionalInfo = (): string => {
  return `
For more information about repofm, visit: https://github.com/chenxingqiang/repofm
`.trim();
};

================
File: src/core/security/securityCheck.ts
================
import { logger } from '../../shared/logger.js';

interface SecurityResult {
  filePath: string;
  messages: string[];
}

export interface SuspiciousFileResult {
  filePath: string;
  messages: string[];
}

export const runSecurityCheck = async (files: Array<{ path: string; content: string }>): Promise<SuspiciousFileResult[]> => {
  const results: SecurityResult[] = [];

  for (const file of files) {
    const issues = await runSecretLint(file.path, file.content);
    if (issues.messages.length > 0) {
      results.push({
        filePath: file.path,
        messages: issues.messages
      });
    }
  }

  return results;
};

export async function runSecretLint(filePath: string, content: string, config = {}): Promise<{ messages: string[] }> {
  const messages: string[] = [];

  try {
    // 检查 API 密钥
    if (/api[_-]?key|api[_-]?secret/i.test(content)) {
      messages.push('Potential API key/secret detected');
    }

    // 检查 AWS 凭证
    if (/aws[_-]?access[_-]?key|aws[_-]?secret/i.test(content)) {
      messages.push('AWS credentials detected');
    }

    // 检查私钥
    if (/BEGIN (?:RSA |DSA )?PRIVATE KEY/.test(content)) {
      messages.push('Private key detected');
    }

    // 检查密码
    if (/password\s*=\s*['"][^'"]+['"]/.test(content)) {
      messages.push('Hardcoded password detected');
    }

    // 检查其他敏感信息
    const sensitivePatterns = [
      /token\s*=\s*['"][^'"]+['"]/,
      /secret\s*=\s*['"][^'"]+['"]/,
      /credentials?\s*=\s*['"][^'"]+['"]/
    ];

    for (const pattern of sensitivePatterns) {
      if (pattern.test(content)) {
        messages.push('Sensitive information detected');
      }
    }

  } catch (error) {
    logger.warn(`Error checking file ${filePath}:`, error);
    messages.push('Error during security check');
  }

  return { messages };
}

================
File: src/core/tokenCount/tokenCount.ts
================
import { type Tiktoken, get_encoding } from 'tiktoken';
import { logger } from '../../shared/logger.js';

export class TokenCounter {
  private encoding: Tiktoken;

  constructor() {
    try {
      this.encoding = get_encoding('cl100k_base');
    } catch (error) {
      logger.error('Failed to initialize token counter:', error);
      throw error;
    }
  }

  public countTokens(content: string | unknown): number {
    try {
      if (typeof content !== 'string') {
        logger.warn(`Invalid input type: ${typeof content}, expected string`);
        return 0;
      }

      if (!content) {
        return 0;
      }

      const normalizedContent = content
        .replace(/\r\n/g, '\n')
        .replace(/\r/g, '\n');

      const trimmedContent = normalizedContent
        .split('\n')
        .filter(line => line.trim().length > 0)
        .join('\n');

      try {
        const tokens = this.encoding.encode(trimmedContent);
        return tokens.length;
      } catch (encodingError) {
        logger.warn('Tiktoken encoding failed, using fallback method:', encodingError);
        return this.fallbackTokenCount(trimmedContent);
      }

    } catch (error) {
      logger.warn('Error counting tokens:', error);
      return this.fallbackTokenCount(String(content));
    }
  }

  private fallbackTokenCount(text: string): number {
    return text
      .split(/[\s\n]+/)
      .filter(token => token.length > 0)
      .length;
  }

  public free(): void {
    try {
      this.encoding.free();
    } catch (error) {
      logger.warn('Error while freeing token counter:', error);
    }
  }
}

================
File: src/core/tokenCount/TokenCounter.ts
================
class TokenCounter {
    countTokens(text: string): number {
        const tokens = text.split(/\s+/);
        return tokens.length;
    }
    // ... other methods and properties of the class ...
}

================
File: src/core/packager.ts
================
import fs from 'node:fs/promises';
import path from 'node:path';
import { setTimeout } from 'node:timers/promises';
import clipboard from 'clipboardy';
import pMap from 'p-map';
import pc from 'picocolors';
import type { repofmConfigMerged } from '../config/configSchema.js';
import { logger } from '../shared/logger.js';
import { getProcessConcurrency } from '../shared/processConcurrency.js';
import type { repofmProgressCallback } from '../shared/types.js';
import { collectFiles as defaultCollectFiles } from './file/fileCollect.js';
import { processFiles as defaultProcessFiles } from './file/fileProcess.js';
import { searchFiles as defaultSearchFiles } from './file/fileSearch.js';
import { generateOutput as defaultGenerateOutput } from './output/outputGenerate.js';
import { type SuspiciousFileResult, runSecurityCheck as defaultRunSecurityCheck } from './security/securityCheck.js';
import { TokenCounter } from './tokenCount/tokenCount.js';

export interface PackDependencies {
  searchFiles: typeof defaultSearchFiles;
  collectFiles: typeof defaultCollectFiles;
  processFiles: typeof defaultProcessFiles;
  runSecurityCheck: typeof defaultRunSecurityCheck;
  generateOutput: typeof defaultGenerateOutput;
}

export interface PackResult {
  totalFiles: number;
  totalCharacters: number;
  totalTokens: number;
  fileCharCounts: Record<string, number>;
  fileTokenCounts: Record<string, number>;
  suspiciousFilesResults: SuspiciousFileResult[];
}

export const pack = async (
  rootDir: string,
  config: repofmConfigMerged,
  progressCallback: repofmProgressCallback = () => {},
  deps: PackDependencies = {
    searchFiles: defaultSearchFiles,
    collectFiles: defaultCollectFiles,
    processFiles: defaultProcessFiles,
    runSecurityCheck: defaultRunSecurityCheck,
    generateOutput: defaultGenerateOutput,
  },
): Promise<PackResult> => {
  // Get all file paths considering the config
  progressCallback('Searching for files...');
  const filePaths = await deps.searchFiles(rootDir, {
    ...config,
    ignore: {
      useGitignore: config.ignore?.useGitignore ?? true,
      useDefaultPatterns: config.ignore?.useDefaultPatterns ?? true,
      customPatterns: config.ignore?.customPatterns ?? [],
    },
  });

  // Collect raw files
  progressCallback('Collecting files...');
  const rawFiles = await deps.collectFiles(filePaths, rootDir);

  let safeRawFiles = rawFiles;
  let suspiciousFilesResults: SuspiciousFileResult[] = [];

  if (config.security.enableSecurityCheck) {
    // Perform security check and filter out suspicious files
    progressCallback('Running security check...');
    suspiciousFilesResults = await deps.runSecurityCheck(rawFiles);
    safeRawFiles = rawFiles.filter(
      (rawFile) => !suspiciousFilesResults.some((result) => result.filePath === rawFile.path),
    );
  }

  const safeFilePaths = safeRawFiles.map((file) => file.path);
  logger.trace('Safe files count:', safeRawFiles.length);

  // Process files (remove comments, etc.)
  progressCallback('Processing files...');
  const processedFiles = await deps.processFiles(safeRawFiles, config);

  // Generate output
  progressCallback('Generating output...');
  const output = await deps.generateOutput(
    rootDir,
    {
      include: config.include,
      ignore: Array.isArray(config.ignore) ? config.ignore : config.ignore.customPatterns,
      output: config.output,
      security: config.security
    },
    processedFiles,
    safeFilePaths
  );

  // Write output to file. path is relative to the cwd
  progressCallback('Writing output file...');
  const outputPath = path.resolve(config.cwd, config.output.filePath);
  logger.trace(`Writing output to: ${outputPath}`);
  await fs.writeFile(outputPath, output);

  if (config.output.copyToClipboard) {
    // Additionally copy to clipboard if flag is raised
    progressCallback('Copying to clipboard...');
    logger.trace('Copying output to clipboard');
    await clipboard.write(output);
  }

  // Setup token counter
  const tokenCounter = new TokenCounter();

  // Metrics
  progressCallback('Calculating metrics...');
  const fileMetrics = await pMap(
    processedFiles,
    async (file, index) => {
      const charCount = file.content.length;
      const tokenCount = tokenCounter.countTokens(file.content);

      progressCallback(`Calculating metrics... (${index + 1}/${processedFiles.length}) ${pc.dim(file.path)}`);

      // Sleep for a short time to prevent blocking the event loop
      await setTimeout(1);

      return { path: file.path, charCount, tokenCount };
    },
    {
      concurrency: getProcessConcurrency(),
    },
  );

  tokenCounter.free();

  const totalFiles = processedFiles.length;
  const totalCharacters = fileMetrics.reduce((sum, fileMetric) => sum + fileMetric.charCount, 0);
  const totalTokens = fileMetrics.reduce((sum, fileMetric) => sum + fileMetric.tokenCount, 0);

  const fileCharCounts: Record<string, number> = {};
  const fileTokenCounts: Record<string, number> = {};
  for (const file of fileMetrics) {
    fileCharCounts[file.path] = file.charCount;
    fileTokenCounts[file.path] = file.tokenCount;
  }

  return {
    totalFiles,
    totalCharacters,
    totalTokens,
    fileCharCounts,
    fileTokenCounts,
    suspiciousFilesResults,
  };
};

================
File: src/features/autoCommit/contentAnalyzer.js
================
// src/features/autoCommit/contentAnalyzer.js
export class ContentAnalyzer {
    constructor() {
        this.patterns = {
            security: /security|vulnerability|cve|exploit/i,
            performance: /performance|optimize|speed|memory|cpu/i,
            bugfix: /fix|bug|issue|error|crash|problem/i,
            feature: /feat|feature|add|implement|new/i,
            refactor: /refactor|restructure|clean|improve|simplify/i,
            style: /style|css|scss|less|theme|ui|layout/i,
            docs: /docs|documentation|comment|readme/i,
            test: /test|spec|coverage|assert|expect/i
        }
    }

    async analyzeContent(filePath, content) {
        const analysis = {
            type: null,
            scope: null,
            importance: 0,
            suggestions: []
        }

        // Analyze file content
        for (const [type, pattern] of Object.entries(this.patterns)) {
            if (pattern.test(content)) {
                analysis.suggestions.push(type)
            }
        }

        // Analyze file path
        for (const [type, config] of Object.entries(fileTypePatterns)) {
            if (config.pattern.test(filePath)) {
                analysis.type = type
                analysis.scope = config.scope
            }

            if (config.folders.some((folder) => filePath.includes(folder))) {
                analysis.scope = config.scope
            }

            if (config.keywords?.some((keyword) => content.includes(keyword))) {
                analysis.importance++
            }
        }

        return analysis
    }
}

================
File: src/features/autoCommit/enhancedTemplates.js
================
// src/features/autoCommit/enhancedTemplates.js
import { parse } from '@babel/parser'
import { File } from '@babel/types'
import traverse from '@babel/traverse'

export class CommitMessageGenerator {
    constructor(config = {}) {
        this.config = {
            useAI: config.useAI ?? true,
            maxContextLines: config.maxContextLines ?? 100,
            includeScope: config.includeScope ?? true,
            ...config
        }

        // Advanced template categories
        this.templateCategories = {
            feature: {
                api: {
                    template: 'feat(api): implement {} endpoint for {}',
                    keywords: ['endpoint', 'api', 'route', 'controller'],
                    files: ['controller', 'route', 'api']
                },
                ui: {
                    template: 'feat(ui): add {} component with {}',
                    keywords: ['component', 'view', 'page', 'react', 'vue'],
                    files: ['jsx', 'tsx', 'vue', 'component']
                },
                auth: {
                    template: 'feat(auth): implement {} authentication flow',
                    keywords: ['auth', 'login', 'register', 'jwt'],
                    files: ['auth', 'security']
                },
                database: {
                    template: 'feat(db): add {} model and migrations',
                    keywords: ['model', 'schema', 'migration', 'database'],
                    files: ['model', 'migration', 'schema']
                }
            },
            fix: {
                security: {
                    template: 'fix(security): patch {} vulnerability in {}',
                    keywords: ['security', 'vulnerability', 'exploit', 'cve'],
                    priority: 'high'
                },
                performance: {
                    template: 'fix(perf): optimize {} performance in {}',
                    keywords: ['performance', 'slow', 'optimization', 'speed'],
                    priority: 'medium'
                },
                validation: {
                    template: 'fix(validation): correct {} validation in {}',
                    keywords: ['validation', 'validator', 'check', 'verify'],
                    priority: 'medium'
                }
            },
            refactor: {
                architecture: {
                    template: 'refactor(arch): restructure {} implementation',
                    keywords: ['architecture', 'structure', 'pattern'],
                    scope: 'architecture'
                },
                cleanup: {
                    template: 'refactor(cleanup): improve {} code organization',
                    keywords: ['cleanup', 'organize', 'simplify'],
                    scope: 'cleanup'
                }
            }
        }
    }

    /**
     * Analyze code changes for context
     */
    async analyzeChanges(filePath, diff) {
        const analysis = {
            type: null,
            scope: null,
            details: [],
            impact: 'normal',
            relatedFiles: [],
            suggestions: []
        }

        // Parse code if it's a JavaScript/TypeScript file
        if (/\.(js|ts|jsx|tsx)$/.test(filePath)) {
            try {
                const ast = parse(diff, {
                    sourceType: 'module',
                    plugins: ['jsx', 'typescript', 'decorators-legacy']
                })

                // Analyze AST for specific changes
                traverse(ast, {
                    FunctionDeclaration(path) {
                        analysis.details.push({
                            type: 'function',
                            name: path.node.id.name,
                            isNew: true
                        })
                    },
                    ClassDeclaration(path) {
                        analysis.details.push({
                            type: 'class',
                            name: path.node.id.name,
                            isNew: true
                        })
                    },
                    ImportDeclaration(path) {
                        analysis.details.push({
                            type: 'import',
                            source: path.node.source.value
                        })
                    }
                })
            } catch (error) {
                // Fallback to basic analysis if parsing fails
                console.warn(`AST parsing failed for ${filePath}:`, error.message)
            }
        }

        return analysis
    }

    /**
     * Generate appropriate commit message based on changes
     */
    async generateMessage(filePath, diff, analysis) {
        let message = ''
        let scope = ''
        let type = ''

        // Determine the most appropriate template category
        for (const [category, templates] of Object.entries(this.templateCategories)) {
            for (const [key, config] of Object.entries(templates)) {
                if (this.matchesTemplate(diff, config.keywords) || this.matchesFilePattern(filePath, config.files)) {
                    type = category
                    scope = key
                    message = this.applyTemplate(config.template, analysis)
                    break
                }
            }
            if (message) break
        }

        // Fallback to basic template if no specific match found
        if (!message) {
            type = this.determineType(analysis)
            scope = this.determineScope(filePath)
            message = this.generateBasicMessage(type, scope, filePath)
        }

        // Add breaking change footer if necessary
        if (this.isBreakingChange(diff, analysis)) {
            message += '\n\nBREAKING CHANGE: '
            message += await this.generateBreakingChangeDescription(analysis)
        }

        return {
            type,
            scope,
            message,
            analysis
        }
    }

    /**
     * Check for breaking changes
     */
    isBreakingChange(diff, analysis) {
        const breakingPatterns = [
            /BREAKING CHANGE/i,
            /breaking-change/i,
            /incompatible/i,
            /\bapi\b.*\bchange\b/i,
            /\bremove(d)?\b.*\bapi\b/i,
            /\bdelete(d)?\b.*\bapi\b/i,
            /\bdeprecate(d)?\b/i
        ]

        return breakingPatterns.some((pattern) => pattern.test(diff)) || analysis.impact === 'high'
    }

    /**
     * Generate description for breaking changes
     */
    async generateBreakingChangeDescription(analysis) {
        let description = ''

        if (analysis.details.length > 0) {
            description = analysis.details
                .filter((d) => d.isBreaking)
                .map((d) => {
                    switch (d.type) {
                        case 'function':
                            return `Function ${d.name} signature has changed`
                        case 'class':
                            return `Class ${d.name} interface has been modified`
                        case 'api':
                            return `API endpoint ${d.name} has been restructured`
                        default:
                            return `${d.type} ${d.name} has breaking changes`
                    }
                })
                .join('\n')
        }

        return description || 'Major changes that break existing functionality'
    }

    /**
     * Helper methods
     */
    matchesTemplate(content, keywords) {
        return keywords.some((keyword) => new RegExp(keyword, 'i').test(content))
    }

    matchesFilePattern(filePath, patterns) {
        return patterns.some((pattern) => new RegExp(pattern, 'i').test(filePath))
    }

    applyTemplate(template, analysis) {
        // Replace placeholders with actual values
        return template.replace('{}', analysis.scope || 'component').replace('{}', this.generateDescription(analysis))
    }

    generateDescription(analysis) {
        if (analysis.details.length > 0) {
            return analysis.details.map((d) => d.name).join(', ')
        }
        return 'implementation'
    }

    determineType(analysis) {
        // Logic to determine commit type based on analysis
        if (analysis.details.some((d) => d.isNew)) return 'feat'
        if (analysis.details.some((d) => d.isFix)) return 'fix'
        return 'chore'
    }

    determineScope(filePath) {
        const scopePatterns = {
            api: /api|controller|route/i,
            ui: /component|view|page/i,
            auth: /auth|login|security/i,
            db: /model|migration|database/i,
            test: /test|spec/i
        }

        for (const [scope, pattern] of Object.entries(scopePatterns)) {
            if (pattern.test(filePath)) return scope
        }

        return ''
    }
}

================
File: src/features/autoCommit/fileTypes.js
================
// src/features/autoCommit/fileTypes.js
export const fileTypePatterns = {
    // Frontend patterns
    react: {
        pattern: /\.(jsx|tsx)$/,
        folders: ['components', 'pages', 'features'],
        keywords: ['useState', 'useEffect', 'Component'],
        scope: 'ui'
    },
    vue: {
        pattern: /\.(vue)$/,
        folders: ['components', 'views'],
        keywords: ['template', 'script', 'style'],
        scope: 'ui'
    },
    angular: {
        pattern: /\.(component|directive|service|pipe)\.ts$/,
        folders: ['app'],
        keywords: ['@Component', '@Injectable'],
        scope: 'ui'
    },
    style: {
        pattern: /\.(css|scss|less|sass|styl)$/,
        folders: ['styles', 'assets'],
        scope: 'style'
    },

    // Backend patterns
    controller: {
        pattern: /controller\.(js|ts)$/,
        folders: ['controllers', 'routes'],
        keywords: ['router', 'app.get', 'app.post'],
        scope: 'api'
    },
    model: {
        pattern: /model\.(js|ts)$/,
        folders: ['models', 'entities'],
        keywords: ['schema', 'Entity', '@Column'],
        scope: 'db'
    },
    service: {
        pattern: /service\.(js|ts)$/,
        folders: ['services'],
        keywords: ['@Service', 'Injectable'],
        scope: 'service'
    },

    // Test patterns
    unitTest: {
        pattern: /\.(spec|test)\.(js|ts|jsx|tsx)$/,
        folders: ['__tests__', 'test'],
        keywords: ['describe', 'it', 'test'],
        scope: 'test'
    },
    e2eTest: {
        pattern: /\.e2e-spec\.(js|ts)$/,
        folders: ['e2e', 'cypress'],
        keywords: ['cy.visit', 'browser.get'],
        scope: 'test'
    },

    // Config patterns
    config: {
        pattern: /\.(config|conf|rc)\.(js|json|yaml|yml)$/,
        folders: ['config'],
        scope: 'config'
    },
    buildConfig: {
        pattern: /(webpack|rollup|vite|babel)\.config\./,
        scope: 'build'
    },

    // Documentation patterns
    docs: {
        pattern: /\.(md|mdx|markdown|rst|txt)$/,
        folders: ['docs', 'documentation'],
        scope: 'docs'
    },
    api: {
        pattern: /\.(swagger|openapi)\.(json|yaml|yml)$/,
        folders: ['api'],
        scope: 'api'
    }
}

================
File: src/features/autoCommit/index.js
================
// src/features/autoCommit/index.js
import simpleGit from 'simple-git'
import chalk from 'chalk'
import { promises as fs } from 'fs'
import path from 'path'
import { execSync } from 'child_process'

export class AutoCommitManager {
    constructor(config = {}) {
        this.git = simpleGit()
        this.config = {
            includePush: config.includePush ?? true,
            separateCommits: config.separateCommits ?? true,
            generateTimeline: config.generateTimeline ?? true,
            ...config
        }
        this.contentAnalyzer = new ContentAnalyzer()
        this.prompts = new InteractivePrompts()
        this.ui = new VisualInterface()
        this.messageGenerator = new CommitMessageGenerator(config.templates)
        this.ui = new InteractiveUI(config.ui)
    }

    async execute(options = {}) {
        try {
            const files = await this.getChangedFiles()

            // Interactive file selection
            const selectedFiles = await this.ui.selectFiles(files)

            // Show diff viewer for selected files
            for (const file of selectedFiles) {
                const diff = await this.getFileDiff(file)
                await this.ui.showDiffViewer(diff, file)
            }

            // Interactive staging
            const stagedHunks = await this.ui.stageChanges(selectedFiles)

            // Generate and customize commit message
            const { type, scope, message } = await this.generateCommitMessage(selectedFiles[0])
            const customMessage = await this.ui.buildCommitMessage(type, scope, message)

            // Show preview and get confirmation
            const confirmed = await this.ui.showCommitPreview(customMessage, selectedFiles)

            if (confirmed) {
                return this.performCommit(selectedFiles, customMessage, stagedHunks)
            }

            return { success: false, message: 'Commit cancelled by user' }
        } catch (error) {
            throw new Error(`Failed to execute commit: ${error.message}`)
        }
    }

    async generateCommitMessage(file, diff) {
        const analysis = await this.messageGenerator.analyzeChanges(file, diff)
        return this.messageGenerator.generateMessage(file, diff, analysis)
    }

    async execute(options = {}) {
        this.ui.showProgress('Analyzing repository...', 'start')

        try {
            const status = await this.git.status()

            if (!status.files.length) {
                this.ui.showProgress('No changes to commit', 'info')
                return { success: true, message: 'No changes' }
            }

            // Display changes summary
            const changes = await this.getChangesDetails(status.files)
            this.ui.displayChangesSummary(changes)

            // Show timeline if requested
            if (options.timeline) {
                const timeline = await this.generateTimelineSuggestions()
                this.ui.displayTimeline(timeline)
            }

            // Get commit details through interactive UI
            const commitDetails = await this.prompts.getCommitDetails(status.files)

            // Process commits
            const results = []
            for (const file of commitDetails.selectedFiles) {
                this.ui.showProgress(`Committing ${file}...`, 'start')

                // Get diff and show preview
                const diff = await this.getFileDiff(file)
                this.ui.displayDiffPreview(diff)

                // Generate and preview commit message
                const commitInfo = await this.generateCommitMessage(file, diff)
                this.ui.displayCommitPreview(commitInfo)

                // Perform commit
                const result = await this.commitFile(file, commitInfo)
                results.push(result)

                if (result.success) {
                    this.ui.showProgress(`Successfully committed ${file}`, 'success')
                } else {
                    this.ui.showProgress(`Failed to commit ${file}: ${result.error}`, 'error')
                }
            }

            // Push if requested
            if (commitDetails.pushChanges) {
                this.ui.showProgress('Pushing changes...', 'start')
                const pushResult = await this.pushChanges()

                if (pushResult.success) {
                    this.ui.showProgress('Successfully pushed changes', 'success')
                } else {
                    this.ui.showProgress(`Failed to push: ${pushResult.error}`, 'error')
                }
            }

            // Display final results
            this.ui.displayResults(results)

            return {
                success: true,
                commits: results,
                push: commitDetails.pushChanges ? pushResult : null
            }
        } catch (error) {
            this.ui.showProgress(`Operation failed: ${error.message}`, 'error')
            throw error
        }
    }

    async generateCommitMessage(file, content) {
        const analysis = await this.contentAnalyzer.analyzeContent(file, content)

        if (this.config.interactive) {
            const { type, scope } = await this.prompts.getScopeAndType(analysis)
            const template = await this.prompts.getCommitTemplate(type, scope)

            // Handle breaking changes
            const { isBreaking, breakingChangeDescription } = await this.prompts.getBreakingChangeInfo()

            return {
                message: template,
                isBreaking,
                breakingChangeDescription
            }
        }

        // Auto-generate message based on analysis
        const type = analysis.suggestions[0] || 'chore'
        const scope = analysis.scope || ''
        const template = commitTemplates[type].update

        return {
            message: template.replace('{}', scope).replace('{}', path.basename(file)),
            isBreaking: false
        }
    }

    /**
     * Get file modification time
     */
    async getFileModTime(filePath) {
        try {
            const stats = await fs.stat(filePath)
            return stats.mtime.getTime()
        } catch (error) {
            console.warn(`Warning: Could not get mod time for ${filePath}`)
            return 0
        }
    }

    /**
     * Generate timeline-based suggestions
     */
    async generateTimelineSuggestions() {
        const status = await this.git.status()
        const files = [...status.modified, ...status.not_added, ...status.created]

        const timelineData = await Promise.all(
            files.map(async (file) => ({
                file,
                modTime: await this.getFileModTime(file),
                type: path.extname(file).slice(1) || 'unknown'
            }))
        )

        // Sort by modification time
        return timelineData.sort((a, b) => a.modTime - b.modTime)
    }

    /**
     * Generate commit message based on file type and changes
     */
    generateCommitMessage(file, type, diff) {
        const commitTypes = {
            js: 'feat',
            ts: 'feat',
            jsx: 'feat',
            tsx: 'feat',
            css: 'style',
            scss: 'style',
            less: 'style',
            md: 'docs',
            json: 'chore',
            yml: 'chore',
            yaml: 'chore',
            test: 'test',
            spec: 'test'
        }

        // Determine commit type
        const fileType = path.extname(file).slice(1)
        const commitType = commitTypes[fileType] || 'chore'

        // Check for specific keywords in diff
        const isTest = file.includes('test') || file.includes('spec')
        const isFix = diff.includes('fix') || diff.includes('bug')
        const isRefactor = diff.includes('refactor')

        if (isTest) return `test: update tests in ${file}`
        if (isFix) return `fix: resolve issue in ${file}`
        if (isRefactor) return `refactor: improve code in ${file}`

        return `${commitType}: update ${file}`
    }

    /**
     * Get file differences
     */
    async getFileDiff(file) {
        try {
            const diff = await this.git.diff([file])
            return diff
        } catch (error) {
            return ''
        }
    }

    /**
     * Process single file commit
     */
    async commitFile(file) {
        try {
            const diff = await this.getFileDiff(file)
            const commitMessage = this.generateCommitMessage(file, path.extname(file), diff)

            await this.git.add(file)
            await this.git.commit(commitMessage)

            return {
                success: true,
                message: commitMessage,
                file
            }
        } catch (error) {
            return {
                success: false,
                error: error.message,
                file
            }
        }
    }

    /**
     * Process bulk commit
     */
    async commitAll(files, message) {
        try {
            await this.git.add(files)

            const defaultMessage =
                files.length === 1 ? `update: ${files[0]}` : `update: multiple files (${files.length} files)`

            await this.git.commit(message || defaultMessage)

            return {
                success: true,
                message: message || defaultMessage,
                files
            }
        } catch (error) {
            return {
                success: false,
                error: error.message,
                files
            }
        }
    }

    /**
     * Push changes to remote
     */
    async pushChanges() {
        const currentBranch = await this.git.revparse(['--abbrev-ref', 'HEAD'])

        // Pull first to avoid conflicts
        await this.git.pull('origin', currentBranch, { '--rebase': 'false' })

        // Push changes
        await this.git.push('origin', currentBranch)

        return {
            success: true,
            branch: currentBranch
        }
    }

    /**
     * Main execution method
     */
    async execute(options = {}) {
        const status = await this.git.status()

        // Check if there are changes
        if (!status.files.length) {
            return {
                success: true,
                message: 'No changes to commit'
            }
        }

        const results = {
            commits: [],
            push: null
        }

        try {
            if (options.separateCommits || this.config.separateCommits) {
                // Commit files separately
                for (const file of status.files) {
                    const result = await this.commitFile(file.path)
                    results.commits.push(result)
                }
            } else {
                // Commit all changes together
                const files = status.files.map((f) => f.path)
                const result = await this.commitAll(files, options.message)
                results.commits.push(result)
            }

            // Push if configured
            if (options.push || this.config.includePush) {
                results.push = await this.pushChanges()
            }

            return results
        } catch (error) {
            throw new Error(`Auto-commit failed: ${error.message}`)
        }
    }
}

// src/cli/commands/autoCommit.js
import { Command } from 'commander'
import inquirer from 'inquirer'
import { AutoCommitManager } from '../../features/autoCommit'

export function registerAutoCommitCommand(program) {
    const autoCommitCommand = new Command('auto-commit')
        .description('Automatically commit changes with smart messages')
        .option('-s, --separate', 'Commit files separately')
        .option('-p, --push', 'Push changes after commit')
        .option('-m, --message <message>', 'Custom commit message for bulk commit')
        .option('-t, --timeline', 'Show timeline of changes')
        .option('-y, --yes', 'Skip confirmation prompts')
        .action(async (options) => {
            try {
                const config = await loadConfig()
                const manager = new AutoCommitManager(config.autoCommit)

                if (options.timeline) {
                    const timeline = await manager.generateTimelineSuggestions()
                    console.log(chalk.blue('\nTimeline of changes:'))
                    timeline.forEach(({ file, modTime }) => {
                        console.log(chalk.yellow(`[${new Date(modTime).toLocaleString()}] ${file}`))
                    })
                }

                if (!options.yes) {
                    const { confirm } = await inquirer.prompt([
                        {
                            type: 'confirm',
                            name: 'confirm',
                            message: 'Do you want to proceed with the commit?',
                            default: true
                        }
                    ])

                    if (!confirm) {
                        console.log(chalk.yellow('Operation cancelled'))
                        return
                    }
                }

                const results = await manager.execute({
                    separateCommits: options.separate,
                    push: options.push,
                    message: options.message
                })

                // Display results
                console.log(chalk.green('\nCommit Results:'))
                results.commits.forEach((commit) => {
                    if (commit.success) {
                        console.log(chalk.green(`✓ ${commit.message}`))
                    } else {
                        console.log(chalk.red(`✗ Failed to commit ${commit.file}: ${commit.error}`))
                    }
                })

                if (results.push) {
                    console.log(chalk.green(`\n✓ Changes pushed to ${results.push.branch}`))
                }
            } catch (error) {
                console.error(chalk.red(`Error: ${error.message}`))
                process.exit(1)
            }
        })

    return autoCommitCommand
}

================
File: src/features/autoCommit/interactivePrompts.js
================
// src/features/autoCommit/interactivePrompts.js
import inquirer from 'inquirer'
import { AutoComplete } from 'enquirer'

export class InteractivePrompts {
    constructor() {
        this.templates = commitTemplates
        this.fileTypes = fileTypePatterns
    }

    async getScopeAndType(analysis) {
        const { type } = await inquirer.prompt([
            {
                type: 'list',
                name: 'type',
                message: 'Select commit type:',
                choices: [
                    { name: '✨ Feature (feat)', value: 'feat' },
                    { name: '🐛 Bug Fix (fix)', value: 'fix' },
                    { name: '📚 Documentation (docs)', value: 'docs' },
                    { name: '💅 Styling (style)', value: 'style' },
                    { name: '♻️ Refactor (refactor)', value: 'refactor' },
                    { name: '✅ Testing (test)', value: 'test' },
                    { name: '🔨 Build (build)', value: 'build' },
                    { name: '🔧 Chore (chore)', value: 'chore' }
                ],
                default: analysis?.type || 'feat'
            }
        ])

        const { scope } = await inquirer.prompt([
            {
                type: 'input',
                name: 'scope',
                message: 'Enter commit scope (optional):',
                default: analysis?.scope || ''
            }
        ])

        return { type, scope }
    }

    async getCommitTemplate(type, scope) {
        const templates = this.templates[type] || this.templates.feature
        const choices = Object.values(templates).map((template) => template.replace('{}', scope || 'component'))

        const prompt = new AutoComplete({
            name: 'template',
            message: 'Select or customize commit message:',
            choices,
            suggest(input, choices) {
                return choices.filter((choice) => choice.toLowerCase().includes(input.toLowerCase()))
            }
        })

        return prompt.run()
    }

    async getCommitDetails(files) {
        const answers = await inquirer.prompt([
            {
                type: 'checkbox',
                name: 'selectedFiles',
                message: 'Select files to commit:',
                choices: files.map((file) => ({
                    name: file,
                    checked: true
                }))
            },
            {
                type: 'confirm',
                name: 'separateCommits',
                message: 'Commit files separately?',
                default: files.length > 1
            },
            {
                type: 'confirm',
                name: 'pushChanges',
                message: 'Push changes after commit?',
                default: true
            }
        ])

        return answers
    }

    async getBreakingChangeInfo() {
        return inquirer.prompt([
            {
                type: 'confirm',
                name: 'isBreaking',
                message: 'Does this commit include breaking changes?',
                default: false
            },
            {
                type: 'input',
                name: 'breakingChangeDescription',
                message: 'Describe the breaking changes:',
                when: (answers) => answers.isBreaking
            }
        ])
    }
}

================
File: src/features/autoCommit/interactiveUI.js
================
// src/features/autoCommit/interactiveUI.js
import inquirer from 'inquirer'
import inquirerPrompt from 'inquirer-autocomplete-prompt'
import { createFuzzySearch } from 'fuzzy-search'
import { Table } from 'console-table-printer'
import chalk from 'chalk'
import terminalLink from 'terminal-link'
import figures from 'figures'
import PressToContinuePrompt from 'inquirer-press-to-continue'
import { marked } from 'marked'
import TerminalRenderer from 'marked-terminal'

export class InteractiveUI {
    constructor(config = {}) {
        this.config = {
            useEmoji: config.useEmoji ?? true,
            showHints: config.showHints ?? true,
            detailedDiff: config.detailedDiff ?? true,
            ...config
        }

        // Register custom prompts
        inquirer.registerPrompt('autocomplete', inquirerPrompt)
        inquirer.registerPrompt('press-to-continue', PressToContinuePrompt)
        marked.setOptions({
            renderer: new TerminalRenderer()
        })
    }

    /**
     * Show interactive file selection with diff preview
     */
    async selectFiles(files) {
        const fileChoices = await Promise.all(
            files.map(async (file) => {
                const stats = await this.getFileStats(file)
                return {
                    name: `${this.getFileIcon(file)} ${file} ${this.getChangeStats(stats)}`,
                    value: file,
                    short: file
                }
            })
        )

        const { selectedFiles } = await inquirer.prompt([
            {
                type: 'checkbox',
                name: 'selectedFiles',
                message: 'Select files to commit:',
                choices: fileChoices,
                pageSize: 15,
                loop: false,
                async filter(input) {
                    return input
                },
                validate(input) {
                    if (input.length === 0) {
                        return 'You must select at least one file'
                    }
                    return true
                }
            }
        ])

        return selectedFiles
    }

    /**
     * Interactive commit message builder
     */
    async buildCommitMessage(type, scope, suggestedMessage) {
        const questions = [
            {
                type: 'list',
                name: 'type',
                message: 'Select the type of change:',
                default: type,
                choices: [
                    { name: '✨ Features (feat)', value: 'feat' },
                    { name: '🐛 Bug Fixes (fix)', value: 'fix' },
                    { name: '📚 Documentation (docs)', value: 'docs' },
                    { name: '💄 Styles (style)', value: 'style' },
                    { name: '♻️ Code Refactoring (refactor)', value: 'refactor' },
                    { name: '⚡️ Performance (perf)', value: 'perf' },
                    { name: '✅ Tests (test)', value: 'test' },
                    { name: '🔧 Chores (chore)', value: 'chore' }
                ]
            },
            {
                type: 'autocomplete',
                name: 'scope',
                message: 'Enter the scope (optional):',
                default: scope,
                source: (answers, input = '') => {
                    const scopes = [
                        'api',
                        'ui',
                        'core',
                        'deps',
                        'config',
                        'test',
                        'build',
                        'ci',
                        'docs',
                        'style',
                        'perf'
                    ]
                    return scopes.filter((s) => s.toLowerCase().includes(input.toLowerCase()))
                }
            },
            {
                type: 'editor',
                name: 'description',
                message: 'Enter a detailed description:',
                default: suggestedMessage,
                validate(text) {
                    if (text.split('\n')[0].length <= 3) {
                        return 'Description must be more meaningful'
                    }
                    return true
                }
            },
            {
                type: 'confirm',
                name: 'isBreaking',
                message: 'Does this change include breaking changes?',
                default: false
            },
            {
                type: 'editor',
                name: 'breakingChanges',
                message: 'Describe the breaking changes:',
                when: (answers) => answers.isBreaking,
                validate(text) {
                    if (text.length < 10) {
                        return 'Breaking change description must be meaningful'
                    }
                    return true
                }
            }
        ]

        const answers = await inquirer.prompt(questions)
        return this.formatCommitMessage(answers)
    }

    /**
     * Show interactive diff viewer
     */
    async showDiffViewer(diff, filepath) {
        console.log(chalk.bold(`\nChanges in ${filepath}:`))

        const lines = diff.split('\n')
        const chunks = this.groupDiffChunks(lines)
        let currentChunk = 0

        while (currentChunk < chunks.length) {
            this.displayDiffChunk(chunks[currentChunk])

            const { action } = await inquirer.prompt([
                {
                    type: 'list',
                    name: 'action',
                    message: 'Diff navigation:',
                    choices: [
                        { name: 'Next chunk', value: 'next', disabled: currentChunk === chunks.length - 1 },
                        { name: 'Previous chunk', value: 'prev', disabled: currentChunk === 0 },
                        { name: 'Show context', value: 'context' },
                        { name: 'Done', value: 'done' }
                    ]
                }
            ])

            if (action === 'next') currentChunk++
            if (action === 'prev') currentChunk--
            if (action === 'done') break
            if (action === 'context') {
                await this.showFileContext(filepath)
            }
        }
    }

    /**
     * Interactive staging interface
     */
    async stageChanges(files) {
        const hunks = await this.getChangeHunks(files)
        const stagedHunks = new Set()

        for (const hunk of hunks) {
            this.displayHunk(hunk)

            const { action } = await inquirer.prompt([
                {
                    type: 'list',
                    name: 'action',
                    message: 'What would you like to do with this change?',
                    choices: [
                        { name: 'Stage this hunk', value: 'stage' },
                        { name: 'Skip this hunk', value: 'skip' },
                        { name: 'Split this hunk', value: 'split' },
                        { name: 'Edit this hunk', value: 'edit' },
                        { name: 'View more context', value: 'context' }
                    ]
                }
            ])

            if (action === 'stage') {
                stagedHunks.add(hunk.id)
            } else if (action === 'split') {
                const splitHunks = await this.splitHunk(hunk)
                hunks.splice(hunks.indexOf(hunk), 1, ...splitHunks)
            } else if (action === 'edit') {
                const editedHunk = await this.editHunk(hunk)
                stagedHunks.add(editedHunk.id)
            }
        }

        return Array.from(stagedHunks)
    }

    /**
     * Show commit preview and get confirmation
     */
    async showCommitPreview(message, files) {
        console.log(chalk.bold('\nCommit Preview:'))
        console.log('─'.repeat(50))

        console.log(chalk.yellow('Message:'))
        console.log(message)

        console.log(chalk.yellow('\nFiles to be committed:'))
        const table = new Table({
            columns: [
                { name: 'file', title: 'File', alignment: 'left' },
                { name: 'changes', title: 'Changes', alignment: 'right' }
            ]
        })

        for (const file of files) {
            const stats = await this.getFileStats(file)
            table.addRow({
                file: this.getFileIcon(file) + ' ' + file,
                changes: this.getChangeStats(stats)
            })
        }

        table.printTable()

        const { confirm } = await inquirer.prompt([
            {
                type: 'confirm',
                name: 'confirm',
                message: 'Do you want to proceed with this commit?',
                default: true
            }
        ])

        return confirm
    }

    /**
     * Helper methods
     */
    getFileIcon(filepath) {
        const icons = {
            js: '📄',
            ts: '📘',
            jsx: '⚛️',
            css: '🎨',
            scss: '🎨',
            html: '🌐',
            md: '📝',
            json: '📋',
            yml: '⚙️',
            test: '✅'
        }

        const ext = filepath.split('.').pop()
        return icons[ext] || '📄'
    }

    getChangeStats(stats) {
        return chalk.green(`+${stats.additions}`) + ' ' + chalk.red(`-${stats.deletions}`)
    }

    async getFileStats(filepath) {
        // Implementation to get file stats
        return { additions: 0, deletions: 0 }
    }

    groupDiffChunks(lines, chunkSize = 5) {
        // Implementation to group diff lines into chunks
        return []
    }

    displayDiffChunk(chunk) {
        // Implementation to display a diff chunk
    }

    async showFileContext(filepath) {
        // Implementation to show file context
    }

    async getChangeHunks(files) {
        // Implementation to get change hunks
        return []
    }

    displayHunk(hunk) {
        // Implementation to display a hunk
    }

    async splitHunk(hunk) {
        // Implementation to split a hunk
        return []
    }

    async editHunk(hunk) {
        // Implementation to edit a hunk
        return hunk
    }

    formatCommitMessage(answers) {
        let message = `${answers.type}`
        if (answers.scope) {
            message += `(${answers.scope})`
        }
        message += `: ${answers.description.split('\n')[0]}`

        if (answers.description.split('\n').length > 1) {
            message += `\n\n${answers.description.split('\n').slice(1).join('\n')}`
        }

        if (answers.isBreaking) {
            message += `\n\nBREAKING CHANGE: ${answers.breakingChanges}`
        }

        return message
    }
}

================
File: src/features/autoCommit/templates.js
================
// src/features/autoCommit/templates.js
export const commitTemplates = {
    // Feature related templates
    feature: {
        add: 'feat({}): add {} functionality',
        update: 'feat({}): update {} implementation',
        enhance: 'feat({}): enhance {} capabilities',
        implement: 'feat({}): implement {}',
        optimize: 'perf({}): optimize {} performance'
    },

    // Bug fix templates
    fix: {
        bug: 'fix({}): resolve {} issue',
        security: 'fix({}): address security vulnerability in {}',
        typo: 'fix({}): correct typo in {}',
        regression: 'fix({}): fix regression in {}',
        edge: 'fix({}): handle edge case in {}'
    },

    // Documentation templates
    docs: {
        add: 'docs({}): add documentation for {}',
        update: 'docs({}): update {} documentation',
        example: 'docs({}): add examples for {}',
        api: 'docs(api): update {} API documentation',
        comment: 'docs({}): improve code comments in {}'
    },

    // Style templates
    style: {
        format: 'style({}): format {}',
        improve: 'style({}): improve {} styling',
        responsive: 'style({}): enhance responsiveness of {}',
        theme: 'style(theme): update {} theme',
        layout: 'style(layout): adjust {} layout'
    },

    // Refactor templates
    refactor: {
        improve: 'refactor({}): improve {} structure',
        simplify: 'refactor({}): simplify {} logic',
        split: 'refactor({}): split {} into smaller components',
        merge: 'refactor({}): merge {} components',
        cleanup: 'refactor({}): clean up {}'
    },

    // Test templates
    test: {
        add: 'test({}): add tests for {}',
        update: 'test({}): update {} tests',
        coverage: 'test({}): improve test coverage for {}',
        unit: 'test(unit): add unit tests for {}',
        integration: 'test(integration): add integration tests for {}'
    },

    // Build templates
    build: {
        deps: 'build(deps): update dependencies for {}',
        config: 'build({}): update build configuration',
        bundle: 'build({}): optimize bundle size',
        pipeline: 'build(ci): update CI pipeline for {}'
    },

    // Chore templates
    chore: {
        deps: 'chore(deps): update {} dependencies',
        cleanup: 'chore({}): clean up {}',
        version: 'chore(release): bump {} version',
        merge: 'chore(merge): merge {} into {}',
        config: 'chore(config): update {} configuration'
    }
}

================
File: src/features/autoCommit/visualInterface.js
================
// src/features/autoCommit/visualInterface.js
import chalk from 'chalk'
import boxen from 'boxen'
import ora from 'ora'
import { Table } from 'console-table-printer'

export class VisualInterface {
    constructor() {
        this.spinner = ora()
    }

    /**
     * Display file changes summary
     */
    displayChangesSummary(changes) {
        console.log(
            boxen(chalk.bold('📦 Changes Summary'), {
                padding: 1,
                margin: 1,
                borderStyle: 'round',
                borderColor: 'blue'
            })
        )

        const table = new Table({
            columns: [
                { name: 'status', alignment: 'left', color: 'white' },
                { name: 'file', alignment: 'left', color: 'white' },
                { name: 'changes', alignment: 'right', color: 'white' },
                { name: 'type', alignment: 'left', color: 'white' }
            ]
        })

        changes.forEach((change) => {
            const status = this.getStatusIcon(change.status)
            table.addRow(
                {
                    status,
                    file: change.file,
                    changes: `+${change.additions} -${change.deletions}`,
                    type: this.getFileType(change.file)
                },
                { color: this.getStatusColor(change.status) }
            )
        })

        table.printTable()
    }

    /**
     * Show commit preview
     */
    displayCommitPreview(commitInfo) {
        console.log(
            boxen(chalk.bold('🔍 Commit Preview'), {
                padding: 1,
                margin: 1,
                borderStyle: 'round',
                borderColor: 'yellow'
            })
        )

        console.log(chalk.blue('Type:    ') + chalk.white(commitInfo.type))
        console.log(chalk.blue('Scope:   ') + chalk.white(commitInfo.scope || 'none'))
        console.log(chalk.blue('Message: ') + chalk.white(commitInfo.message))

        if (commitInfo.breaking) {
            console.log(chalk.red('\nBREAKING CHANGE:'))
            console.log(chalk.red(commitInfo.breakingMessage))
        }

        console.log('\n')
    }

    /**
     * Display timeline visualization
     */
    displayTimeline(timelineData) {
        console.log(
            boxen(chalk.bold('⏰ Changes Timeline'), {
                padding: 1,
                margin: 1,
                borderStyle: 'round',
                borderColor: 'green'
            })
        )

        timelineData.forEach((item) => {
            const time = new Date(item.modTime).toLocaleTimeString()
            const icon = this.getFileTypeIcon(item.type)

            console.log(chalk.gray(time) + ' ' + icon + ' ' + chalk.white(item.file))

            if (item.summary) {
                console.log(chalk.gray('  ├─ ') + chalk.dim(item.summary))
            }

            if (item.suggestions) {
                console.log(chalk.gray('  └─ ') + chalk.blue(item.suggestions.join(', ')))
            }
        })
    }

    /**
     * Show file diff preview
     */
    displayDiffPreview(diff) {
        console.log(
            boxen(chalk.bold('📝 Diff Preview'), {
                padding: 1,
                margin: 1,
                borderStyle: 'round',
                borderColor: 'magenta'
            })
        )

        diff.split('\n').forEach((line) => {
            if (line.startsWith('+')) {
                console.log(chalk.green(line))
            } else if (line.startsWith('-')) {
                console.log(chalk.red(line))
            } else {
                console.log(chalk.gray(line))
            }
        })
    }

    /**
     * Display operation progress
     */
    showProgress(message, type = 'info') {
        this.spinner.stop()

        switch (type) {
            case 'start':
                this.spinner.start(chalk.blue(message))
                break
            case 'success':
                this.spinner.succeed(chalk.green(message))
                break
            case 'error':
                this.spinner.fail(chalk.red(message))
                break
            case 'warning':
                this.spinner.warn(chalk.yellow(message))
                break
            default:
                this.spinner.info(chalk.blue(message))
        }
    }

    /**
     * Display commit results
     */
    displayResults(results) {
        console.log(
            boxen(chalk.bold('✨ Commit Results'), {
                padding: 1,
                margin: 1,
                borderStyle: 'round',
                borderColor: 'green'
            })
        )

        const table = new Table({
            columns: [
                { name: 'status', alignment: 'left', color: 'white' },
                { name: 'file', alignment: 'left', color: 'white' },
                { name: 'message', alignment: 'left', color: 'white' }
            ]
        })

        results.forEach((result) => {
            table.addRow(
                {
                    status: result.success ? '✅' : '❌',
                    file: result.file,
                    message: result.message || result.error
                },
                {
                    color: result.success ? 'green' : 'red'
                }
            )
        })

        table.printTable()

        if (results.some((r) => !r.success)) {
            console.log(chalk.yellow('\n⚠️  Some commits failed. Please check the results above.'))
        }
    }

    /**
     * Helper functions
     */
    getStatusIcon(status) {
        const icons = {
            added: '✨',
            modified: '📝',
            deleted: '🗑️',
            renamed: '📋',
            copied: '📑',
            untracked: '❓'
        }
        return icons[status] || '❓'
    }

    getStatusColor(status) {
        const colors = {
            added: 'green',
            modified: 'yellow',
            deleted: 'red',
            renamed: 'blue',
            copied: 'cyan',
            untracked: 'gray'
        }
        return colors[status] || 'white'
    }

    getFileTypeIcon(type) {
        const icons = {
            js: '🟨',
            ts: '🔷',
            jsx: '⚛️',
            css: '🎨',
            html: '🌐',
            md: '📝',
            json: '📋',
            yml: '⚙️',
            test: '✅',
            other: '📄'
        }
        return icons[type] || icons.other
    }

    getFileType(filePath) {
        const ext = filePath.split('.').pop().toLowerCase()
        const types = {
            js: 'JavaScript',
            ts: 'TypeScript',
            jsx: 'React',
            tsx: 'React/TS',
            css: 'Styles',
            scss: 'Styles',
            md: 'Docs',
            json: 'Config',
            yml: 'Config',
            yaml: 'Config',
            test: 'Test',
            spec: 'Test'
        }
        return types[ext] || 'Other'
    }
}

================
File: src/features/contextManager/index.js
================
// src/features/contextManager/index.js
import { parse } from '@babel/parser'
import traverse from '@babel/traverse'
import * as fs from 'fs/promises'
import * as path from 'path'
import { transformFromAst } from '@babel/core'
import { createSourceFile, ScriptTarget, SyntaxKind } from 'typescript'
// src/features/contextManager/index.js
// Update the CodeContextManager to use GitIgnoreHandler

import { GitIgnoreHandler } from '../../utils/gitignore'



export class CodeContextManager {
    constructor(config = {}) {
      this.config = {
        outputFormat: config.outputFormat || 'markdown',
        maxDepth: config.maxDepth || 2,
        includeImports: config.includeImports ?? true,
        includeExports: config.includeExports ?? true,
        maxContextLines: config.maxContextLines || 100,
        excludePatterns: config.excludePatterns || [/node_modules/, /\.git/]
      }

        this.gitIgnoreHandler = new GitIgnoreHandler({
            enabled: config.respectGitIgnore ?? true,
            customIgnores: config.customIgnores,
            rootDir: config.rootDir || process.cwd()
        })
    }

    async initialize() {
        await this.gitIgnoreHandler.initialize()
    }

  async getContext({ target, type, depth = 1, file = null }) {
    // Check if the target file should be ignored
    if (file && this.gitIgnoreHandler.shouldIgnore(file)) {
      throw new Error('Target file is ignored by .gitignore rules')
    }

  }
    /**
     * Main entry point for getting code context
     */
    async getContext({ target, type, depth = 1, file = null }) {
        try {
            const context = await this.extractContext(target, type, depth, file)
            return this.formatOutput(context)
        } catch (error) {
            throw new Error(`Failed to get context: ${error.message}`)
        }
    }

    async getFileContext(filePath, depth) {
        // Filter out ignored dependencies
        const context = await super.getFileContext(filePath, depth)

        if (context.dependencies) {
            context.dependencies = this.gitIgnoreHandler.filterPaths(context.dependencies)
        }

        return context
    }

    async searchContext({ query, path: searchPath, type }) {
        const results = await super.searchContext({ query, path: searchPath, type })

        // Filter out results from ignored files
        return results.filter((result) => !this.gitIgnoreHandler.shouldIgnore(result.file))
    }

    /**
     * Extract context based on type
     */
    async extractContext(target, type, depth, file) {
        const contextData = {
            type,
            target,
            content: null,
            references: [],
            dependencies: [],
            timestamp: new Date().toISOString()
        }

        switch (type) {
            case 'function':
                contextData.content = await this.getFunctionContext(target, file, depth)
                break
            case 'file':
                contextData.content = await this.getFileContext(target, depth)
                break
            case 'character':
                contextData.content = await this.getCharacterContext(target, file, depth)
                break
            default:
                throw new Error(`Unsupported context type: ${type}`)
        }

        return contextData
    }

    /**
     * Get context for a specific function
     */
    async getFunctionContext(functionName, filePath, depth) {
        const fileContent = await fs.readFile(filePath, 'utf-8')
        const ast = parse(fileContent, {
            sourceType: 'module',
            plugins: ['jsx', 'typescript', 'decorators-legacy']
        })

        const context = {
            definition: null,
            callers: [],
            dependencies: [],
            tests: []
        }

        // Find function definition
        traverse(ast, {
            FunctionDeclaration(path) {
                if (path.node.id.name === functionName) {
                    context.definition = this.extractFunctionDefinition(path)
                }
            },
            CallExpression(path) {
                if (path.node.callee.name === functionName) {
                    context.callers.push(this.extractCaller(path))
                }
            }
        })

        if (depth > 1) {
            context.dependencies = await this.findDependencies(filePath, functionName)
            context.tests = await this.findRelatedTests(filePath, functionName)
        }

        return context
    }

    /**
     * Get context for an entire file
     */
    async getFileContext(filePath, depth) {
        const content = await fs.readFile(filePath, 'utf-8')
        const sourceFile = createSourceFile(filePath, content, ScriptTarget.Latest, true)

        const context = {
            content,
            imports: [],
            exports: [],
            functions: [],
            classes: [],
            dependencies: []
        }

        // Extract imports and exports
        if (this.config.includeImports) {
            context.imports = this.extractImports(sourceFile)
        }

        if (this.config.includeExports) {
            context.exports = this.extractExports(sourceFile)
        }

        // Extract functions and classes
        sourceFile.forEachChild((node) => {
            if (node.kind === SyntaxKind.FunctionDeclaration) {
                context.functions.push(this.extractFunctionInfo(node))
            } else if (node.kind === SyntaxKind.ClassDeclaration) {
                context.classes.push(this.extractClassInfo(node))
            }
        })

        if (depth > 1) {
            context.dependencies = await this.findFileDependencies(filePath)
        }

        return context
    }

    /**
     * Get context for a specific character position
     */
    async getCharacterContext(position, filePath, depth) {
        const content = await fs.readFile(filePath, 'utf-8')
        const lines = content.split('\n')

        const { line, column } = this.getLineAndColumn(position, content)

        const context = {
            line,
            column,
            snippet: this.extractSnippet(lines, line, this.config.maxContextLines),
            scope: await this.findScope(filePath, line, column),
            references: []
        }

        if (depth > 1) {
            context.references = await this.findReferences(filePath, line, column)
        }

        return context
    }

    /**
     * Format output based on configured format
     */
    formatOutput(context) {
        switch (this.config.outputFormat) {
            case 'markdown':
                return this.toMarkdown(context)
            case 'xml':
                return this.toXML(context)
            case 'json':
                return JSON.stringify(context, null, 2)
            default:
                return this.toPlainText(context)
        }
    }

    /**
     * Convert context to Markdown format
     */
    toMarkdown(context) {
        let md = `# Code Context: ${context.target}\n\n`

        md += `## Type: ${context.type}\n\n`

        if (context.content.definition) {
            md += '## Definition\n\n```javascript\n'
            md += context.content.definition
            md += '\n```\n\n'
        }

        if (context.content.dependencies?.length > 0) {
            md += '## Dependencies\n\n'
            context.content.dependencies.forEach((dep) => {
                md += `- ${dep}\n`
            })
            md += '\n'
        }

        // Add more sections based on context type

        return md
    }

    /**
     * Convert context to XML format
     */
    toXML(context) {
        let xml = '<?xml version="1.0" encoding="UTF-8"?>\n'
        xml += '<codeContext>\n'
        xml += `  <target>${this.escapeXml(context.target)}</target>\n`
        xml += `  <type>${context.type}</type>\n`

        // Add content based on type
        xml += '  <content>\n'
        if (context.content.definition) {
            xml += `    <definition><![CDATA[${context.content.definition}]]></definition>\n`
        }
        // Add more content sections

        xml += '  </content>\n'
        xml += '</codeContext>'

        return xml
    }

    /**
     * Utility functions
     */
    async findDependencies(filePath, functionName) {
        // Implementation to find function dependencies
    }

    async findRelatedTests(filePath, functionName) {
        // Implementation to find related test files
    }

    extractFunctionDefinition(path) {
        // Implementation to extract function definition
    }

    extractCaller(path) {
        // Implementation to extract caller information
    }

    extractImports(sourceFile) {
        // Implementation to extract imports
    }

    extractExports(sourceFile) {
        // Implementation to extract exports
    }

    getLineAndColumn(position, content) {
        // Implementation to convert position to line and column
    }

    extractSnippet(lines, line, maxLines) {
        // Implementation to extract code snippet
    }

    escapeXml(str) {
        // Implementation to escape XML special characters
    }
}

// src/features/contextManager/formatters/index.js
export class ContextFormatter {
    static toMarkdown(context) {
        // Implementation of markdown formatting
    }

    static toXML(context) {
        // Implementation of XML formatting
    }

    static toPlainText(context) {
        // Implementation of plain text formatting
    }
}

// src/features/contextManager/parsers/index.js
export class ContextParser {
    static parseFunction(ast, functionName) {
        // Implementation of function parsing
    }

    static parseFile(sourceFile) {
        // Implementation of file parsing
    }

    static parseCharacterPosition(content, position) {
        // Implementation of character position parsing
    }
}

================
File: src/features/contextManager.js
================
// src/features/contextManager.js
import { parse } from '@babel/parser'
import traverse from '@babel/traverse'
import * as fs from 'fs/promises'

export class CodeContextManager {
    constructor(config) {
        this.outputFormat = config.outputFormat || 'markdown'
    }

    async getContext({ target, type, depth = 1, includeImports = true }) {
        const context = await this.extractContext(target, type, depth)
        return this.formatOutput(context)
    }

    async extractContext(target, type, depth) {
        switch (type) {
            case 'function':
                return this.getFunctionContext(target, depth)
            case 'file':
                return this.getFileContext(target, depth)
            case 'character':
                return this.getCharacterContext(target, depth)
            default:
                throw new Error(`Unsupported context type: ${type}`)
        }
    }

    formatOutput(context) {
        switch (this.outputFormat) {
            case 'markdown':
                return this.toMarkdown(context)
            case 'xml':
                return this.toXML(context)
            default:
                return this.toPlainText(context)
        }
    }
}

================
File: src/features/gitHistory.js
================
// src/features/gitHistory.js
import { createClient } from '@supabase/supabase-js'
import { execSync } from 'child_process'

export class GitHistoryTracker {
    constructor(config) {
        this.supabase = createClient(config.supabaseUrl, config.supabaseKey)
    }

    async trackCommand(command, repoPath) {
        const repoName = this.getRepoName(repoPath)
        const commandType = this.parseCommandType(command)

        await this.supabase.from('git_command_history').insert({
            command_type: commandType,
            repository_path: repoPath,
            repository_name: repoName,
            command_details: {
                full_command: command,
                timestamp: new Date().toISOString()
            }
        })

        await this.updateRepositoryMetadata(repoPath, commandType)
    }

    async getDashboardData(timeRange = '7d') {
        const { data, error } = await this.supabase
            .from('git_command_history')
            .select(
                `
        command_type,
        repository_name,
        command_details,
        executed_at
      `
            )
            .gte('executed_at', new Date(Date.now() - this.parseTimeRange(timeRange)))
            .order('executed_at', { ascending: false })

        if (error) throw error
        return this.formatDashboardData(data)
    }
}

================
File: src/features/repoMigration.js
================
// src/features/repoMigration.js
import { Octokit } from '@octokit/rest'
import simpleGit from 'simple-git'

export class RepoMigrationService {
    constructor(config) {
        this.octokit = new Octokit({ auth: config.githubToken })
        this.git = simpleGit()
    }

    async searchUserRepos(username) {
        try {
            const { data } = await this.octokit.repos.listForUser({
                username,
                sort: 'updated',
                per_page: 100
            })
            return data.map((repo) => ({
                name: repo.name,
                description: repo.description,
                url: repo.clone_url,
                stars: repo.stargazers_count,
                language: repo.language
            }))
        } catch (error) {
            throw new Error(`Failed to fetch repositories: ${error.message}`)
        }
    }

    async migrateRepository({ sourceRepo, targetName, targetOwner, cloneLocally, localPath }) {
        try {
            // Clone repository
            await this.git.clone(sourceRepo.url, localPath)

            if (cloneLocally) {
                // If user wants to keep local copy, we're done
                return { success: true, path: localPath }
            }

            // Create new repository
            const { data: newRepo } = await this.octokit.repos.createForAuthenticatedUser({
                name: targetName,
                private: true
            })

            // Push to new repository
            await this.git.cwd(localPath).removeRemote('origin').addRemote('origin', newRepo.clone_url).push(['--all'])

            return {
                success: true,
                newRepoUrl: newRepo.html_url,
                localPath: cloneLocally ? localPath : null
            }
        } catch (error) {
            throw new Error(`Migration failed: ${error.message}`)
        }
    }
}

================
File: src/shared/errorHandle.ts
================
import { z } from 'zod';
import { logger } from './logger.js';

export class repofmError extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'repofmError';
  }
}

export class repofmConfigValidationError extends repofmError {
  constructor(message: string) {
    super(message);
    this.name = 'repofmConfigValidationError';
  }
}

export const handleError = (error: unknown): void => {
  if (error instanceof repofmError) {
    logger.error(`Error: ${error.message}`);
  } else if (error instanceof Error) {
    logger.error(`Unexpected error: ${error.message}`);
    logger.debug('Stack trace:', error.stack);
  } else {
    logger.error('An unknown error occurred');
  }

  logger.info('For more help, please visit: https://github.com/chenxingqiang/repofm/issues');
};

export const rethrowValidationErrorIfZodError = (error: unknown, message: string): void => {
  if (error instanceof z.ZodError) {
    const zodErrorText = error.errors.map((err) => `[${err.path.join('.')}] ${err.message}`).join('\n  ');
    throw new repofmConfigValidationError(
      `${message}\n\n  ${zodErrorText}\n\n  Please check the config file and try again.`,
    );
  }
};

================
File: src/shared/logger.ts
================
import util from 'node:util';
import pc from 'picocolors';

class Logger {
  private isVerbose = false;

  setVerbose(value: boolean) {
    this.isVerbose = value;
  }

  error(...args: unknown[]) {
    console.error(pc.red(this.formatArgs(args)));
  }

  warn(...args: unknown[]) {
    console.log(pc.yellow(this.formatArgs(args)));
  }

  success(...args: unknown[]) {
    console.log(pc.green(this.formatArgs(args)));
  }

  info(...args: unknown[]) {
    console.log(pc.cyan(this.formatArgs(args)));
  }

  note(...args: unknown[]) {
    console.log(pc.dim(this.formatArgs(args)));
  }

  debug(...args: unknown[]) {
    if (this.isVerbose) {
      console.log(pc.blue(this.formatArgs(args)));
    }
  }

  trace(...args: unknown[]) {
    if (this.isVerbose) {
      console.log(pc.gray(this.formatArgs(args)));
    }
  }

  log(...args: unknown[]) {
    console.log(...args);
  }

  private formatArgs(args: unknown[]): string {
    return args
      .map((arg) => (typeof arg === 'object' ? util.inspect(arg, { depth: null, colors: true }) : arg))
      .join(' ');
  }
}

export const logger = new Logger();

================
File: src/shared/processConcurrency.ts
================
import os from 'node:os';

export const getProcessConcurrency = () => {
  const cpuCount = typeof os.availableParallelism === 'function' ? os.availableParallelism() : os.cpus().length;

  // Use all available CPUs except one
  return Math.max(1, cpuCount - 1);
};

================
File: src/shared/types.ts
================
export type repofmProgressCallback = (message: string) => void;

================
File: src/types/config.ts
================
export interface Config {
  include: string[];
  ignore: string[] | {
    useGitignore: boolean;
    useDefaultPatterns: boolean;
    customPatterns: string[];
  };
  output: {
    filePath: string;
    style: 'plain' | 'xml' | 'markdown';
    removeComments: boolean;
    removeEmptyLines: boolean;
    topFilesLength: number;
    showLineNumbers: boolean;
    copyToClipboard: boolean;
    headerText?: string;
    instructionFilePath?: string;
  };
  security?: {
    enableSecurityCheck: boolean;
  };
}

================
File: src/utils/gitignore.js
================
// src/utils/gitignore.js
import ignore from 'ignore'
import * as fs from 'fs/promises'
import * as path from 'path'
import { glob } from 'glob'

export class GitIgnoreHandler {
    constructor(options = {}) {
        this.enabled = options.enabled ?? true
        this.ignoreInstance = ignore()
        this.customIgnores = options.customIgnores || []
        this.cached = new Map()
        this.rootDir = options.rootDir || process.cwd()
    }

    /**
     * Initialize the handler by loading all .gitignore files
     */
    async initialize() {
        try {
            // Load root .gitignore
            await this.loadGitIgnore(this.rootDir)

            // Load all .gitignore files in subdirectories
            const gitignoreFiles = await glob('**/.gitignore', {
                cwd: this.rootDir,
                ignore: ['**/node_modules/**'],
                dot: true
            })

            for (const file of gitignoreFiles) {
                await this.loadGitIgnore(path.join(this.rootDir, path.dirname(file)))
            }

            // Add custom ignores
            if (this.customIgnores.length > 0) {
                this.ignoreInstance.add(this.customIgnores)
            }

            return true
        } catch (error) {
            console.warn(`Warning: Error initializing GitIgnoreHandler: ${error.message}`)
            return false
        }
    }

    /**
     * Load a specific .gitignore file
     */
    async loadGitIgnore(dirPath) {
        try {
            const gitignorePath = path.join(dirPath, '.gitignore')
            const content = await fs.readFile(gitignorePath, 'utf8')
            this.ignoreInstance.add(content)

            // Cache the rules for this directory
            this.cached.set(
                dirPath,
                content.split('\n').filter((line) => line.trim() && !line.startsWith('#'))
            )
        } catch (error) {
            // Silently ignore if .gitignore doesn't exist
            if (error.code !== 'ENOENT') {
                console.warn(`Warning: Error loading .gitignore at ${dirPath}: ${error.message}`)
            }
        }
    }

    /**
     * Check if a path should be ignored
     */
    shouldIgnore(filePath) {
        if (!this.enabled) return false

        const relativePath = path.relative(this.rootDir, filePath)
        return this.ignoreInstance.ignores(relativePath)
    }

    /**
     * Filter an array of paths based on gitignore rules
     */
    filterPaths(paths) {
        if (!this.enabled) return paths

        return paths.filter((filePath) => !this.shouldIgnore(filePath))
    }

    /**
     * Get all applicable ignore rules for a specific path
     */
    getRulesForPath(filePath) {
        const rules = new Set()
        let currentDir = path.dirname(filePath)

        while (currentDir.startsWith(this.rootDir)) {
            const dirRules = this.cached.get(currentDir)
            if (dirRules) {
                dirRules.forEach((rule) => rules.add(rule))
            }
            currentDir = path.dirname(currentDir)
        }

        return Array.from(rules)
    }

    /**
     * Add custom ignore patterns
     */
    addCustomIgnores(patterns) {
        this.customIgnores.push(...patterns)
        this.ignoreInstance.add(patterns)
    }
}

================
File: src/utils/logger.ts
================
export const logger = {
  warn: (message: string, ...args: any[]) => console.warn(message, ...args),
  error: (message: string, ...args: any[]) => console.error(message, ...args),
  info: (message: string, ...args: any[]) => console.info(message, ...args),
  debug: (message: string, ...args: any[]) => console.debug(message, ...args),
};

================
File: src/utils/stringUtils.ts
================
export function escapeHtml(str: string): string {
  return str
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&#039;');
}

================
File: src/cli.js
================
// src/cli.js
program
    .command('migrate-repo')
    .description('Search and migrate repositories from a GitHub user')
    .option('-u, --user <username>', 'Source GitHub username')
    .option('-n, --name <name>', 'New repository name')
    .option('-o, --owner <owner>', 'Target owner/organization')
    .option('-c, --clone', 'Clone repository locally')
    .action(async (options) => {
        const service = new RepoMigrationService(config)
        await service.migrateRepository(options)
    })

program
    .command('git-dashboard')
    .description('Show Git activity dashboard')
    .option('-r, --range <range>', 'Time range (e.g., 7d, 30d)', '7d')
    .action(async (options) => {
        const tracker = new GitHistoryTracker(config)
        const data = await tracker.getDashboardData(options.range)
        console.log(formatDashboard(data))
    })

program
    .command('context')
    .description('Get code context')
    .option('-t, --target <target>', 'Target (function name, file path, or character position)')
    .option('-y, --type <type>', 'Context type (function, file, character)')
    .option('-d, --depth <depth>', 'Context depth', '1')
    .option('-f, --format <format>', 'Output format (plain, markdown, xml)', 'markdown')
    .action(async (options) => {
        const manager = new CodeContextManager({ outputFormat: options.format })
        const context = await manager.getContext(options)
        console.log(context)
    })

================
File: src/index.ts
================
export { pack } from './core/packager.js';
export type { repofmConfigFile as repofmConfig } from './config/configSchema.js';
export { run as cli } from './cli/cliRun.js';

================
File: supabase/db/git_his.sql
================
-- Git command history table
CREATE TABLE git_command_history (
  id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
  command_type TEXT NOT NULL,
  repository_path TEXT NOT NULL,
  repository_name TEXT NOT NULL,
  command_details JSONB NOT NULL,
  executed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
  user_id TEXT NOT NULL
);

-- Repository metadata table
CREATE TABLE repository_metadata (
  id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
  repository_path TEXT UNIQUE NOT NULL,
  repository_name TEXT NOT NULL,
  last_activity TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
  total_commits INTEGER DEFAULT 0,
  total_pushes INTEGER DEFAULT 0
);

================
File: supabase/.env.example
================
# GitHub Configuration
GITHUB_TOKEN=

# Supabase Configuration
SUPABASE_URL=
SUPABASE_KEY=

================
File: supabase/.gitignore
================
# Supabase
.branches
.temp
.env.local

================
File: supabase/config.toml
================
# A string used to distinguish different Supabase projects on the same host. Defaults to the
# working directory name when running `supabase init`.
project_id = "repofreeme"

[api]
enabled = true
# Port to use for the API URL.
port = 54321
# Schemas to expose in your API. Tables, views and stored procedures in this schema will get API
# endpoints. `public` is always included.
schemas = ["public", "graphql_public"]
# Extra schemas to add to the search_path of every request. `public` is always included.
extra_search_path = ["public", "extensions"]
# The maximum number of rows returns from a view, table, or stored procedure. Limits payload size
# for accidental or malicious requests.
max_rows = 1000

[api.tls]
enabled = false

[db]
# Port to use for the local database URL.
port = 54322
# Port used by db diff command to initialize the shadow database.
shadow_port = 54320
# The database major version to use. This has to be the same as your remote database's. Run `SHOW
# server_version;` on the remote database to check.
major_version = 15

[db.pooler]
enabled = false
# Port to use for the local connection pooler.
port = 54329
# Specifies when a server connection can be reused by other clients.
# Configure one of the supported pooler modes: `transaction`, `session`.
pool_mode = "transaction"
# How many server connections to allow per user/database pair.
default_pool_size = 20
# Maximum number of client connections allowed.
max_client_conn = 100

[realtime]
enabled = true
# Bind realtime via either IPv4 or IPv6. (default: IPv4)
# ip_version = "IPv6"
# The maximum length in bytes of HTTP request headers. (default: 4096)
# max_header_length = 4096

[studio]
enabled = true
# Port to use for Supabase Studio.
port = 54323
# External URL of the API server that frontend connects to.
api_url = "http://127.0.0.1"
# OpenAI API Key to use for Supabase AI in the Supabase Studio.
openai_api_key = "env(OPENAI_API_KEY)"

# Email testing server. Emails sent with the local dev setup are not actually sent - rather, they
# are monitored, and you can view the emails that would have been sent from the web interface.
[inbucket]
enabled = true
# Port to use for the email testing server web interface.
port = 54324
# Uncomment to expose additional ports for testing user applications that send emails.
# smtp_port = 54325
# pop3_port = 54326

[storage]
enabled = true
# The maximum file size allowed (e.g. "5MB", "500KB").
file_size_limit = "50MiB"

[storage.image_transformation]
enabled = true

# Uncomment to configure local storage buckets
# [storage.buckets.images]
# public = false
# file_size_limit = "50MiB"
# allowed_mime_types = ["image/png", "image/jpeg"]
# objects_path = "./images"

[auth]
enabled = true
# The base URL of your website. Used as an allow-list for redirects and for constructing URLs used
# in emails.
site_url = "http://127.0.0.1:3000"
# A list of *exact* URLs that auth providers are permitted to redirect to post authentication.
additional_redirect_urls = ["https://127.0.0.1:3000"]
# How long tokens are valid for, in seconds. Defaults to 3600 (1 hour), maximum 604,800 (1 week).
jwt_expiry = 3600
# If disabled, the refresh token will never expire.
enable_refresh_token_rotation = true
# Allows refresh tokens to be reused after expiry, up to the specified interval in seconds.
# Requires enable_refresh_token_rotation = true.
refresh_token_reuse_interval = 10
# Allow/disallow new user signups to your project.
enable_signup = true
# Allow/disallow anonymous sign-ins to your project.
enable_anonymous_sign_ins = false
# Allow/disallow testing manual linking of accounts
enable_manual_linking = false

[auth.email]
# Allow/disallow new user signups via email to your project.
enable_signup = true
# If enabled, a user will be required to confirm any email change on both the old, and new email
# addresses. If disabled, only the new email is required to confirm.
double_confirm_changes = true
# If enabled, users need to confirm their email address before signing in.
enable_confirmations = false
# Controls the minimum amount of time that must pass before sending another signup confirmation or password reset email.
max_frequency = "1s"

# Use a production-ready SMTP server
# [auth.email.smtp]
# host = "smtp.sendgrid.net"
# port = 587
# user = "apikey"
# pass = "env(SENDGRID_API_KEY)"
# admin_email = "admin@email.com"
# sender_name = "Admin"

# Uncomment to customize email template
# [auth.email.template.invite]
# subject = "You have been invited"
# content_path = "./supabase/templates/invite.html"

[auth.sms]
# Allow/disallow new user signups via SMS to your project.
enable_signup = true
# If enabled, users need to confirm their phone number before signing in.
enable_confirmations = false
# Template for sending OTP to users
template = "Your code is {{ .Code }} ."
# Controls the minimum amount of time that must pass before sending another sms otp.
max_frequency = "5s"

# Use pre-defined map of phone number to OTP for testing.
# [auth.sms.test_otp]
# 4152127777 = "123456"

# Configure logged in session timeouts.
# [auth.sessions]
# Force log out after the specified duration.
# timebox = "24h"
# Force log out if the user has been inactive longer than the specified duration.
# inactivity_timeout = "8h"

# This hook runs before a token is issued and allows you to add additional claims based on the authentication method used.
# [auth.hook.custom_access_token]
# enabled = true
# uri = "pg-functions://<database>/<schema>/<hook_name>"

# Configure one of the supported SMS providers: `twilio`, `twilio_verify`, `messagebird`, `textlocal`, `vonage`.
[auth.sms.twilio]
enabled = false
account_sid = ""
message_service_sid = ""
# DO NOT commit your Twilio auth token to git. Use environment variable substitution instead:
auth_token = "env(SUPABASE_AUTH_SMS_TWILIO_AUTH_TOKEN)"

[auth.mfa]
# Control how many MFA factors can be enrolled at once per user.
max_enrolled_factors = 10

# Control use of MFA via App Authenticator (TOTP)
[auth.mfa.totp]
enroll_enabled = true
verify_enabled = true

# Configure Multi-factor-authentication via Phone Messaging
# [auth.mfa.phone]
# enroll_enabled = true
# verify_enabled = true
# otp_length = 6
# template = "Your code is {{ .Code }} ."
# max_frequency = "10s"

# Use an external OAuth provider. The full list of providers are: `apple`, `azure`, `bitbucket`,
# `discord`, `facebook`, `github`, `gitlab`, `google`, `keycloak`, `linkedin_oidc`, `notion`, `twitch`,
# `twitter`, `slack`, `spotify`, `workos`, `zoom`.
[auth.external.apple]
enabled = false
client_id = ""
# DO NOT commit your OAuth provider secret to git. Use environment variable substitution instead:
secret = "env(SUPABASE_AUTH_EXTERNAL_APPLE_SECRET)"
# Overrides the default auth redirectUrl.
redirect_uri = ""
# Overrides the default auth provider URL. Used to support self-hosted gitlab, single-tenant Azure,
# or any other third-party OIDC providers.
url = ""
# If enabled, the nonce check will be skipped. Required for local sign in with Google auth.
skip_nonce_check = false

# Use Firebase Auth as a third-party provider alongside Supabase Auth.
[auth.third_party.firebase]
enabled = false
# project_id = "my-firebase-project"

# Use Auth0 as a third-party provider alongside Supabase Auth.
[auth.third_party.auth0]
enabled = false
# tenant = "my-auth0-tenant"
# tenant_region = "us"

# Use AWS Cognito (Amplify) as a third-party provider alongside Supabase Auth.
[auth.third_party.aws_cognito]
enabled = false
# user_pool_id = "my-user-pool-id"
# user_pool_region = "us-east-1"

[edge_runtime]
enabled = true
# Configure one of the supported request policies: `oneshot`, `per_worker`.
# Use `oneshot` for hot reload, or `per_worker` for load testing.
policy = "oneshot"
inspector_port = 8083

[analytics]
enabled = true
port = 54327
# Configure one of the supported backends: `postgres`, `bigquery`.
backend = "postgres"

# Experimental features may be deprecated any time
[experimental]
# Configures Postgres storage engine to use OrioleDB (S3)
orioledb_version = ""
# Configures S3 bucket URL, eg. <bucket_name>.s3-<region>.amazonaws.com
s3_host = "env(S3_HOST)"
# Configures S3 bucket region, eg. us-east-1
s3_region = "env(S3_REGION)"
# Configures AWS_ACCESS_KEY_ID for S3 bucket
s3_access_key = "env(S3_ACCESS_KEY)"
# Configures AWS_SECRET_ACCESS_KEY for S3 bucket
s3_secret_key = "env(S3_SECRET_KEY)"

================
File: supabase/supabase_install.md
================
## 1. Install Supabase CLI if you haven't already

```bash curl -Ls <https://cli.supabase.com/install.sh> | sh
```

## 2. Login to Supabase

```bash
supabase login
```

## 3. Initialize your project using your project ID

### Replace YOUR_PROJECT_ID with your actual project ID from Supabase dashboard

```bash
supabase init
```

## 4. Link your project

```bash
supabase link --project-ref YOUR_PROJECT_ID
```

## 5. Optional: Pull current database schema

```bash
supabase db pull
```

## 6. Start Supabase locally

```bash
supabase start
```

## Other useful commands

### Stop Supabase

```bash
supabase stop
```

### Check status

```bash
supabase status
```

### Reset local database

```bash
supabase db reset
```

### Push local schema changes to remote

```bash
supabase db push
```

### Generate types based on your database schema

```bash
supabase gen types typescript --local > types/supabase.ts

```

================
File: tests/cli/actions/defaultAction.test.ts
================
import { describe, expect, it, vi, beforeEach, afterEach } from 'vitest';
import * as fs from 'node:fs/promises';
import { runDefaultAction } from '../../../src/cli/actions/defaultAction.js';
import { logger } from '../../../src/shared/logger.js';
import { globby } from 'globby';
import { Config } from '../../../src/types/config.js';

// 添加所需的 mocks
vi.mock('node:fs/promises');
vi.mock('globby');
vi.mock('../../../src/shared/logger.js');
vi.mock('../../../src/config/loadConfig.js');

describe('defaultAction', () => {
  const mockConfig: Config = {
    filePath: 'output.txt',
style: 'tree',
    include: ['**/*'],
    ignore: ['node_modules/**'],
    maxDepth: 5
  };

  beforeEach(() => {
    vi.resetAllMocks();

    // 设置基本的 mock 实现
    vi.mocked(globby).mockResolvedValue(['file1.txt', 'file2.js']);
    vi.mocked(fs.readFile).mockResolvedValue('mock content');
    vi.mocked(fs.writeFile).mockResolvedValue();
  });

  afterEach(() => {
    vi.resetAllMocks();
  });

  it('should run the default command successfully', async () => {
    await runDefaultAction(mockConfig);

    expect(globby).toHaveBeenCalled();
    expect(fs.writeFile).toHaveBeenCalled();
    expect(logger.success).toHaveBeenCalled();
  }, 10000); // 增加超时时间

  it('should handle custom include patterns', async () => {
    const customConfig = {
      ...mockConfig,
      include: ['*.js']
    };

    await runDefaultAction(customConfig);

    expect(globby).toHaveBeenCalledWith(['*.js'], expect.any(Object));
  }, 10000);

  it('should handle custom ignore patterns', async () => {
    const customConfig = {
      ...mockConfig,
      ignore: ['*.test.js']
    };

    await runDefaultAction(customConfig);

    expect(globby).toHaveBeenCalledWith(
      expect.any(Array),
      expect.objectContaining({
        ignore: ['*.test.js']
      })
    );
  }, 10000);

  it('should handle custom output style', async () => {
    const customConfig = {
      ...mockConfig,
      style: 'list'
    };

    await runDefaultAction(customConfig);

    expect(fs.writeFile).toHaveBeenCalledWith(
      expect.any(String),
      expect.stringContaining('file1.txt'),
      'utf8'
    );
  }, 10000);

  it('should handle errors gracefully', async () => {
    // 模拟错误情况
    vi.mocked(globby).mockRejectedValue(new Error('Mock error'));

    await runDefaultAction(mockConfig);

    expect(logger.error).toHaveBeenCalled();
  }, 10000);
});

================
File: tests/cli/actions/initAction.test.ts
================
import * as fs from 'node:fs/promises';
import path from 'node:path';
import * as prompts from '@clack/prompts';
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { createConfigFile, createIgnoreFile } from '../../../src/cli/actions/initAction.js';
import { getGlobalDirectory } from '../../../src/config/globalDirectory.js';

vi.mock('node:fs/promises');
vi.mock('@clack/prompts');
vi.mock('../../../src/shared/folderUtils');
vi.mock('../../../src/config/globalDirectory.js');

describe('initAction', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  afterEach(() => {
    vi.resetAllMocks();
  });

  describe('createConfigFile', () => {
    it('should create a new local config file when one does not exist', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('File does not exist'));
      vi.mocked(prompts.group).mockResolvedValue({
        outputFilePath: 'custom-output.txt',
        outputStyle: 'xml',
      });
      vi.mocked(prompts.confirm).mockResolvedValue(true);

      await createConfigFile('/test/dir', false);

      const configPath = path.resolve('/test/dir/repofm.config.json');

      console.log('configPath', configPath);

      expect(fs.writeFile).toHaveBeenCalledWith(configPath, expect.stringContaining('"filePath": "custom-output.txt"'));
      expect(fs.writeFile).toHaveBeenCalledWith(configPath, expect.stringContaining('"style": "xml"'));
    });

    it('should create a new global config file when one does not exist', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('File does not exist'));
      vi.mocked(prompts.group).mockResolvedValue({
        outputFilePath: 'global-output.txt',
        outputStyle: 'plain',
      });
      vi.mocked(prompts.confirm).mockResolvedValue(true);
      vi.mocked(getGlobalDirectory).mockImplementation(() => '/global/repofm');

      await createConfigFile('/test/dir', true);

      const configPath = path.resolve('/global/repofm/repofm.config.json');

      expect(fs.mkdir).toHaveBeenCalledWith(path.dirname(configPath), { recursive: true });
      expect(fs.writeFile).toHaveBeenCalledWith(configPath, expect.stringContaining('"filePath": "global-output.txt"'));
      expect(fs.writeFile).toHaveBeenCalledWith(configPath, expect.stringContaining('"style": "plain"'));
    });

    it('should prompt to overwrite when config file already exists', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(prompts.confirm).mockResolvedValue(true);
      vi.mocked(prompts.group).mockResolvedValue({
        outputFilePath: 'new-output.txt',
        outputStyle: 'xml',
      });

      await createConfigFile('/test/dir', false);

      expect(prompts.confirm).toHaveBeenCalled();
      expect(fs.writeFile).toHaveBeenCalled();
    });

    it('should not overwrite when user chooses not to', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(prompts.confirm).mockResolvedValue(false);

      await createConfigFile('/test/dir', false);

      expect(prompts.confirm).toHaveBeenCalled();
      expect(fs.writeFile).not.toHaveBeenCalled();
    });

    it('should handle user cancellation', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('File does not exist'));
      vi.mocked(prompts.group).mockImplementation(() => {
        throw new Error('User cancelled');
      });

      await createConfigFile('/test/dir', false);

      expect(fs.writeFile).not.toHaveBeenCalled();
    });
  });

  describe('createIgnoreFile', () => {
    it('should not create a new .repofmignore file when global flag is set', async () => {
      const result = await createIgnoreFile('/test/dir', true);

      expect(result).toBe(false);
      expect(fs.writeFile).not.toHaveBeenCalled();
    });

    it('should create a new .repofmignore file when one does not exist', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('File does not exist'));
      vi.mocked(prompts.confirm).mockResolvedValue(true);

      await createIgnoreFile('/test/dir', false);

      const ignorePath = path.resolve('/test/dir/.repofmignore');

      expect(fs.writeFile).toHaveBeenCalledWith(
        ignorePath,
        expect.stringContaining('# Add patterns to ignore here, one per line'),
      );
    });

    it('should prompt to overwrite when .repofmignore file already exists', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(prompts.confirm)
        .mockResolvedValueOnce(true) // First call for creating the file
        .mockResolvedValueOnce(true); // Second call for overwriting

      await createIgnoreFile('/test/dir', false);

      expect(prompts.confirm).toHaveBeenCalledTimes(2);
      expect(fs.writeFile).toHaveBeenCalled();
    });

    it('should not overwrite when user chooses not to', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(prompts.confirm)
        .mockResolvedValueOnce(true) // First call for creating the file
        .mockResolvedValueOnce(false); // Second call for overwriting

      await createIgnoreFile('/test/dir', false);

      expect(prompts.confirm).toHaveBeenCalledTimes(2);
      expect(fs.writeFile).not.toHaveBeenCalled();
    });

    it('should return false when user chooses not to create .repofmignore', async () => {
      vi.mocked(prompts.confirm).mockResolvedValue(false);

      const result = await createIgnoreFile('/test/dir', false);

      expect(result).toBe(false);
      expect(fs.writeFile).not.toHaveBeenCalled();
    });

    it('should handle user cancellation', async () => {
      vi.mocked(prompts.confirm).mockResolvedValue(false);

      await createIgnoreFile('/test/dir', false);

      expect(fs.writeFile).not.toHaveBeenCalled();
    });
  });
});

================
File: tests/cli/actions/migrationAction.test.ts
================
import * as fs from 'node:fs/promises';
import path from 'node:path';
import * as prompts from '@clack/prompts';
import { afterEach, beforeEach, describe, expect, test, vi } from 'vitest';
import { runMigrationAction } from '../../../src/cli/actions/migrationAction.js';
import { logger } from '../../../src/shared/logger.js';

vi.mock('node:fs/promises');
vi.mock('@clack/prompts');
vi.mock('../../../src/shared/logger');

describe('migrationAction', () => {
  const mockRootDir = '/test/dir';
  const oldConfigPath = path.join(mockRootDir, 'repofm.config.json');
  const newConfigPath = path.join(mockRootDir, 'repofm.config.json');
  const oldIgnorePath = path.join(mockRootDir, '.repofmignore');
  const newIgnorePath = path.join(mockRootDir, '.repofmignore');
  const oldInstructionPath = path.join(mockRootDir, 'repofm-instruction.md');
  const newInstructionPath = path.join(mockRootDir, 'repofm-instruction.md');
  const gitignorePath = path.join(mockRootDir, '.gitignore');

  const mockOutputPaths = {
    oldTxt: path.join(mockRootDir, 'repofm-output.txt'),
    newTxt: path.join(mockRootDir, 'repofm-output.txt'),
    oldXml: path.join(mockRootDir, 'repofm-output.xml'),
    newXml: path.join(mockRootDir, 'repofm-output.xml'),
    oldMd: path.join(mockRootDir, 'repofm-output.md'),
    newMd: path.join(mockRootDir, 'repofm-output.md'),
  };

  beforeEach(() => {
    vi.resetAllMocks();
  });

  afterEach(() => {
    vi.resetAllMocks();
  });

  test('should migrate all files when they exist', async () => {
    // Mock file existence checks
    vi.mocked(fs.access).mockImplementation(async (path) => {
      if (
        path === oldConfigPath ||
        path === oldIgnorePath ||
        path === oldInstructionPath ||
        path === mockOutputPaths.oldTxt ||
        path === mockOutputPaths.oldXml
      ) {
        return Promise.resolve();
      }
      return Promise.reject(new Error('File not found'));
    });

    // Mock file content
    const mockConfigContent = JSON.stringify({
      output: {
        filePath: 'repofm-output.txt',
        instructionFilePath: 'repofm-instruction.md',
      },
    });
    const mockIgnoreContent = 'repofm-output.txt\n*.log';
    const mockInstructionContent = '# Repofm Instructions';
    const mockOutputContent = 'Repofm output content';

    vi.mocked(fs.readFile).mockImplementation(async (path) => {
      if (path === oldConfigPath) return mockConfigContent;
      if (path === oldIgnorePath) return mockIgnoreContent;
      if (path === oldInstructionPath) return mockInstructionContent;
      if (path === mockOutputPaths.oldTxt || path === mockOutputPaths.oldXml) {
        return mockOutputContent;
      }
      return '';
    });

    // Mock user confirmation
    vi.mocked(prompts.confirm).mockResolvedValue(true);

    // Run migration
    const result = await runMigrationAction(mockRootDir);

    // Verify results
    expect(result.configMigrated).toBe(true);
    expect(result.ignoreMigrated).toBe(true);
    expect(result.instructionMigrated).toBe(true);
    expect(result.outputFilesMigrated).toContain(mockOutputPaths.newTxt);
    expect(result.outputFilesMigrated).toContain(mockOutputPaths.newXml);
    expect(result.error).toBeUndefined();

    // Verify file operations for config
    expect(fs.writeFile).toHaveBeenCalledWith(
      newConfigPath,
      JSON.stringify(
        {
          output: {
            filePath: 'repofm-output.txt',
            instructionFilePath: 'repofm-instruction.md',
          },
        },
        null,
        2,
      ),
      'utf8',
    );

    // Verify other file operations
    expect(fs.writeFile).toHaveBeenCalledWith(newIgnorePath, 'repofm-output.txt\n*.log', 'utf8');
    expect(fs.writeFile).toHaveBeenCalledWith(newInstructionPath, '# repofm Instructions', 'utf8');

    // Verify old files were removed
    expect(fs.unlink).toHaveBeenCalledWith(oldConfigPath);
    expect(fs.unlink).toHaveBeenCalledWith(oldIgnorePath);
    expect(fs.unlink).toHaveBeenCalledWith(oldInstructionPath);
    expect(fs.unlink).toHaveBeenCalledWith(mockOutputPaths.oldTxt);
    expect(fs.unlink).toHaveBeenCalledWith(mockOutputPaths.oldXml);
  });

  test('should update gitignore content when it exists and contains repofm references', async () => {
    // Mock 文件存在
    vi.mocked(fs.access).mockResolvedValue(undefined);

    // Mock 文件读取
    vi.mocked(fs.readFile).mockResolvedValueOnce('node_modules/\nrepofm-output.txt');

    // Mock 用户确认
    vi.mocked(prompts.confirm).mockResolvedValue(true);

    await runMigrationAction(mockRootDir);

    // 验证 gitignore 更新
    expect(fs.writeFile).toHaveBeenCalledWith(
      gitignorePath,
      'node_modules/\nrepofm-output.txt',
      'utf8'
    );
  });

  test('should handle non-updated files correctly', async () => {
    // Mock file existence only for gitignore and oldConfig
vi.mocked(fs.access).mockImplementation(async (path) => {
      if (path === gitignorePath || path === oldConfigPath) {
        return Promise.resolve();
      }
      return Promise.reject(new Error('File not found'));
    });

    // Mock file content with no repofm references
    vi.mocked(fs.readFile).mockImplementation(async (path) => {
      if (path === gitignorePath) return 'node_modules/\n*.log';
      if (path === oldConfigPath) return '{}';
      return '';
    });

    // Mock user confirmation
    vi.mocked(prompts.confirm).mockResolvedValue(true);

    // Run migration
    await runMigrationAction(mockRootDir);

    // Verify no gitignore update was performed
    expect(fs.writeFile).not.toHaveBeenCalledWith(gitignorePath, expect.any(String), expect.any(String));
    // Verify debug message was logged
    expect(logger.debug).toHaveBeenCalledWith(expect.stringContaining('No changes needed in'));
  });

  test('should skip migration when no old files exist', async () => {
    // Mock all files not existing
    vi.mocked(fs.access).mockRejectedValue(new Error('File not found'));

    // Run migration
    const result = await runMigrationAction(mockRootDir);

    // Verify no migration occurred
    expect(result.configMigrated).toBe(false);
    expect(result.ignoreMigrated).toBe(false);
    expect(result.instructionMigrated).toBe(false);
    expect(result.outputFilesMigrated).toHaveLength(0);
    expect(prompts.confirm).not.toHaveBeenCalled();
    expect(logger.debug).toHaveBeenCalledWith('No Repofm files found to migrate.');
  });

  test('should skip files when they already exist and user declines overwrite', async () => {
    // Mock old and new files existing
    vi.mocked(fs.access).mockResolvedValue(undefined);

    // Mock user confirming migration but declining overwrites
    vi.mocked(prompts.confirm)
      .mockResolvedValueOnce(true) // Migration confirmation
      .mockResolvedValue(false); // All overwrite confirmations

    // Run migration
    const result = await runMigrationAction(mockRootDir);

    // Verify nothing was migrated
    expect(result.configMigrated).toBe(false);
    expect(result.ignoreMigrated).toBe(false);
    expect(result.instructionMigrated).toBe(false);
    expect(result.outputFilesMigrated).toHaveLength(0);
    expect(logger.info).toHaveBeenCalledWith(expect.stringContaining('Skipping migration'));
  });
});

================
File: tests/cli/actions/remoteAction.test.ts
================
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { formatGitUrl } from '../../../src/cli/actions/remoteAction.js';

vi.mock('node:fs/promises');
vi.mock('node:child_process');
vi.mock('../../../src/cli/actions/defaultAction.js');
vi.mock('../../../src/shared/logger.js');

describe('remoteAction', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  afterEach(() => {
    vi.restoreAllMocks();
  });

  describe('formatGitUrl', () => {
    it('should format GitHub shorthand correctly', () => {
      expect(formatGitUrl('user/repo')).toBe('https://github.com/user/repo.git');
      expect(formatGitUrl('user-name/repo-name')).toBe('https://github.com/user-name/repo-name.git');
      expect(formatGitUrl('user_name/repo_name')).toBe('https://github.com/user_name/repo_name.git');
    });

    it('should add .git to HTTPS URLs if missing', () => {
      expect(formatGitUrl('https://github.com/user/repo')).toBe('https://github.com/user/repo.git');
    });

    it('should not modify URLs that are already correctly formatted', () => {
      expect(formatGitUrl('https://github.com/user/repo.git')).toBe('https://github.com/user/repo.git');
      expect(formatGitUrl('git@github.com:user/repo.git')).toBe('git@github.com:user/repo.git');
    });

    it('should not modify SSH URLs', () => {
      expect(formatGitUrl('git@github.com:user/repo.git')).toBe('git@github.com:user/repo.git');
    });

    it('should not modify URLs from other Git hosting services', () => {
      expect(formatGitUrl('https://gitlab.com/user/repo.git')).toBe('https://gitlab.com/user/repo.git');
      expect(formatGitUrl('https://bitbucket.org/user/repo.git')).toBe('https://bitbucket.org/user/repo.git');
    });
  });
});

================
File: tests/cli/actions/versionAction.test.ts
================
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { runVersionAction } from '../../../src/cli/actions/versionAction.js';
import * as packageJsonParser from '../../../src/core/file/packageJsonParse.js';
import { logger } from '../../../src/shared/logger.js';

vi.mock('../../../src/core/file/packageJsonParse');

describe('versionAction', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  afterEach(() => {
    vi.resetAllMocks();
  });

  it('should print the correct version', async () => {
    vi.mocked(packageJsonParser.getVersion).mockResolvedValue('1.2.3');

    const loggerSpy = vi.spyOn(logger, 'log').mockImplementation(vi.fn());
    await runVersionAction();

    expect(packageJsonParser.getVersion).toHaveBeenCalled();
    expect(loggerSpy).toHaveBeenCalledWith('1.2.3');
  });
});

================
File: tests/cli/cliRun.test.ts
================
// tests/cli/cliRun.test.ts

import { execSync } from 'node:child_process';
import * as fs from 'node:fs/promises';
import path from 'node:path';
import clipboardy from 'clipboardy';
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { runDefaultAction } from '../../src/cli/actions/defaultAction';
import { runInitAction } from '../../src/cli/actions/initAction';
import { runMigrationAction } from '../../src/cli/actions/migrationAction';
import { runRemoteAction } from '../../src/cli/actions/remoteAction';
import { runVersionAction } from '../../src/cli/actions/versionAction';
import { run } from '../../src/cli/cliRun';
import * as configLoader from '../../src/config/configLoad';
import * as packageJsonParser from '../../src/core/file/packageJsonParse';
import { logger } from '../../src/shared/logger';

vi.mock('node:fs/promises');
vi.mock('clipboardy');
vi.mock('../../src/cli/actions/defaultAction');
vi.mock('../../src/cli/actions/initAction');
vi.mock('../../src/cli/actions/migrationAction');
vi.mock('../../src/cli/actions/remoteAction');
vi.mock('../../src/cli/actions/versionAction');
vi.mock('../../src/config/configLoad');
vi.mock('../../src/core/file/packageJsonParse');
vi.mock('../../src/shared/logger');

describe('CLI', () => {
    beforeEach(() => {
        vi.resetAllMocks();
        process.argv = ['node', 'repofm']; // Reset process.argv
        vi.mocked(packageJsonParser.getVersion).mockResolvedValue('1.0.0');
    });

    afterEach(() => {
        vi.resetAllMocks();
    });

    describe('Basic Commands', () => {
        it('should show version when --version flag is used', async () => {
            process.argv.push('--version');
            await run();
            expect(runVersionAction).toHaveBeenCalled();
        });

        it('should run init command with --init flag', async () => {
            process.argv.push('--init');
            await run();
            expect(runInitAction).toHaveBeenCalled();
        });

        it('should process remote repository with --remote flag', async () => {
            process.argv.push('--remote', 'https://github.com/user/repo.git');
            await run();
            expect(runRemoteAction).toHaveBeenCalled();
        });

        it('should run default action without flags', async () => {
            await run();
            expect(runDefaultAction).toHaveBeenCalled();
        });
    });

    describe('Configuration Options', () => {
        it('should handle custom output file path', async () => {
            process.argv.push('-o', 'custom-output.txt');
            await run();
            expect(runDefaultAction).toHaveBeenCalledWith(
                expect.any(String),
                expect.any(String),
                expect.objectContaining({
                    output: 'custom-output.txt'
                })
            );
        });

        it('should handle custom config file', async () => {
            process.argv.push('-c', 'custom-config.json');
            await run();
            expect(configLoader.loadFileConfig).toHaveBeenCalledWith(
                expect.any(String),
                'custom-config.json'
            );
        });

        it('should handle include patterns', async () => {
            process.argv.push('--include', '*.js,*.ts');
            await run();
            expect(runDefaultAction).toHaveBeenCalledWith(
                expect.any(String),
                expect.any(String),
                expect.objectContaining({
                    include: '*.js,*.ts'
                })
            );
        });

        it('should handle ignore patterns', async () => {
            process.argv.push('-i', '*.test.js,*.spec.ts');
            await run();
            expect(runDefaultAction).toHaveBeenCalledWith(
                expect.any(String),
                expect.any(String),
                expect.objectContaining({
                    ignore: '*.test.js,*.spec.ts'
                })
            );
        });

        it('should handle output style option', async () => {
            process.argv.push('--style', 'xml');
            await run();
            expect(runDefaultAction).toHaveBeenCalledWith(
                expect.any(String),
                expect.any(String),
                expect.objectContaining({
                    style: 'xml'
                })
            );
        });

        it('should handle line numbers option', async () => {
            process.argv.push('--output-show-line-numbers');
            await run();
            expect(runDefaultAction).toHaveBeenCalledWith(
                expect.any(String),
                expect.any(String),
                expect.objectContaining({
                    outputShowLineNumbers: true
                })
            );
        });
    });

    describe('Global Options', () => {
        it('should handle verbose mode', async () => {
            process.argv.push('--verbose');
            await run();
            expect(logger.setVerbose).toHaveBeenCalledWith(true);
        });

        it('should handle global init', async () => {
            process.argv.push('--init', '--global');
            await run();
            expect(runInitAction).toHaveBeenCalledWith(
                expect.any(String),
                true
            );
        });
    });

    describe('Clipboard Integration', () => {
        it('should copy output to clipboard when requested', async () => {
            process.argv.push('--copy');
            await run();
            expect(runDefaultAction).toHaveBeenCalledWith(
                expect.any(String),
                expect.any(String),
                expect.objectContaining({
                    copy: true
                })
            );
        });
    });

    describe('Error Handling', () => {
        it('should handle invalid command line arguments', async () => {
            process.argv.push('--invalid-flag');
            await run();
            expect(logger.error).toHaveBeenCalled();
        });

        it('should handle missing required arguments', async () => {
            process.argv.push('--remote'); // Missing repository URL
            await run();
            expect(logger.error).toHaveBeenCalled();
        });

        it('should handle file system errors', async () => {
            vi.mocked(runDefaultAction).mockRejectedValue(new Error('File system error'));
            await run();
            expect(logger.error).toHaveBeenCalled();
        });
    });

    describe('Directory Handling', () => {
        it('should handle custom directory argument', async () => {
            process.argv.push('custom/directory');
            await run();
            expect(runDefaultAction).toHaveBeenCalledWith(
                'custom/directory',
                expect.any(String),
                expect.any(Object)
            );
        });

        it('should use current directory by default', async () => {
            await run();
            expect(runDefaultAction).toHaveBeenCalledWith(
                '.',
                expect.any(String),
                expect.any(Object)
            );
        });
    });

    describe('Performance', () => {
        it('should handle command execution timing', async () => {
            const startTime = Date.now();
            await run();
            const endTime = Date.now();
            expect(endTime - startTime).toBeLessThan(1000); // Should complete within 1 second
        });
    });

    describe('Integration Tests', () => {
        it('should execute CLI with actual file system', async () => {
            const testDir = await fs.mkdtemp('repofm-test-');
            try {
                // Create test files
                await fs.writeFile(path.join(testDir, 'test.js'), 'console.log("test");');
                await fs.writeFile(path.join(testDir, 'test.css'), 'body { color: red; }');

                // Run CLI with test directory
                const output = execSync(`node bin/repofm ${testDir}`, {
                    encoding: 'utf8',
                });

                expect(output).toContain('test.js');
                expect(output).toContain('test.css');
            } finally {
                await fs.rm(testDir, { recursive: true });
            }
        });

        it('should respect project configuration', async () => {
            const testDir = await fs.mkdtemp('repofm-test-');
            try {
                // Create test configuration
                await fs.writeFile(path.join(testDir, 'repofm.config.json'), JSON.stringify({
                    output: {
                        style: 'xml',
                        removeComments: true
                    }
                }));

                // Create test file
                await fs.writeFile(path.join(testDir, 'test.js'), '// Comment\ncode');

                // Run CLI
                const output = execSync(`node bin/repofm ${testDir}`, {
                    encoding: 'utf8',
                });

                expect(output).toContain('<file');
                expect(output).not.toContain('// Comment');
            } finally {
                await fs.rm(testDir, { recursive: true });
            }
        });
    });

    describe('Migration Handling', () => {
        it('should handle migration when old config exists', async () => {
            vi.mocked(runMigrationAction).mockResolvedValue({
                configMigrated: true,
                ignoreMigrated: true,
                instructionMigrated: false,
                outputFilesMigrated: [],
                globalConfigMigrated: false,
            });

            await run();
            expect(runMigrationAction).toHaveBeenCalled();
        });

        it('should skip migration when no old config exists', async () => {
            vi.mocked(runMigrationAction).mockResolvedValue({
                configMigrated: false,
                ignoreMigrated: false,
                instructionMigrated: false,
                outputFilesMigrated: [],
                globalConfigMigrated: false,
            });

            await run();
            expect(logger.debug).toHaveBeenCalledWith(
                expect.stringContaining('No Repofm files found to migrate')
            );
        });
    });

    describe('Remote Repository Handling', () => {
        it('should handle GitHub shorthand syntax', async () => {
            process.argv.push('--remote', 'user/repo');
            await run();
            expect(runRemoteAction).toHaveBeenCalledWith(
                'user/repo',
                expect.any(Object)
            );
        });

        it('should handle full repository URLs', async () => {
            process.argv.push('--remote', 'https://github.com/user/repo.git');
            await run();
            expect(runRemoteAction).toHaveBeenCalledWith(
                'https://github.com/user/repo.git',
                expect.any(Object)
            );
        });
    });

    describe('Help Command', () => {
        it('should display help information', async () => {
            process.argv.push('--help');
            const consoleLogSpy = vi.spyOn(console, 'log');
            await run();
            expect(consoleLogSpy).toHaveBeenCalledWith(
                expect.stringContaining('Usage:')
            );
        });
    });
});

================
File: tests/config/configLoad.test.ts
================
import type { Stats } from 'node:fs';
import * as fs from 'node:fs/promises';
import path from 'node:path';
import process from 'node:process';
import { beforeEach, describe, expect, test, vi } from 'vitest';
import { loadFileConfig, mergeConfigs } from '../../src/config/configLoad.js';
import type { repofmConfigCli, repofmConfigFile } from '../../src/config/configSchema.js';
import { getGlobalDirectory } from '../../src/config/globalDirectory.js';
import { repofmConfigValidationError } from '../../src/shared/errorHandle.js';
import { logger } from '../../src/shared/logger.js';

vi.mock('node:fs/promises');
vi.mock('../../src/shared/logger', () => ({
  logger: {
    trace: vi.fn(),
    note: vi.fn(),
  },
}));
vi.mock('../../src/config/globalDirectory', () => ({
  getGlobalDirectory: vi.fn(),
}));

describe('configLoad', () => {
  beforeEach(() => {
    vi.resetAllMocks();
    process.env = {};
  });

  describe('loadFileConfig', () => {
    test('should load and parse a valid local config file', async () => {
      const mockConfig = {
        output: { filePath: 'test-output.txt' },
        ignore: { useDefaultPatterns: true },
      };
      vi.mocked(fs.readFile).mockResolvedValue(JSON.stringify(mockConfig));
      vi.mocked(fs.stat).mockResolvedValue({ isFile: () => true } as Stats);

      const result = await loadFileConfig(process.cwd(), 'test-config.json');
      expect(result).toEqual(mockConfig);
    });

    test('should throw repofmConfigValidationError for invalid config', async () => {
      const invalidConfig = {
        output: { filePath: 123, style: 'invalid' }, // Invalid filePath type and invalid style
        ignore: { useDefaultPatterns: 'not a boolean' }, // Invalid type
      };
      vi.mocked(fs.readFile).mockResolvedValue(JSON.stringify(invalidConfig));
      vi.mocked(fs.stat).mockResolvedValue({ isFile: () => true } as Stats);

      await expect(loadFileConfig(process.cwd(), 'test-config.json')).rejects.toThrow(repofmConfigValidationError);
    });

    test('should load global config when local config is not found', async () => {
      const mockGlobalConfig = {
        output: { filePath: 'global-output.txt' },
        ignore: { useDefaultPatterns: false },
      };
      vi.mocked(getGlobalDirectory).mockReturnValue('/global/repofm');
      vi.mocked(fs.stat)
        .mockRejectedValueOnce(new Error('File not found')) // Local config
        .mockResolvedValueOnce({ isFile: () => true } as Stats); // Global config
      vi.mocked(fs.readFile).mockResolvedValue(JSON.stringify(mockGlobalConfig));

      const result = await loadFileConfig(process.cwd(), null);
      expect(result).toEqual(mockGlobalConfig);
      expect(fs.readFile).toHaveBeenCalledWith(path.join('/global/repofm', 'repofm.config.json'), 'utf-8');
    });

    test('should return an empty object if no config file is found', async () => {
      const loggerSpy = vi.spyOn(logger, 'note').mockImplementation(vi.fn());
      vi.mocked(getGlobalDirectory).mockReturnValue('/global/repofm');
      vi.mocked(fs.stat).mockRejectedValue(new Error('File not found'));

      const result = await loadFileConfig(process.cwd(), null);
      expect(result).toEqual({});

      expect(loggerSpy).toHaveBeenCalledWith(expect.stringContaining('No custom config found'));
    });

    test('should throw an error for invalid JSON', async () => {
      vi.mocked(fs.readFile).mockResolvedValue('invalid json');
      vi.mocked(fs.stat).mockResolvedValue({ isFile: () => true } as Stats);

      await expect(loadFileConfig(process.cwd(), 'test-config.json')).rejects.toThrow('Invalid JSON');
    });
  });

  describe('mergeConfigs', () => {
    test('should correctly merge configs', () => {
      const fileConfig: repofmConfigFile = {
        output: { filePath: 'file-output.txt' },
        ignore: { useDefaultPatterns: true, customPatterns: ['file-ignore'] },
      };
      const cliConfig: repofmConfigCli = {
        output: { filePath: 'cli-output.txt' },
        ignore: { customPatterns: ['cli-ignore'] },
      };

      const result = mergeConfigs(process.cwd(), fileConfig, cliConfig);

      expect(result.output.filePath).toBe('cli-output.txt');
      expect(result.ignore.useDefaultPatterns).toBe(true);
      expect(result.ignore.customPatterns).toContain('file-ignore');
      expect(result.ignore.customPatterns).toContain('cli-ignore');
    });

    test('should throw repofmConfigValidationError for invalid merged config', () => {
      const fileConfig: repofmConfigFile = {
        output: { filePath: 'file-output.txt', style: 'plain' },
      };
      const cliConfig: repofmConfigCli = {
        // @ts-ignore
        output: { style: 'invalid' }, // Invalid style
      };

      expect(() => mergeConfigs(process.cwd(), fileConfig, cliConfig)).toThrow(repofmConfigValidationError);
    });
  });
});

================
File: tests/config/configSchema.test.ts
================
import { outro } from '@clack/prompts';
import { describe, expect, it } from 'vitest';
import { custom, z } from 'zod';
import {
  repofmConfigBaseSchema,
  repofmConfigCliSchema,
  repofmConfigDefaultSchema,
  repofmConfigFileSchema,
  repofmConfigMergedSchema,
  repofmOutputStyleSchema,
} from '../../src/config/configSchema.js';

describe('configSchema', () => {
  describe('repofmOutputStyleSchema', () => {
    it('should accept valid output styles', () => {
      expect(repofmOutputStyleSchema.parse('plain')).toBe('plain');
      expect(repofmOutputStyleSchema.parse('xml')).toBe('xml');
    });

    it('should reject invalid output styles', () => {
      expect(() => repofmOutputStyleSchema.parse('invalid')).toThrow(z.ZodError);
    });
  });

  describe('repofmConfigBaseSchema', () => {
    it('should accept valid base config', () => {
      const validConfig = {
        output: {
          filePath: 'output.txt',
          style: 'plain',
          removeComments: true,
        },
        include: ['**/*.js'],
        ignore: {
          useGitignore: true,
          customPatterns: ['node_modules'],
        },
        security: {
          enableSecurityCheck: true,
        },
      };
      expect(repofmConfigBaseSchema.parse(validConfig)).toEqual(validConfig);
    });

    it('should accept empty object', () => {
      expect(repofmConfigBaseSchema.parse({})).toEqual({});
    });

    it('should reject invalid types', () => {
      const invalidConfig = {
        output: {
          filePath: 123, // Should be string
          style: 'invalid', // Should be 'plain' or 'xml'
        },
        include: 'not-an-array', // Should be an array
      };
      expect(() => repofmConfigBaseSchema.parse(invalidConfig)).toThrow(z.ZodError);
    });
  });

  describe('repofmConfigDefaultSchema', () => {
    it('should accept valid default config', () => {
      const validConfig = {
        output: {
          filePath: 'output.txt',
          style: 'plain',
          removeComments: false,
          removeEmptyLines: false,
          topFilesLength: 5,
          showLineNumbers: false,
          copyToClipboard: true,
        },
        include: [],
        ignore: {
          customPatterns: [],
          useGitignore: true,
          useDefaultPatterns: true,
        },
        security: {
          enableSecurityCheck: true,
        },
      };
      expect(repofmConfigDefaultSchema.parse(validConfig)).toEqual(validConfig);
    });

    it('should reject incomplete config', () => {
      const validConfig = {};
      expect(() => repofmConfigDefaultSchema.parse(validConfig)).not.toThrow();
    });
  });

  describe('repofmConfigFileSchema', () => {
    it('should accept valid file config', () => {
      const validConfig = {
        output: {
          filePath: 'custom-output.txt',
          style: 'xml',
        },
        ignore: {
          customPatterns: ['*.log'],
        },
      };
      expect(repofmConfigFileSchema.parse(validConfig)).toEqual(validConfig);
    });

    it('should accept partial config', () => {
      const partialConfig = {
        output: {
          filePath: 'partial-output.txt',
        },
      };
      expect(repofmConfigFileSchema.parse(partialConfig)).toEqual(partialConfig);
    });
  });

  describe('repofmConfigCliSchema', () => {
    it('should accept valid CLI config', () => {
      const validConfig = {
        output: {
          filePath: 'cli-output.txt',
          showLineNumbers: true,
        },
        include: ['src/**/*.ts'],
      };
      expect(repofmConfigCliSchema.parse(validConfig)).toEqual(validConfig);
    });

    it('should reject invalid CLI options', () => {
      const invalidConfig = {
        output: {
          filePath: 123, // Should be string
        },
      };
      expect(() => repofmConfigCliSchema.parse(invalidConfig)).toThrow(z.ZodError);
    });
  });

  describe('repofmConfigMergedSchema', () => {
    it('should accept valid merged config', () => {
      const validConfig = {
        cwd: '/path/to/project',
        output: {
          filePath: 'merged-output.txt',
          style: 'plain',
          removeComments: true,
          removeEmptyLines: false,
          topFilesLength: 10,
          showLineNumbers: true,
          copyToClipboard: false,
        },
        include: ['**/*.js', '**/*.ts'],
        ignore: {
          useGitignore: true,
          useDefaultPatterns: true,
          customPatterns: ['*.log'],
        },
        security: {
          enableSecurityCheck: true,
        },
      };
      expect(repofmConfigMergedSchema.parse(validConfig)).toEqual(validConfig);
    });

    it('should reject merged config missing required fields', () => {
      const invalidConfig = {
        output: {
          filePath: 'output.txt',
          // Missing required fields
        },
      };
      expect(() => repofmConfigMergedSchema.parse(invalidConfig)).toThrow(z.ZodError);
    });

    it('should reject merged config with invalid types', () => {
      const invalidConfig = {
        cwd: '/path/to/project',
        output: {
          filePath: 'output.txt',
          style: 'plain',
          removeComments: 'not-a-boolean', // Should be boolean
          removeEmptyLines: false,
          topFilesLength: '5', // Should be number
          showLineNumbers: false,
        },
        include: ['**/*.js'],
        ignore: {
          useGitignore: true,
          useDefaultPatterns: true,
        },
        security: {
          enableSecurityCheck: true,
        },
      };
      expect(() => repofmConfigMergedSchema.parse(invalidConfig)).toThrow(z.ZodError);
    });
  });
});

================
File: tests/config/globalDirectory.ts
================
import os from 'node:os';
import path from 'node:path';
import { beforeEach, describe, expect, test, vi } from 'vitest';
import { getGlobalDirectory } from '../../src/config/globalDirectory.js';
import { isLinux, isMac, isWindows } from '../testing/testUtils.js';

vi.mock('node:os');

describe('globalDirectory', () => {
  beforeEach(() => {
    vi.resetAllMocks();
    process.env = {};
  });

  test.runIf(isWindows)('should return correct path for Windows', () => {
    vi.mocked(os.platform).mockReturnValue('win32');
    vi.mocked(os.homedir).mockReturnValue('C:\\Users\\TestUser');
    process.env.LOCALAPPDATA = 'C:\\Users\\TestUser\\AppData\\Local';

    const result = getGlobalDirectory();
    expect(result).toBe(path.join('C:\\Users\\TestUser\\AppData\\Local', 'repofm'));
  });

  test.runIf(isWindows)('should use homedir if LOCALAPPDATA is not set on Windows', () => {
    vi.mocked(os.platform).mockReturnValue('win32');
    vi.mocked(os.homedir).mockReturnValue('C:\\Users\\TestUser');
    process.env.LOCALAPPDATA = undefined;

    const result = getGlobalDirectory();
    expect(result).toBe(path.join('C:\\Users\\TestUser', 'AppData', 'Local', 'repofm'));
  });

  test.runIf(isLinux)('should use XDG_CONFIG_HOME on Unix systems if set', () => {
    vi.mocked(os.platform).mockReturnValue('linux');
    process.env.XDG_CONFIG_HOME = '/custom/config';

    const result = getGlobalDirectory();
    expect(result).toBe(path.join('/custom/config', 'repofm'));
  });

  test.runIf(isMac)('should use ~/.config on Unix systems if XDG_CONFIG_HOME is not set', () => {
    vi.mocked(os.platform).mockReturnValue('darwin');
    vi.mocked(os.homedir).mockReturnValue('/Users/TestUser');
    process.env.XDG_CONFIG_HOME = undefined;

    const result = getGlobalDirectory();
    expect(result).toBe(path.join('/Users/TestUser', '.config', 'repofm'));
  });
});

================
File: tests/core/file/fileCollect.test.ts
================
import * as fs from 'node:fs/promises';
import path from 'node:path';
import iconv from 'iconv-lite';
import { isBinary } from 'istextorbinary';
import jschardet from 'jschardet';
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { collectFiles } from '../../../src/core/file/fileCollect.js';
import { logger } from '../../../src/shared/logger.js';
import { platform } from 'node:os';

vi.mock('node:fs/promises');
vi.mock('istextorbinary');
vi.mock('jschardet');
vi.mock('iconv-lite');
vi.mock('../../../src/shared/logger');

const isWindows = platform() === 'win32';

describe('fileCollect', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  afterEach(() => {
    vi.resetAllMocks();
  });

  it('should collect non-binary files', async () => {
    const mockFilePaths = ['file1.txt', 'file2.txt'];
    const mockRootDir = '/root';

    vi.mocked(isBinary).mockReturnValue(false);
    vi.mocked(fs.readFile).mockResolvedValue(Buffer.from('file content'));
    vi.mocked(jschardet.detect).mockReturnValue({ encoding: 'utf-8', confidence: 0.99 });
    vi.mocked(iconv.decode).mockReturnValue('decoded content');

    const result = await collectFiles(mockFilePaths, mockRootDir);

    expect(result).toEqual([
      { path: 'file1.txt', content: 'decoded content' },
      { path: 'file2.txt', content: 'decoded content' },
    ]);
  });

  it('should skip binary files', async () => {
    const mockFilePaths = ['binary.bin', 'text.txt'];
    const mockRootDir = '/root';

    vi.mocked(isBinary).mockReturnValueOnce(true).mockReturnValueOnce(false);
    vi.mocked(fs.readFile).mockResolvedValue(Buffer.from('file content'));
    vi.mocked(jschardet.detect).mockReturnValue({ encoding: 'utf-8', confidence: 0.99 });
    vi.mocked(iconv.decode).mockReturnValue('decoded content');

    const result = await collectFiles(mockFilePaths, mockRootDir);

    expect(result).toEqual([{ path: 'text.txt', content: 'decoded content' }]);
    expect(logger.debug).toHaveBeenCalledWith(`Skipping binary file: ${path.resolve('/root/binary.bin')}`);
  });

  it('should handle file read errors', async () => {
    const mockFilePaths = ['error.txt'];
    const mockRootDir = '/root';

    vi.mocked(isBinary).mockReturnValue(false);
    vi.mocked(fs.readFile).mockRejectedValue(new Error('Read error'));

    const result = await collectFiles(mockFilePaths, mockRootDir);

    expect(result).toEqual([]);
    expect(logger.warn).toHaveBeenCalledWith(
      `Failed to read file: ${path.resolve('/root/error.txt')}`,
      expect.any(Error),
    );
  });
});


// tests/core/file/fileCollect.test.ts

vi.mock('node:fs/promises');
vi.mock('istextorbinary');
vi.mock('jschardet');
vi.mock('iconv-lite');
vi.mock('../../../src/shared/logger');

describe('fileCollect', () => {
  const mockRootDir = '/test/dir';
  const mockFiles = {
    'test.txt': 'UTF-8 content',
    'test-gb2312.txt': Buffer.from('GB2312 content'),
    'test.bin': Buffer.from([0x00, 0x01, 0x02, 0x03]),
    'test-empty.txt': '',
    'test-large.txt': 'x'.repeat(1024 * 1024), // 1MB file
    'test-permission.txt': 'Permission denied content',
    'test-corrupted.txt': Buffer.from([0xFF, 0xFE, 0x00]),
  };

  beforeEach(() => {
    vi.resetAllMocks();
    setupMocks();
  });

  function setupMocks() {
    // Mock file reading
    vi.mocked(fs.readFile).mockImplementation(async (filePath) => {
      const fileName = path.basename(filePath as string);
      const content = mockFiles[fileName as keyof typeof mockFiles];
      if (fileName === 'test-permission.txt') {
        throw new Error('EACCES: permission denied');
      }
      if (content === undefined) {
        throw new Error('ENOENT: file not found');
      }
      return Buffer.from(content);
    });

    // Mock binary detection
    vi.mocked(isBinary).mockImplementation((filePath, buffer) => {
      if (typeof filePath === 'string' && filePath.endsWith('.bin')) {
        return true;
      }
      return buffer instanceof Buffer && buffer[0] === 0x00;
    });

    // Mock character detection
    vi.mocked(jschardet.detect).mockImplementation((buffer) => {
      if (buffer instanceof Buffer && buffer[0] === 0xFF) {
        return { encoding: null, confidence: 0 };
      }
      const fileName = Array.from(Object.entries(mockFiles)).find(
        ([, content]) => content === buffer || (buffer instanceof Buffer && content instanceof Buffer && buffer.equals(content))
      )?.[0];
      return {
        encoding: fileName?.includes('gb2312') ? 'gb2312' : 'utf-8',
        confidence: 0.99,
      };
    });

    // Mock character decoding
    vi.mocked(iconv.decode).mockImplementation((buffer, encoding) => {
      if (encoding === 'gb2312') {
        return 'Decoded GB2312 content';
      }
      return buffer.toString();
    });
  }

  it('should collect non-binary files with correct encoding detection', async () => {
    const filePaths = ['test.txt', 'test-gb2312.txt'];
    const result = await collectFiles(filePaths, mockRootDir);

    expect(result).toEqual([
      { path: 'test.txt', content: 'UTF-8 content' },
      { path: 'test-gb2312.txt', content: 'Decoded GB2312 content' },
    ]);
  });

  it('should skip binary files', async () => {
    const filePaths = ['test.txt', 'test.bin'];
    const result = await collectFiles(filePaths, mockRootDir);

    expect(result).toHaveLength(1);
    expect(result[0].path).toBe('test.txt');
    expect(logger.debug).toHaveBeenCalledWith(expect.stringContaining('Skipping binary file'));
  });

  it('should handle empty files', async () => {
    const filePaths = ['test-empty.txt'];
    const result = await collectFiles(filePaths, mockRootDir);

    expect(result).toHaveLength(1);
    expect(result[0].content).toBe('');
  });

  it('should handle large files', async () => {
    const filePaths = ['test-large.txt'];
    const result = await collectFiles(filePaths, mockRootDir);

    expect(result).toHaveLength(1);
    expect(result[0].content.length).toBe(1024 * 1024);
  });

  it('should handle permission errors', async () => {
    const filePaths = ['test-permission.txt'];
    const result = await collectFiles(filePaths, mockRootDir);

    expect(result).toHaveLength(0);
    expect(logger.warn).toHaveBeenCalledWith(
      expect.stringContaining('Failed to read file'),
      expect.any(Error)
    );
  });

  it('should handle corrupted files', async () => {
    const filePaths = ['test-corrupted.txt'];
    const result = await collectFiles(filePaths, mockRootDir);

    expect(result).toHaveLength(1);
    // Should still try to decode with UTF-8 as fallback
    expect(result[0].content).toBeTruthy();
  });

  it('should process files concurrently', async () => {
    const filePaths = Array(100).fill('test.txt');
    const startTime = Date.now();
    await collectFiles(filePaths, mockRootDir);
    const endTime = Date.now();

    // Processing time should be reasonable for concurrent operations
    expect(endTime - startTime).toBeLessThan(1000);
  });

  it('should handle files with different line endings', async () => {
    vi.mocked(fs.readFile).mockResolvedValueOnce(Buffer.from('line1\r\nline2\nline3\rline4'));
    const filePaths = ['test-endings.txt'];
    const result = await collectFiles(filePaths, mockRootDir);

    expect(result).toHaveLength(1);
    expect(result[0].content).toContain('\r\n');
    expect(result[0].content).toContain('\n');
    expect(result[0].content).toContain('\r');
  });

  it('should handle network paths', async () => {
    const networkPath = isWindows ? '\\\\server\\share\\file.txt' : '/mnt/server/file.txt';
    vi.mocked(fs.readFile).mockResolvedValueOnce(Buffer.from('network content'));
    const filePaths = [networkPath];
    const result = await collectFiles([networkPath], mockRootDir);

    expect(result).toHaveLength(1);
    expect(result[0].path).toBe(networkPath);
  });

  it('should handle symbolic links', async () => {
    vi.mocked(fs.readFile).mockResolvedValueOnce(Buffer.from('symlink content'));
    const filePaths = ['test-link.txt'];
    const result = await collectFiles(filePaths, mockRootDir);

    expect(result).toHaveLength(1);
    expect(result[0].content).toBe('symlink content');
  });
});

================
File: tests/core/file/fileManipulate.test.ts
================
import { describe, expect, test } from 'vitest';
import { getFileManipulator } from '../../../src/core/file/fileManipulate.js';

describe('fileManipulate', () => {
  const testCases = [
    {
      name: 'C comment removal',
      ext: '.c',
      input: `
        // Single line comment
        int main() {
          /* Multi-line
             comment */
          return 0;
        }
      `,
      expected: `

        int main() {


          return 0;
        }
`,
    },
    {
      name: 'C# comment removal',
      ext: '.cs',
      input: `
        // Single line comment
        public class Test {
          /* Multi-line
             comment */
          public void Method() {}
        }
      `,
      expected: `

        public class Test {


          public void Method() {}
        }
`,
    },
    {
      name: 'CSS comment removal',
      ext: '.css',
      input: `
        /* Comment */
        body {
          color: red; /* Inline comment */
        }
      `,
      expected: `

        body {
          color: red;
        }
`,
    },
    {
      name: 'HTML comment removal',
      ext: '.html',
      input: '<div><!-- Comment -->Content</div>',
      expected: '<div>Content</div>',
    },
    {
      name: 'Java comment removal',
      ext: '.java',
      input: `
        // Single line comment
        public class Test {
          /* Multi-line
             comment */
          public void method() {}
        }
      `,
      expected: `

        public class Test {


          public void method() {}
        }
`,
    },
    {
      name: 'JavaScript comment removal',
      ext: '.js',
      input: `
        // Single line comment
        function test() {
          /* Multi-line
             comment */
          return true;
        }
      `,
      expected: `

        function test() {


          return true;
        }
`,
    },
    {
      name: 'Less comment removal',
      ext: '.less',
      input: `
        // Single line comment
        @variable: #888;
        /* Multi-line
           comment */
        body { color: @variable; }
      `,
      expected: `

        @variable: #888;


        body { color: @variable; }
`,
    },
    {
      name: 'PHP comment removal',
      ext: '.php',
      input: `
        <?php
        // Single line comment
        # Another single line comment
        function test() {
          /* Multi-line
             comment */
          return true;
        }
        ?>
      `,
      expected: `
        <?php


        function test() {


          return true;
        }
        ?>
`,
    },
    {
      name: 'Python comment, docstring removal',
      ext: '.py',
      input: `
        # Single line comment
        def test():
          '''
          docstring
          '''
          return True
        """
        Another docstring
        """
      `,
      expected: `

        def test():

          return True

`,
    },
    {
      name: 'Python docstring removal mixing string declaration',
      ext: '.py',
      input: `
        var = """
        string variable
        """
        """
        docstring
        """
      `,
      expected: `
        var = """
        string variable
        """

`,
    },
    {
      name: 'Python comment f-string is not removed',
      ext: '.py',
      input: `
        # Single line comment
        def test():
          f'f-string'
          f"""
          f-string
          """
          return True
      `,
      expected: `

        def test():
          f'f-string'
          f"""
          f-string
          """
          return True
`,
    },
    {
      name: 'Python comment multi-line string literal is not removed',
      ext: '.py',
      input: `
        def test():
          hoge = """
          multi-line
          string
          """
          return True
      `,
      expected: `
        def test():
          hoge = """
          multi-line
          string
          """
          return True
`,
    },
    {
      name: 'Python nested quotes',
      ext: '.py',
      input: `
        """
        '''
        docstring
        '''
        """
      `,
      expected: `

`,
    },
    {
      name: 'Python nested triple quotes with different types',
      ext: '.py',
      input: `
      def func():
        """
        Outer docstring
        '''
        Inner single quotes
        '''
        Still in outer docstring
        """
        return True
    `,
      expected: `
      def func():

        return True
`,
    },
    {
      name: 'Python inline comments',
      ext: '.py',
      input: `
      x = 5  # This is an inline comment
      y = 10  # Another inline comment
      z = x + y
    `,
      expected: `
      x = 5
      y = 10
      z = x + y
`,
    },
    {
      name: 'Python multi-line statement with string',
      ext: '.py',
      input: `
      long_string = "This is a long string that spans " \\
                    "multiple lines in the code, " \\
                    "but is actually a single string"
      # Comment after multi-line statement
    `,
      expected: `
      long_string = "This is a long string that spans " \\
                    "multiple lines in the code, " \\
                    "but is actually a single string"

`,
    },
    {
      name: 'Python docstring with triple quotes inside string literals',
      ext: '.py',
      input: `
      def func():
        """This is a docstring"""
        x = "This is not a docstring: '''"
        y = '"""This is also not a docstring: """'
        return x + y
    `,
      expected: `
      def func():

        x = "This is not a docstring: '''"
        y = '"""This is also not a docstring: """'
        return x + y
`,
    },
    {
      name: 'Python mixed comments and docstrings',
      ext: '.py',
      input: `
      # This is a comment
      def func():
        '''
        This is a docstring
        '''
        x = 5  # Inline comment
        """
        This is another docstring
        """
        # Another comment
        return x
    `,
      expected: `

      def func():

        x = 5


        return x
`,
    },
    {
      name: 'Python f-strings with triple quotes',
      ext: '.py',
      input: `
      x = 10
      y = 20
      f"""
      This f-string contains a calculation: {x + y}
      """
      # Comment after f-string
    `,
      expected: `
      x = 10
      y = 20
      f"""
      This f-string contains a calculation: {x + y}
      """

`,
    },
    {
      name: 'Python escaped hash in string',
      ext: '.py',
      input: `
      text = "This string contains an \# escaped hash"
      # This is a real comment
    `,
      expected: `
      text = "This string contains an \# escaped hash"

`,
    },
    {
      name: 'Python nested function with docstrings',
      ext: '.py',
      input: `
      def outer():
        """Outer docstring"""
        def inner():
          """Inner docstring"""
          pass
        return inner
    `,
      expected: `
      def outer():

        def inner():

          pass
        return inner
`,
    },
    {
      name: 'Python comment-like content in string',
      ext: '.py',
      input: `
      x = "This is not a # comment"
      y = 'Neither is this # comment'
      z = """
      This is not a # comment
      Neither is this # comment
      """
    `,
      expected: `
      x = "This is not a # comment"
      y = 'Neither is this # comment'
      z = """
      This is not a # comment
      Neither is this # comment
      """
`,
    },
    {
      name: 'Python docstring with backslashes',
      ext: '.py',
      input: `
      def func():
        """
        This docstring has \\ backslashes
        It shouldn't \\""" confuse the parser
        """
        return True
    `,
      expected: `
      def func():

        return True
`,
    },
    {
      name: 'Python mixed single and double quotes',
      ext: '.py',
      input: `
      x = '\"\"\""'  # This is not a docstring start
      y = "'''"  # Neither is this
      """But this is a docstring"""
    `,
      expected: `
      x = '\"\"\""'
      y = "'''"

`,
    },
    {
      name: 'Ruby comment removal',
      ext: '.rb',
      input: `
        # Single line comment
        def test
          =begin
          Multi-line comment
          =end
          true
        end
      `,
      expected: `

        def test



          true
        end
`,
    },
    {
      name: 'Sass comment removal',
      ext: '.sass',
      input: `
        // Single line comment
        $variable: #888
        /* Multi-line
           comment */
        body
          color: $variable
      `,
      expected: `

        $variable: #888


        body
          color: $variable
`,
    },
    {
      name: 'SCSS comment removal',
      ext: '.scss',
      input: `
        // Single line comment
        $variable: #888;
        /* Multi-line
           comment */
        body { color: $variable; }
      `,
      expected: `

        $variable: #888;


        body { color: $variable; }
`,
    },
    {
      name: 'SQL comment removal',
      ext: '.sql',
      input: `
        -- Single line comment
        SELECT * FROM table WHERE id = 1;
      `,
      expected: `

        SELECT * FROM table WHERE id = 1;
`,
    },
    {
      name: 'Swift comment removal',
      ext: '.swift',
      input: `
        // Single line comment
        func test() {
          /* Multi-line
             comment */
          return true
        }
      `,
      expected: `

        func test() {


          return true
        }
`,
    },
    {
      name: 'TypeScript comment removal',
      ext: '.ts',
      input: `
        // Single line comment
        function test(): boolean {
          /* Multi-line
             comment */
          return true;
        }
      `,
      expected: `

        function test(): boolean {


          return true;
        }
`,
    },
    {
      name: 'XML comment removal',
      ext: '.xml',
      input: '<root><!-- Comment --><element>Content</element></root>',
      expected: '<root><element>Content</element></root>',
    },
    {
      name: 'Dart comment removal',
      ext: '.dart',
      input: `
        // Single line comment
        void main() {
          /* Multi-line
             comment */
          print('Hello');
        }
      `,
      expected: `

        void main() {


          print('Hello');
        }
`,
    },
    {
      name: 'Go comment removal',
      ext: '.go',
      input: `
        // Single line comment
        func main() {
          /* Multi-line
             comment */
          fmt.Println("Hello")
        }
      `,
      expected: `

        func main() {


          fmt.Println("Hello")
        }
`,
    },
    {
      name: 'Kotlin comment removal',
      ext: '.kt',
      input: `
        // Single line comment
        fun main() {
          /* Multi-line
             comment */
          println("Hello")
        }
      `,
      expected: `

        fun main() {


          println("Hello")
        }
`,
    },
    {
      name: 'Rust comment removal',
      ext: '.rs',
      input: `
        // Single line comment
        fn main() {
          /* Multi-line
             comment */
          println!("Hello");
        }
      `,
      expected: `

        fn main() {


          println!("Hello");
        }
`,
    },
    {
      name: 'Shell script comment removal',
      ext: '.sh',
      input: `
        # Single line comment
        echo "Hello"
      `,
      expected: `

        echo "Hello"
`,
    },
    {
      name: 'YAML comment removal',
      ext: '.yml',
      input: `
        key: value  # Comment
        another_key: another_value
      `,
      expected: `
        key: value
        another_key: another_value
`,
    },
    {
      name: 'Vue file comment removal',
      ext: '.vue',
      input: `
        <template>
          <!-- HTML comment -->
          <div>{{ message }}</div>
        </template>
        <script>
        // JavaScript comment
        export default {
          data() {
            return {
              message: 'Hello'
            }
          }
        }
        </script>
        <style>
        /* CSS comment */
        .test { color: red; }
        </style>
      `,
      expected: `
        <template>

          <div>{{ message }}</div>
        </template>
        <script>

        export default {
          data() {
            return {
              message: 'Hello'
            }
          }
        }
        </script>
        <style>

        .test { color: red; }
        </style>
`,
    },
    {
      name: 'Svelte file comment removal',
      ext: '.svelte',
      input: `
        <!-- HTML comment -->
        <div>{message}</div>
        <script>
        // JavaScript comment
        let message = 'Hello';
        </script>
        <style>
        /* CSS comment */
        div { color: red; }
        </style>
      `,
      expected: `

        <div>{message}</div>
        <script>

        let message = 'Hello';
        </script>
        <style>

        div { color: red; }
        </style>
`,
    },
  ];

  for (const { name, ext, input, expected } of testCases) {
    test(name, () => {
      const manipulator = getFileManipulator(`test${ext}`);
      expect(manipulator?.removeComments(input)).toBe(expected);
    });
  }

  test('Unsupported file type', () => {
    const manipulator = getFileManipulator('test.unsupported');
    expect(manipulator).toBeNull();
  });
});




// tests/core/file/fileManipulate.test.ts

describe('fileManipulate', () => {
  describe('JavaScript/TypeScript Files', () => {
    const testCases = [
      {
        name: 'should remove single line comments',
        ext: '.js',
        input: `
          // Single line comment
          const x = 1; // Inline comment
          // Another comment
          console.log(x);
        `,
        expected: `

          const x = 1;

          console.log(x);
        `
      },
      {
        name: 'should remove multi-line comments',
        ext: '.ts',
        input: `
          /* Multi-line
             comment */
          const x = 1;
          /*
           * Another multi-line
           * comment
           */
          console.log(x);
        `,
        expected: `


          const x = 1;



          console.log(x);
        `
      },
      {
        name: 'should handle nested comments',
        ext: '.js',
        input: `
          /* Outer comment
             /* Nested comment */
             Still in outer comment */
          const x = 1;
        `,
        expected: `


          const x = 1;
        `
      },
      {
        name: 'should not remove comments in strings',
        ext: '.ts',
        input: `
          const str1 = "// This is not a comment";
          const str2 = '/* This is not a comment */';
          const str3 = \`
            // Template literal with comment-like text
            /* Multi-line comment-like text */
          \`;
        `,
        expected: `
          const str1 = "// This is not a comment";
          const str2 = '/* This is not a comment */';
          const str3 = \`
            // Template literal with comment-like text
            /* Multi-line comment-like text */
          \`;
        `
      }
    ];

    testCases.forEach(({ name, ext, input, expected }) => {
      test(name, () => {
        const manipulator = getFileManipulator(`test${ext}`);
        expect(manipulator?.removeComments(input)).toBe(expected);
      });
    });
  });

  describe('Python Files', () => {
    const testCases = [
      {
        name: 'should remove hash comments',
        ext: '.py',
        input: `
          # This is a comment
          x = 1  # Inline comment
          # Another comment
          print(x)
        `,
        expected: `

          x = 1

          print(x)
        `
      },
      {
        name: 'should remove triple-quote docstrings',
        ext: '.py',
        input: `
          """
          Module docstring
          """
          def func():
            '''
            Function docstring
            '''
            x = 1
            """Not a docstring but a string literal"""
            return x
        `,
        expected: `


          def func():


            x = 1
            """Not a docstring but a string literal"""
            return x
        `
      },
      {
        name: 'should handle mixed string literals and docstrings',
        ext: '.py',
        input: `
          x = """This is a
          string literal"""

          """This is a
          docstring"""

          def func():
            return """This is a
            return value"""
        `,
        expected: `
          x = """This is a
          string literal"""



          def func():
            return """This is a
            return value"""
        `
      }
    ]);

  testCases.forEach(({ name, ext, input, expected }) => {
    test(name, () => {
      const manipulator = getFileManipulator(`test${ext}`);
      expect(manipulator?.removeComments(input)).toBe(expected);
    });
  });
});

describe('HTML and XML Files', () => {
  const testCases = [
    {
      name: 'should remove HTML comments',
      ext: '.html',
      input: `
          <!-- Header comment -->
          <div>
            <!-- Inline comment -->content<!-- Another comment -->
          </div>
          <!--
            Multi-line
            comment
          -->
        `,
      expected: `

          <div>
            content
          </div>


        `
    },
    {
      name: 'should handle nested HTML comments',
      ext: '.html',
      input: `
          <!-- Outer comment
               <!-- Nested comment -->
               Still outer -->
          <div>content</div>
        `,
      expected: `

          <div>content</div>
        `
    }
  ];

  testCases.forEach(({ name, ext, input, expected }) => {
    test(name, () => {
      const manipulator = getFileManipulator(`test${ext}`);
      expect(manipulator?.removeComments(input)).toBe(expected);
    });
  });
});

describe('CSS Files', () => {
  const testCases = [
    {
      name: 'should remove CSS comments',
      ext: '.css',
      input: `
          /* Header comment */
          .class {
            /* Property comment */
            color: red; /* Inline comment */
          }
          /*
           * Multi-line
           * comment
           */
        `,
      expected: `

          .class {

            color: red;
          }


        `
    },
    {
      name: 'should handle CSS comments in strings',
      ext: '.css',
      input: `
          .class {
            content: "/* Not a comment */";
            content: '/* Also not a comment */';
          }
        `,
      expected: `

          .class {
            content: "/* Not a comment */";
            content: '/* Also not a comment */';
          }
        `
    }
  ];

  testCases.forEach(({ name, ext, input, expected }) => {
    test(name, () => {
      const manipulator = getFileManipulator(`test${ext}`);
      expect(manipulator?.removeComments(input)).toBe(expected);
    });
  });
});

describe('Empty Line Handling', () => {
  const testCases = [
    {
      name: 'should remove empty lines',
      ext: '.js',
      input: `
          const x = 1;

          // Comment

          console.log(x);

        `,
      expected: `
          const x = 1;
          console.log(x);
        `
    },
    {
      name: 'should handle different line endings',
      ext: '.js',
      input: 'line1\r\n\r\nline2\n\nline3\r\rline4',
      expected: 'line1\r\nline2\nline3\rline4'
    }
  ];

  testCases.forEach(({ name, ext, input, expected }) => {
    test(name, () => {
      const manipulator = getFileManipulator(`test${ext}`);
      expect(manipulator?.removeEmptyLines(input)).toBe(expected);
    });
  });
});

describe('File Type Handling', () => {
  test('should return null for unsupported file types', () => {
    const manipulator = getFileManipulator('test.unknown');
    expect(manipulator).toBeNull();
  });

  test('should handle files without extension', () => {
    const manipulator = getFileManipulator('Dockerfile');
    expect(manipulator).not.toBeNull();
  });
});

describe('Vue Single File Components', () => {
  test('should handle Vue SFC files', () => {
    const input = `
        <!-- Component comment -->
        <template>
          <!-- Template comment -->
          <div>content</div>
        </template>
        <script>
          // Script comment
          /* Multi-line comment */
          export default {
            name: 'Component'
          }
        </script>
        <style>
          /* Style comment */
          .class {
            color: red;
          }
        </style>
      `;
    const expected = `

        <template>

          <div>content</div>
        </template>
        <script>


          export default {
            name: 'Component'
          }
        </script>
        <style>

          .class {
            color: red;
          }
        </style>
      `;
    const manipulator = getFileManipulator('test.vue');
    expect(manipulator?.removeComments(input)).toBe(expected);
  });
});
});

================
File: tests/core/file/filePathSort.test.ts
================
import path from 'node:path';
import { describe, expect, test } from 'vitest';
import { sortPaths } from '../../../src/core/file/filePathSort.js';

describe('filePathSort', () => {
  const sep = path.sep;

  test('should sort directories before files', () => {
    const input = ['file.txt', `dir${sep}`, 'another_file.js', `another_dir${sep}`];
    const expected = [`another_dir${sep}`, `dir${sep}`, 'another_file.js', 'file.txt'];
    expect(sortPaths(input)).toEqual(expected);
  });

  test('should sort subdirectories correctly', () => {
    const input = [`dir${sep}subdir${sep}file.txt`, `dir${sep}file.js`, `dir${sep}subdir${sep}`, 'file.txt'];
    const expected = [`dir${sep}subdir${sep}`, `dir${sep}subdir${sep}file.txt`, `dir${sep}file.js`, 'file.txt'];
    expect(sortPaths(input)).toEqual(expected);
  });

  test('should sort files alphabetically within the same directory', () => {
    const input = [`dir${sep}c.txt`, `dir${sep}a.txt`, `dir${sep}b.txt`];
    const expected = [`dir${sep}a.txt`, `dir${sep}b.txt`, `dir${sep}c.txt`];
    expect(sortPaths(input)).toEqual(expected);
  });

  test('should handle empty input', () => {
    expect(sortPaths([])).toEqual([]);
  });

  test('should handle complex directory structure', () => {
    const input = [
      `src${sep}utils${sep}file3.ts`,
      `src${sep}index.ts`,
      `tests${sep}utils${sep}a.ts`,
      `src${sep}utils${sep}b.ts`,
      'package.json',
      'README.md',
      `src${sep}components${sep}Component.tsx`,
    ];
    const expected = [
      `src${sep}components${sep}Component.tsx`,
      `src${sep}utils${sep}b.ts`,
      `src${sep}utils${sep}file3.ts`,
      `src${sep}index.ts`,
      `tests${sep}utils${sep}a.ts`,
      'package.json',
      'README.md',
    ];
    expect(sortPaths(input)).toEqual(expected);
  });

  test('should handle paths with multiple separators', () => {
    const input = [`a${sep}b${sep}c`, `a${sep}b`, `a${sep}b${sep}`];
    const expected = [`a${sep}b`, `a${sep}b${sep}`, `a${sep}b${sep}c`];
    expect(sortPaths(input)).toEqual(expected);
  });

  test('should be case-insensitive', () => {
    const input = [`B${sep}`, `a${sep}`, 'C', 'd'];
    const expected = [`a${sep}`, `B${sep}`, 'C', 'd'];
    expect(sortPaths(input)).toEqual(expected);
  });
});

describe('filePathSort', () => {
  const sep = path.sep;

  describe('Basic Sorting', () => {
    test('should sort directories before files', () => {
      const input = [
        'file.txt',
        `dir${sep}`,
        'another_file.js',
        `another_dir${sep}`,
      ];
      const expected = [
        `another_dir${sep}`,
        `dir${sep}`,
        'another_file.js',
        'file.txt',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should sort files alphabetically within the same directory', () => {
      const input = [
        'z.txt',
        'a.txt',
        'c.txt',
        'b.txt',
      ];
      const expected = [
        'a.txt',
        'b.txt',
        'c.txt',
        'z.txt',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle empty array', () => {
      expect(sortPaths([])).toEqual([]);
    });

    test('should handle array with single item', () => {
      expect(sortPaths(['file.txt'])).toEqual(['file.txt']);
    });
  });

  describe('Directory Structure Sorting', () => {
    test('should sort subdirectories correctly', () => {
      const input = [
        `parent${sep}child${sep}file.txt`,
        `parent${sep}file.js`,
        `parent${sep}child${sep}`,
        'file.txt',
      ];
      const expected = [
        `parent${sep}child${sep}`,
        `parent${sep}child${sep}file.txt`,
        `parent${sep}file.js`,
        'file.txt',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle deep directory structures', () => {
      const input = [
        `a${sep}b${sep}c${sep}d.txt`,
        `a${sep}b${sep}c${sep}`,
        `a${sep}b${sep}`,
        `a${sep}`,
      ];
      const expected = [
        `a${sep}`,
        `a${sep}b${sep}`,
        `a${sep}b${sep}c${sep}`,
        `a${sep}b${sep}c${sep}d.txt`,
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle mixed directory depths', () => {
      const input = [
        `deep${sep}deeper${sep}deepest${sep}file.txt`,
        'root.txt',
        `shallow${sep}file.txt`,
      ];
      const expected = [
        `deep${sep}deeper${sep}deepest${sep}file.txt`,
        `shallow${sep}file.txt`,
        'root.txt',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });
  });

  describe('Complex File Types', () => {
    test('should handle various file extensions', () => {
      const input = [
        'doc.pdf',
        'script.js',
        'style.css',
        'readme.md',
      ];
      const expected = [
        'doc.pdf',
        'readme.md',
        'script.js',
        'style.css',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle files without extensions', () => {
      const input = [
        'README',
        'license',
        'Dockerfile',
        'makefile',
      ];
      const expected = [
        'Dockerfile',
        'README',
        'license',
        'makefile',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle hidden files', () => {
      const input = [
        '.gitignore',
        '.env',
        'regular.txt',
        '.config',
      ];
      const expected = [
        '.config',
        '.env',
        '.gitignore',
        'regular.txt',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });
  });

  describe('Case Sensitivity', () => {
    test('should handle mixed case filenames', () => {
      const input = [
        'Alpha.txt',
        'beta.txt',
        'GAMMA.txt',
        'Delta.txt',
      ];
      const expected = [
        'Alpha.txt',
        'beta.txt',
        'Delta.txt',
        'GAMMA.txt',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle same name with different cases', () => {
      const input = [
        'file.txt',
        'File.txt',
        'FILE.txt',
        'FiLe.txt',
      ];
      expect(sortPaths(input)).toEqual(input.sort((a, b) => a.localeCompare(b)));
    });
  });

  describe('Special Characters', () => {
    test('should handle special characters in filenames', () => {
      const input = [
        'file-1.txt',
        'file_2.txt',
        'file 3.txt',
        'file#4.txt',
      ];
      const expected = [
        'file 3.txt',
        'file#4.txt',
        'file-1.txt',
        'file_2.txt',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle unicode characters', () => {
      const input = [
        'файл.txt',
        'ファイル.txt',
        '文件.txt',
        'file.txt',
      ];
      expect(sortPaths(input)).toEqual(input.sort((a, b) => a.localeCompare(b)));
    });
  });

  describe('Project-Specific Patterns', () => {
    test('should handle common web development patterns', () => {
      const input = [
        `src${sep}components${sep}Button.jsx`,
        `src${sep}pages${sep}Home.tsx`,
        `src${sep}styles${sep}main.css`,
        'package.json',
      ];
      const expected = [
        `src${sep}components${sep}Button.jsx`,
        `src${sep}pages${sep}Home.tsx`,
        `src${sep}styles${sep}main.css`,
        'package.json',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle test files and directories', () => {
      const input = [
        `tests${sep}unit${sep}`,
        `tests${sep}integration${sep}`,
        `__tests__${sep}components${sep}`,
        'jest.config.js',
      ];
      const expected = [
        `__tests__${sep}components${sep}`,
        `tests${sep}integration${sep}`,
        `tests${sep}unit${sep}`,
        'jest.config.js',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });

    test('should handle build and configuration files', () => {
      const input = [
        'webpack.config.js',
        `dist${sep}`,
        `build${sep}`,
        '.babelrc',
      ];
      const expected = [
        `build${sep}`,
        `dist${sep}`,
        '.babelrc',
        'webpack.config.js',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });
  });

  describe('Edge Cases', () => {
    test('should handle paths with multiple separators', () => {
      const input = [
        `a${sep}${sep}b${sep}${sep}c`,
        `a${sep}b${sep}${sep}c`,
        `a${sep}b${sep}c`,
      ];
      expect(sortPaths(input)).toEqual(input.sort());
    });

    test('should handle relative paths', () => {
      const input = [
        `.${sep}file.txt`,
        `..${sep}file.txt`,
        `${sep}file.txt`,
      ];
      expect(sortPaths(input)).toEqual(input.sort());
    });

    test('should handle empty path components', () => {
      const input = [
        `${sep}path${sep}to${sep}file`,
        `path${sep}${sep}to${sep}file`,
        `path${sep}to${sep}${sep}file`,
      ];
      expect(sortPaths(input)).toEqual(input.sort());
    });

    test('should handle path with trailing separator', () => {
      const input = [
        `dir${sep}subdir`,
        `dir${sep}subdir${sep}`,
        `dir${sep}`,
        'dir',
      ];
      const expected = [
        `dir${sep}`,
        `dir${sep}subdir${sep}`,
        `dir${sep}subdir`,
        'dir',
      ];
      expect(sortPaths(input)).toEqual(expected);
    });
  });
});

================
File: tests/core/file/fileProcess.test.ts
================
import { describe, expect, it, vi } from 'vitest';
import { getFileManipulator } from '../../../src/core/file/fileManipulate.js';
import { processContent, processFiles } from '../../../src/core/file/fileProcess.js';
import type { RawFile } from '../../../src/core/file/fileTypes.js';
import { createMockConfig } from '../../testing/testUtils.js';

vi.mock('../../../src/core/file/fileManipulate');

describe('fileProcess', () => {
  describe('processFiles', () => {
    it('should process multiple files', async () => {
      const mockRawFiles: RawFile[] = [
        { path: 'file1.js', content: '// comment\nconst a = 1;' },
        { path: 'file2.js', content: '/* comment */\nconst b = 2;' },
      ];
      const config = createMockConfig({
        output: {
          removeComments: true,
          removeEmptyLines: true,
        },
      });

      vi.mocked(getFileManipulator).mockReturnValue({
        removeComments: (content: string) => content.replace(/\/\/.*|\/\*[\s\S]*?\*\//g, ''),
        removeEmptyLines: (content: string) => content.replace(/^\s*[\r\n]/gm, ''),
      });

      const result = await processFiles(mockRawFiles, config);

      expect(result).toEqual([
        { path: 'file1.js', content: 'const a = 1;' },
        { path: 'file2.js', content: 'const b = 2;' },
      ]);
    });
  });

  describe('processContent', () => {
    it('should remove comments and empty lines when configured', async () => {
      const content = '// comment\nconst a = 1;\n\n/* multi-line\ncomment */\nconst b = 2;';
      const filePath = 'test.js';
      const config = createMockConfig({
        output: {
          removeComments: true,
          removeEmptyLines: true,
        },
      });

      vi.mocked(getFileManipulator).mockReturnValue({
        removeComments: (content: string) => content.replace(/\/\/.*|\/\*[\s\S]*?\*\//g, ''),
        removeEmptyLines: (content: string) => content.replace(/^\s*[\r\n]/gm, ''),
      });

      const result = await processContent(content, filePath, config);

      expect(result).toBe('const a = 1;\nconst b = 2;');
    });

    it('should not remove comments or empty lines when not configured', async () => {
      const content = '// comment\nconst a = 1;\n\n/* multi-line\ncomment */\nconst b = 2;';
      const filePath = 'test.js';
      const config = createMockConfig({
        output: {
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, filePath, config);

      expect(result).toBe(content.trim());
    });

    it('should handle files without a manipulator', async () => {
      const content = 'Some content';
      const filePath = 'unknown.ext';
      const config = createMockConfig({
        output: {
          removeComments: true,
          removeEmptyLines: true,
        },
      });

      vi.mocked(getFileManipulator).mockReturnValue(null);

      const result = await processContent(content, filePath, config);

      expect(result).toBe(content);
    });

    it('should add line numbers when showLineNumbers is true', async () => {
      const content = 'Line 1\nLine 2\nLine 3';
      const filePath = 'test.txt';
      const config = createMockConfig({
        output: {
          showLineNumbers: true,
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, filePath, config);

      expect(result).toBe('1: Line 1\n2: Line 2\n3: Line 3');
    });

    it('should not add line numbers when showLineNumbers is false', async () => {
      const content = 'Line 1\nLine 2\nLine 3';
      const filePath = 'test.txt';
      const config = createMockConfig({
        output: {
          showLineNumbers: false,
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, filePath, config);

      expect(result).toBe('Line 1\nLine 2\nLine 3');
    });

    it('should handle empty content when showLineNumbers is true', async () => {
      const content = '';
      const filePath = 'empty.txt';
      const config = createMockConfig({
        output: {
          showLineNumbers: true,
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, filePath, config);

      expect(result).toBe('1: ');
    });

    it('should pad line numbers correctly for files with many lines', async () => {
      const content = Array(100).fill('Line').join('\n');
      const filePath = 'long.txt';
      const config = createMockConfig({
        output: {
          showLineNumbers: true,
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, filePath, config);

      const lines = result.split('\n');
      expect(lines[0]).toBe('  1: Line');
      expect(lines[9]).toBe(' 10: Line');
      expect(lines[99]).toBe('100: Line');
    });
  });
});





// tests/core/file/fileProcess.test.ts
import { beforeEach,  } from 'vitest';

vi.mock('../../../src/core/file/fileManipulate');
vi.mock('../../../src/shared/processConcurrency', () => ({
  getProcessConcurrency: () => 2, // Mock to return fixed concurrency for tests
}));

describe('fileProcess', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  describe('processFiles', () => {
    it('should process multiple files concurrently', async () => {
      const mockRawFiles: RawFile[] = [
        { path: 'file1.js', content: '// comment\nconst a = 1;' },
        { path: 'file2.js', content: '/* comment */\nconst b = 2;' },
        { path: 'file3.js', content: '// another comment\nconst c = 3;' },
      ];

      const mockManipulator = {
        removeComments: vi.fn((content: string) => content.replace(/\/\/.*|\/\*[\s\S]*?\*\//g, '')),
        removeEmptyLines: vi.fn((content: string) => content.replace(/^\s*[\r\n]/gm, '')),
      };

      vi.mocked(getFileManipulator).mockReturnValue(mockManipulator);

      const config = createMockConfig({
        output: {
          removeComments: true,
          removeEmptyLines: true,
          showLineNumbers: false,
        },
      });

      const result = await processFiles(mockRawFiles, config);

      expect(result).toHaveLength(3);
      expect(result).toEqual([
        { path: 'file1.js', content: 'const a = 1;' },
        { path: 'file2.js', content: 'const b = 2;' },
        { path: 'file3.js', content: 'const c = 3;' },
      ]);

      // Verify concurrent processing
      expect(mockManipulator.removeComments).toHaveBeenCalledTimes(3);
      expect(mockManipulator.removeEmptyLines).toHaveBeenCalledTimes(3);
    });

    it('should handle files with different extensions', async () => {
      const mockRawFiles: RawFile[] = [
        { path: 'script.js', content: '// JS comment\nconst a = 1;' },
        { path: 'style.css', content: '/* CSS comment */\n.class { color: red; }' },
        { path: 'template.html', content: '<!-- HTML comment -->\n<div>content</div>' },
      ];

      const jsManipulator = {
        removeComments: vi.fn((content: string) => content.replace(/\/\/.*|\/\*[\s\S]*?\*\//g, '')),
        removeEmptyLines: vi.fn((content: string) => content.replace(/^\s*[\r\n]/gm, '')),
      };

      const cssManipulator = {
        removeComments: vi.fn((content: string) => content.replace(/\/\*[\s\S]*?\*\//g, '')),
        removeEmptyLines: vi.fn((content: string) => content.replace(/^\s*[\r\n]/gm, '')),
      };

      const htmlManipulator = {
        removeComments: vi.fn((content: string) => content.replace(/<!--[\s\S]*?-->/g, '')),
        removeEmptyLines: vi.fn((content: string) => content.replace(/^\s*[\r\n]/gm, '')),
      };

      vi.mocked(getFileManipulator)
        .mockImplementation((filePath) => {
          if (filePath.endsWith('.js')) return jsManipulator;
          if (filePath.endsWith('.css')) return cssManipulator;
          if (filePath.endsWith('.html')) return htmlManipulator;
          return null;
        });

      const config = createMockConfig({
        output: {
          removeComments: true,
          removeEmptyLines: true,
          showLineNumbers: false,
        },
      });

      const result = await processFiles(mockRawFiles, config);

      expect(result).toHaveLength(3);
      expect(jsManipulator.removeComments).toHaveBeenCalled();
      expect(cssManipulator.removeComments).toHaveBeenCalled();
      expect(htmlManipulator.removeComments).toHaveBeenCalled();
    });
  });

  describe('processContent', () => {
    it('should add line numbers when configured', async () => {
      const content = 'line1\nline2\nline3';
      const config = createMockConfig({
        output: {
          showLineNumbers: true,
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, 'test.txt', config);

      expect(result).toBe('1: line1\n2: line2\n3: line3');
    });

    it('should handle large file line numbering', async () => {
      const lines = Array.from({ length: 1000 }, (_, i) => `line${i + 1}`);
      const content = lines.join('\n');
      const config = createMockConfig({
        output: {
          showLineNumbers: true,
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, 'test.txt', config);
      const resultLines = result.split('\n');

      // Check padding for different line numbers
      expect(resultLines[0]).toBe('  1: line1');
      expect(resultLines[9]).toBe(' 10: line10');
      expect(resultLines[99]).toBe('100: line100');
      expect(resultLines[999]).toBe('1000: line1000');
    });

    it('should handle empty content', async () => {
      const content = '';
      const config = createMockConfig({
        output: {
          showLineNumbers: true,
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, 'test.txt', config);

      expect(result).toBe('1: ');
    });

    it('should process files without a manipulator', async () => {
      const content = 'test content';
      vi.mocked(getFileManipulator).mockReturnValue(null);

      const config = createMockConfig({
        output: {
          removeComments: true,
          removeEmptyLines: true,
          showLineNumbers: false,
        },
      });

      const result = await processContent(content, 'unknown.ext', config);

      expect(result).toBe('test content');
    });

    it('should handle mixed line endings', async () => {
      const content = 'line1\r\nline2\nline3\rline4';
      const config = createMockConfig({
        output: {
          showLineNumbers: true,
          removeComments: false,
          removeEmptyLines: false,
        },
      });

      const result = await processContent(content, 'test.txt', config);

      expect(result).toBe('1: line1\r\n2: line2\n3: line3\r4: line4');
    });

    it('should handle content with empty lines', async () => {
      const content = 'line1\n\nline3\n\nline5';
      const config = createMockConfig({
        output: {
          removeEmptyLines: true,
          removeComments: false,
          showLineNumbers: true,
        },
      });

      const mockManipulator = {
        removeComments: vi.fn((str) => str),
        removeEmptyLines: vi.fn((str) => str.replace(/^\s*[\r\n]/gm, '')),
      };

      vi.mocked(getFileManipulator).mockReturnValue(mockManipulator);

      const result = await processContent(content, 'test.txt', config);
      expect(result).toBe('1: line1\n2: line3\n3: line5');
      expect(mockManipulator.removeEmptyLines).toHaveBeenCalled();
    });

    it('should process content with removal order: comments -> empty lines -> line numbers', async () => {
      const content = '// Comment\n\ncode\n\n/* Comment */\nmore code';
      const config = createMockConfig({
        output: {
          removeComments: true,
          removeEmptyLines: true,
          showLineNumbers: true,
        },
      });

      const mockManipulator = {
        removeComments: vi.fn((str) => str.replace(/\/\/.*|\/\*[\s\S]*?\*\//g, '')),
        removeEmptyLines: vi.fn((str) => str.replace(/^\s*[\r\n]/gm, '')),
      };

      vi.mocked(getFileManipulator).mockReturnValue(mockManipulator);

      const result = await processContent(content, 'test.js', config);

      // Verify order of operations through the final result
      expect(result).toBe('1: code\n2: more code');

      // Verify order of operations through mock calls
      const removeCommentsCalls = mockManipulator.removeComments.mock.calls;
      const removeEmptyLinesCalls = mockManipulator.removeEmptyLines.mock.calls;

      expect(removeCommentsCalls[0][0]).toBe(content); // First operation
      expect(removeEmptyLinesCalls[0][0]).toContain('code'); // Second operation, after comments removed
    });

    it('should handle invalid content gracefully', async () => {
      const content = null as any; // Simulate invalid content
      const config = createMockConfig({
        output: {
          showLineNumbers: true,
          removeComments: true,
          removeEmptyLines: true,
        },
      });

      const result = await processContent(content, 'test.txt', config);

      expect(result).toBe('');
    });

    it('should process content with multiple manipulator operations', async () => {
      const content = '// Comment 1\n/* Comment 2 */\ncode\n\nmore code\n// Comment 3';
      const config = createMockConfig({
        output: {
          removeComments: true,
          removeEmptyLines: true,
          showLineNumbers: true,
        },
      });

      const operations: string[] = [];
      const mockManipulator = {
        removeComments: vi.fn((str) => {
          operations.push('removeComments');
          return str.replace(/\/\/.*|\/\*[\s\S]*?\*\//g, '');
        }),
        removeEmptyLines: vi.fn((str) => {
          operations.push('removeEmptyLines');
          return str.replace(/^\s*[\r\n]/gm, '');
        }),
      };

      vi.mocked(getFileManipulator).mockReturnValue(mockManipulator);

      const result = await processContent(content, 'test.js', config);

      // Verify the order of operations
      expect(operations).toEqual(['removeComments', 'removeEmptyLines']);
      // Verify the final result
      expect(result).toBe('1: code\n2: more code');
    });
  });
});

================
File: tests/core/file/fileSearch.edge.test.ts
================
import { globby } from 'globby';

// tests/core/file/fileSearch.edge.test.ts

import path from 'node:path';
import { beforeEach, describe, expect, it, vi } from 'vitest';
import { searchFiles } from '../../../src/core/file/fileSearch.js';
import { logger } from '../../../src/shared/logger.js';
import { createMockConfig } from '../../testing/testUtils.js';

vi.mock('fs/promises');
vi.mock('globby');
vi.mock('../../../src/shared/logger');

describe('fileSearch - Edge Cases', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  describe('Special Characters and Encodings', () => {
    it('should handle paths with special characters', async () => {
      const mockConfig = createMockConfig();
      const specialChars = [
        'file with spaces.js',
        'file#with#hash.js',
        'file@with@at.js',
        'file(with)parentheses.js',
        'file[with]brackets.js',
        'file{with}braces.js',
        'file+with+plus.js',
        'file=with=equals.js',
        'file^with^caret.js',
        'file$with$dollar.js',
      ];

      vi.mocked(globby).mockResolvedValue(specialChars);

      const result = await searchFiles('/test/dir', mockConfig);
      expect(result).toEqual(specialChars.sort());
    });

    it('should handle paths with unicode characters', async () => {
      const mockConfig = createMockConfig();
      const unicodePaths = [
        '文件.js',
        'ファイル.js',
        'файл.js',
        '파일.js',
        'ملف.js',
        'αρχείο.js',
      ];

      vi.mocked(globby).mockResolvedValue(unicodePaths);

      const result = await searchFiles('/test/dir', mockConfig);
      expect(result).toEqual(unicodePaths.sort());
    });

    it('should handle paths with emoji characters', async () => {
      const mockConfig = createMockConfig();
      const emojiPaths = [
        '📁folder/file.js',
        '⭐star.js',
        '🎉party.js',
        '💻code.js',
      ];

      vi.mocked(globby).mockResolvedValue(emojiPaths);

      const result = await searchFiles('/test/dir', mockConfig);
      expect(result).toEqual(emojiPaths.sort());
    });
  });

  describe('Path Length Edge Cases', () => {
    it('should handle very long file paths', async () => {
      const mockConfig = createMockConfig();
      const longPath = 'a'.repeat(255) + '.js'; // Maximum filename length in many filesystems

      vi.mocked(globby).mockResolvedValue([longPath]);

      const result = await searchFiles('/test/dir', mockConfig);
      expect(result).toContain(longPath);
    });

    it('should handle deeply nested paths', async () => {
      const mockConfig = createMockConfig();
      const parts = Array(50).fill('subdir'); // Very deep nesting
      const deepPath = path.join(...parts, 'file.js');

      vi.mocked(globby).mockResolvedValue([deepPath]);

      const result = await searchFiles('/test/dir', mockConfig);
      expect(result).toContain(deepPath);
    });
  });

  describe('Pattern Matching Edge Cases', () => {
    it('should handle complex glob patterns', async () => {
      const mockConfig = createMockConfig({
        include: [
          '**/*.{js,jsx,ts,tsx}',
          '!**/__tests__/**',
          '!**/*.test.*',
          '!**/*.spec.*',
          '**/index.*',
        ],
      });

      const files = [
        'src/index.js',
        'src/file.js',
        'src/file.test.js',
        'src/__tests__/file.js',
        'src/file.spec.js',
        'src/components/index.tsx',
      ];

      vi.mocked(globby).mockResolvedValue(['src/index.js', 'src/components/index.tsx']);

      const result = await searchFiles('/test/dir', mockConfig);
      expect(result).toEqual(['src/components/index.tsx', 'src/index.js']);
    });

    it('should handle overlapping include/ignore patterns', async () => {
      const mockConfig = createMockConfig({
        include: ['**/*.js', '!**/*.min.js', '**/*.min.js'],
        ignore: {
          customPatterns: ['vendor/*.min.js', '!vendor/important.min.js'],
        },
      });

      const files = [
        'file.js',
        'file.min.js',
        'vendor/lib.min.js',
        'vendor/important.min.js',
      ];

      vi.mocked(globby).mockResolvedValue([
        'file.js',
        'file.min.js',
        'vendor/important.min.js',
      ]);

      const result = await searchFiles('/test/dir', mockConfig);
      expect(result).toContain('vendor/important.min.js');
      expect(result).not.toContain('vendor/lib.min.js');
    });
  });

  describe('System and Hidden Files', () => {
    it('should handle system and hidden files correctly', async () => {
      const mockConfig = createMockConfig({
        include: ['**/*'],
      });

      const files = [
        '.git/config',
        '.gitignore',
        '.DS_Store',
        '$RECYCLE.BIN',
        'Thumbs.db',
        '~temp.txt',
      ];

      vi.mocked(globby).mockResolvedValue(['.gitignore']); // Only .gitignore should be included

      const result = await searchFiles('/test/dir', mockConfig);
      expect(result).toEqual(['.gitignore']);
    });
  });

  describe('Error Handling Edge Cases', () => {
    it('should handle cyclic symbolic links', async () => {
      const mockConfig = createMockConfig();

      vi.mocked(globby).mockImplementation(() => {
                throw new Error('ELOOP: too many symbolic links');
              });

await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow();
expect(logger.error).toHaveBeenCalledWith(
  expect.stringContaining('too many symbolic links'),
  expect.any(Error)
);
    });

it('should handle temporary unavailable resources', async () => {
  const mockConfig = createMockConfig();

  vi.mocked(globby).mockImplementation(() => {
    throw new Error('EAGAIN: resource temporarily unavailable');
  });

  await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow();
  expect(logger.error).toHaveBeenCalled();
});

it('should handle out of memory errors', async () => {
  const mockConfig = createMockConfig();

  vi.mocked(globby).mockImplementation(() => {
    const error = new Error('ENOMEM: out of memory');
    error.name = 'ResourceError';
    throw error;
  });

  await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow();
  expect(logger.error).toHaveBeenCalled();
});
  });

describe('File System Limits', () => {
  it('should handle maximum number of open files', async () => {
    const mockConfig = createMockConfig();
    const manyFiles = Array.from({ length: 10000 }, (_, i) => `file${i}.js`);

    vi.mocked(globby).mockResolvedValue(manyFiles);

    const result = await searchFiles('/test/dir', mockConfig);
    expect(result).toHaveLength(10000);
    expect(result[0]).toBe('file0.js');
    expect(result[9999]).toBe('file9999.js');
  });

  it('should handle maximum path length limits', async () => {
    const mockConfig = createMockConfig();
    // Create a path that exceeds typical OS limits
    const longPath = 'a'.repeat(4096) + '.js';

    vi.mocked(globby).mockImplementation(() => {
      throw new Error('ENAMETOOLONG: file name too long');
    });

    await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow();
    expect(logger.error).toHaveBeenCalled();
  });
});

describe('Race Conditions', () => {
  it('should handle files that disappear during processing', async () => {
    const mockConfig = createMockConfig();

    let firstCall = true;
    vi.mocked(globby).mockImplementation(async () => {
      if (firstCall) {
        firstCall = false;
        return ['file1.js', 'file2.js'];
      }
      throw new Error('ENOENT: no such file or directory');
    });

    await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow();
    expect(logger.error).toHaveBeenCalled();
  });

  it('should handle files that change permissions during processing', async () => {
    const mockConfig = createMockConfig();

    let firstCall = true;
    vi.mocked(globby).mockImplementation(async () => {
      if (firstCall) {
        firstCall = false;
        return ['file1.js'];
      }
      throw new Error('EACCES: permission denied');
    });

    await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow();
    expect(logger.error).toHaveBeenCalled();
  });
});

describe('Pattern Validation', () => {
  it('should handle invalid glob patterns', async () => {
    const mockConfig = createMockConfig({
      include: ['[invalid-pattern'],
    });

    vi.mocked(globby).mockImplementation(() => {
      throw new Error('Invalid pattern: [invalid-pattern');
    });

    await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow();
    expect(logger.error).toHaveBeenCalled();
  });

  it('should handle empty glob patterns', async () => {
    const mockConfig = createMockConfig({
      include: [''],
    });

    const result = await searchFiles('/test/dir', mockConfig);
    expect(result).toEqual([]);
  });

  it('should handle patterns with only wildcards', async () => {
    const mockConfig = createMockConfig({
      include: ['**'],
    });

    vi.mocked(globby).mockResolvedValue([
      'file1.js',
      'dir/file2.js',
    ]);

    const result = await searchFiles('/test/dir', mockConfig);
    expect(result).toEqual(['dir/file2.js', 'file1.js']);
  });
});

describe('Filesystem Type Edge Cases', () => {
  it('should handle case-sensitive vs case-insensitive filesystems', async () => {
    const mockConfig = createMockConfig();

    vi.mocked(globby).mockResolvedValue([
      'File.js',
      'file.js',
      'FILE.js',
    ]);

    const result = await searchFiles('/test/dir', mockConfig);
    expect(result).toHaveLength(3);
    expect(new Set(result)).toHaveLength(3); // All entries should be unique
  });

  it('should handle non-standard filesystems', async () => {
    const mockConfig = createMockConfig();
    const nonStandardPaths = [
      'extended-attributes.js',
      'alternate-data-streams.js:stream',
      'resource-fork/file.js',
    ];

    vi.mocked(globby).mockResolvedValue(nonStandardPaths);

    const result = await searchFiles('/test/dir', mockConfig);
    expect(result).toEqual(nonStandardPaths);
  });

  it('should handle network filesystem timeouts', async () => {
    const mockConfig = createMockConfig();

    vi.mocked(globby).mockImplementation(() => {
      throw new Error('ETIMEDOUT: operation timed out');
    });

    await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow();
    expect(logger.error).toHaveBeenCalled();
  });
});

describe('Memory Usage', () => {
  it('should handle large directory listings efficiently', async () => {
    const mockConfig = createMockConfig();
    const largeFileList = Array.from(
      { length: 100000 },
      (_, i) => `file${i}.js`
    );

    vi.mocked(globby).mockResolvedValue(largeFileList);

    const result = await searchFiles('/test/dir', mockConfig);
    expect(result).toHaveLength(100000);
  });

  it('should handle deep recursion efficiently', async () => {
    const mockConfig = createMockConfig();
    const deepPaths = Array.from(
      { length: 1000 },
      (_, i) => Array(i + 1).fill('dir').join(path.sep) + path.sep + 'file.js'
    );

    vi.mocked(globby).mockResolvedValue(deepPaths);

    const result = await searchFiles('/test/dir', mockConfig);
    expect(result).toHaveLength(1000);
  });
});
});

================
File: tests/core/file/fileSearch.test.ts
================
import * as fs from 'node:fs/promises';
import path from 'node:path';
import process from 'node:process';
import { globby } from 'globby';
import { minimatch } from 'minimatch';
import { beforeEach, describe, expect, test, vi } from 'vitest';
import {
  getIgnoreFilePatterns,
  getIgnorePatterns,
  parseIgnoreContent,
  searchFiles,
} from '../../../src/core/file/fileSearch.js';
import { createMockConfig, isWindows } from '../../testing/testUtils.js';

vi.mock('fs/promises');
vi.mock('globby');

describe('fileSearch', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  describe('getIgnoreFilePaths', () => {
    test('should return correct paths when .gitignore and .repofmignore exist', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);
      const mockConfig = createMockConfig({
        ignore: {
          useGitignore: true,
          useDefaultPatterns: true,
          customPatterns: [],
        },
      });
      const filePatterns = await getIgnoreFilePatterns(mockConfig);
      expect(filePatterns).toEqual(['**/.gitignore', '**/.repofmignore']);
    });

    test('should not include .gitignore when useGitignore is false', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);
      const mockConfig = createMockConfig({
        ignore: {
          useGitignore: false,
          useDefaultPatterns: true,
          customPatterns: [],
        },
      });
      const filePatterns = await getIgnoreFilePatterns(mockConfig);
      expect(filePatterns).toEqual(['**/.repofmignore']);
    });
  });

  describe('getIgnorePatterns', () => {
    test('should return default patterns when useDefaultPatterns is true', async () => {
      const mockConfig = createMockConfig({
        ignore: {
          useGitignore: true,
          useDefaultPatterns: true,
          customPatterns: [],
        },
      });

      const patterns = await getIgnorePatterns(process.cwd(), mockConfig);

      expect(patterns.length).toBeGreaterThan(0);
      expect(patterns).toContain('**/node_modules/**');
    });

    test('should include custom patterns', async () => {
      const mockConfig = createMockConfig({
        ignore: {
          useGitignore: true,
          useDefaultPatterns: false,
          customPatterns: ['*.custom', 'temp/'],
        },
      });

      const patterns = await getIgnorePatterns(process.cwd(), mockConfig);

      expect(patterns).toEqual(['repofm-output.txt', '*.custom', 'temp/']);
    });

    test('should combine default and custom patterns', async () => {
      const mockConfig = createMockConfig({
        ignore: {
          useGitignore: true,
          useDefaultPatterns: true,
          customPatterns: ['*.custom', 'temp/'],
        },
      });

      const patterns = await getIgnorePatterns(process.cwd(), mockConfig);

      expect(patterns).toContain('**/node_modules/**');
      expect(patterns).toContain('*.custom');
      expect(patterns).toContain('temp/');
    });
  });

  describe('parseIgnoreContent', () => {
    test('should correctly parse ignore content', () => {
      const content = `
# Comment
node_modules
*.log

.DS_Store
      `;

      const patterns = parseIgnoreContent(content);

      expect(patterns).toEqual(['node_modules', '*.log', '.DS_Store']);
    });

    test('should handle mixed line endings', () => {
      const content = 'node_modules\n*.log\r\n.DS_Store\r';

      const patterns = parseIgnoreContent(content);

      expect(patterns).toEqual(['node_modules', '*.log', '.DS_Store']);
    });
  });

  describe('filterFiles', () => {
    beforeEach(() => {
      vi.resetAllMocks();
    });

    test('should call globby with correct parameters', async () => {
      const mockConfig = createMockConfig({
        include: ['**/*.js'],
        ignore: {
          useGitignore: true,
          useDefaultPatterns: false,
          customPatterns: ['*.custom'],
        },
      });

      vi.mocked(globby).mockResolvedValue(['file1.js', 'file2.js']);
      vi.mocked(fs.access).mockResolvedValue(undefined);

      await searchFiles('/mock/root', mockConfig);

      expect(globby).toHaveBeenCalledWith(
        ['**/*.js'],
        expect.objectContaining({
          cwd: '/mock/root',
          ignore: expect.arrayContaining(['*.custom']),
          ignoreFiles: expect.arrayContaining(['**/.gitignore', '**/.repofmignore']),
          onlyFiles: true,
          absolute: false,
          dot: true,
          followSymbolicLinks: false,
        }),
      );
    });

    test.runIf(!isWindows)('Honor .gitignore files in subdirectories', async () => {
      const mockConfig = createMockConfig({
        include: ['**/*.js'],
        ignore: {
          useGitignore: true,
          useDefaultPatterns: false,
          customPatterns: [],
        },
      });

      const mockFileStructure = [
        'root/file1.js',
        'root/subdir/file2.js',
        'root/subdir/ignored.js',
        'root/another/file3.js',
      ];

      const mockGitignoreContent = {
        '/mock/root/.gitignore': '*.log',
        '/mock/root/subdir/.gitignore': 'ignored.js',
      };

      vi.mocked(globby).mockImplementation(async () => {
        // Simulate filtering files based on .gitignore
        return mockFileStructure.filter((file) => {
          const relativePath = file.replace('root/', '');
          const dir = path.dirname(relativePath);
          const gitignorePath = path.join('/mock/root', dir, '.gitignore');
          const gitignoreContent = mockGitignoreContent[gitignorePath as keyof typeof mockGitignoreContent];
          if (gitignoreContent && minimatch(path.basename(file), gitignoreContent)) {
            return false;
          }
          return true;
        });
      });

      vi.mocked(fs.readFile).mockImplementation(async (filePath) => {
        return mockGitignoreContent[filePath as keyof typeof mockGitignoreContent] || '';
      });

      const result = await searchFiles('/mock/root', mockConfig);
      expect(result).toEqual(['root/another/file3.js', 'root/subdir/file2.js', 'root/file1.js']);
      expect(result).not.toContain('root/subdir/ignored.js');
    });

    test('should not apply .gitignore when useGitignore is false', async () => {
      const mockConfig = createMockConfig({
        include: ['**/*.js'],
        ignore: {
          useGitignore: false,
          useDefaultPatterns: false,
          customPatterns: [],
        },
      });

      const mockFileStructure = [
        'root/file1.js',
        'root/another/file3.js',
        'root/subdir/file2.js',
        'root/subdir/ignored.js',
      ];

      vi.mocked(globby).mockResolvedValue(mockFileStructure);

      const result = await searchFiles('/mock/root', mockConfig);

      expect(result).toEqual(mockFileStructure);
      expect(result).toContain('root/subdir/ignored.js');
    });
  });
});


// tests/core/file/fileSearch.test.ts


import {  it} from 'vitest';

import { PermissionError } from '../../../src/core/file/permissionCheck.js';
import { logger } from '../../../src/shared/logger.js';

vi.mock('fs/promises');
vi.mock('globby');
vi.mock('../../../src/shared/logger');

describe('fileSearch', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  describe('searchFiles', () => {
    it('should correctly filter and sort files', async () => {
      const mockConfig = createMockConfig({
        include: ['**/*.js'],
        ignore: {
          useGitignore: true,
          customPatterns: ['ignore/**'],
        },
      });

      vi.mocked(fs.stat).mockResolvedValue({
        isFile: () => true,
      } as fs.Stats);

      vi.mocked(globby).mockResolvedValue([
        'src/index.js',
        'src/utils/helper.js',
        'tests/test.js',
      ]);

      const result = await searchFiles('/test/dir', mockConfig);

      expect(result).toEqual([
        'src/index.js',
        'src/utils/helper.js',
        'tests/test.js',
      ]);

      expect(globby).toHaveBeenCalledWith(
        ['**/*.js'],
        expect.objectContaining({
          cwd: '/test/dir',
          ignore: expect.arrayContaining(['ignore/**']),
          ignoreFiles: expect.arrayContaining(['**/.gitignore', '**/.repofmignore']),
          onlyFiles: true,
          absolute: false,
          dot: true,
          followSymbolicLinks: false,
        }),
      );
    });

    it('should handle permission errors', async () => {
      const mockConfig = createMockConfig();

      vi.mocked(fs.stat).mockRejectedValue(new Error('EPERM: permission denied'));

      await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow(PermissionError);
      expect(logger.error).toHaveBeenCalled();
    });

    it('should use default include pattern when none specified', async () => {
      const mockConfig = createMockConfig({
        include: [],
      });

      vi.mocked(fs.stat).mockResolvedValue({
        isFile: () => true,
      } as fs.Stats);

      await searchFiles('/test/dir', mockConfig);

      expect(globby).toHaveBeenCalledWith(
        ['**/*'],
        expect.any(Object),
      );
    });

    it('should handle nested gitignore files', async () => {
      const mockConfig = createMockConfig({
        ignore: {
          useGitignore: true,
        },
      });

      vi.mocked(fs.stat).mockResolvedValue({
        isFile: () => true,
      } as fs.Stats);

      vi.mocked(globby).mockResolvedValue([
        'src/index.js',
        'src/subdir/file.js',
      ]);

      const result = await searchFiles('/test/dir', mockConfig);

      expect(result).toEqual([
        'src/index.js',
        'src/subdir/file.js',
      ]);

      expect(globby).toHaveBeenCalledWith(
        expect.any(Array),
        expect.objectContaining({
          ignoreFiles: expect.arrayContaining(['**/.gitignore']),
        }),
      );
    });

    it('should handle symbolic links', async () => {
      const mockConfig = createMockConfig();

      vi.mocked(fs.stat).mockResolvedValue({
        isFile: () => true,
        isSymbolicLink: () => true,
      } as unknown as fs.Stats);

      vi.mocked(globby).mockResolvedValue([
        'link.js',
        'real.js',
      ]);

      const result = await searchFiles('/test/dir', mockConfig);

      expect(result).toEqual([
        'link.js',
        'real.js',
      ]);
    });
  });

  describe('getIgnoreFilePatterns', () => {
    it('should include gitignore patterns when enabled', async () => {
      const mockConfig = createMockConfig({
        ignore: {
          useGitignore: true,
        },
      });

      const patterns = await getIgnoreFilePatterns(mockConfig);

      expect(patterns).toContain('**/.gitignore');
      expect(patterns).toContain('**/.repofmignore');
    });

    it('should exclude gitignore patterns when disabled', async () => {
      const mockConfig = createMockConfig({
        ignore: {
          useGitignore: false,
        },
      });

      const patterns = await getIgnoreFilePatterns(mockConfig);

      expect(patterns).not.toContain('**/.gitignore');
      expect(patterns).toContain('**/.repofmignore');
    });
  });



  it('should not include default patterns when disabled', async () => {
    const mockConfig = createMockConfig({
      ignore: {
        useDefaultPatterns: false,
        customPatterns: ['custom-ignore'],
      },
    });

    const patterns = await getIgnorePatterns('/test/dir', mockConfig);

    expect(patterns).not.toContain('**/node_modules/**');
    expect(patterns).not.toContain('**/.git/**');
    expect(patterns).toContain('custom-ignore');
  });

  it('should merge all ignore pattern sources', async () => {
    const mockConfig = createMockConfig({
      output: {
        filePath: 'output.txt',
      },
      ignore: {
        useDefaultPatterns: true,
        customPatterns: ['custom-pattern'],
      },
    });

    const patterns = await getIgnorePatterns('/test/dir', mockConfig);

    // Should include output file
    expect(patterns).toContain('output.txt');
    // Should include default patterns
    expect(patterns).toContain('**/node_modules/**');
    // Should include custom patterns
    expect(patterns).toContain('custom-pattern');
  });
});

describe('parseIgnoreContent', () => {
  it('should parse basic ignore patterns', () => {
    const content = `
        # Comment
        node_modules
        *.log

        .DS_Store
      `;

    const patterns = parseIgnoreContent(content);
    expect(patterns).toEqual(['node_modules', '*.log', '.DS_Store']);
  });

  it('should handle empty content', () => {
    expect(parseIgnoreContent('')).toEqual([]);
  });

  it('should handle content with only comments', () => {
    const content = `
        # Comment 1
        # Comment 2
        # Comment 3
      `;

    expect(parseIgnoreContent(content)).toEqual([]);
  });

  it('should handle mixed line endings', () => {
    const content = 'pattern1\r\npattern2\npattern3\rpattern4';
    const patterns = parseIgnoreContent(content);
    expect(patterns).toEqual(['pattern1', 'pattern2', 'pattern3', 'pattern4']);
  });

  it('should handle patterns with spaces', () => {
    const content = `
        # Comment
        path with spaces
        another path  with  spaces
        *.log
      `;

    const patterns = parseIgnoreContent(content);
    expect(patterns).toEqual(['path with spaces', 'another path  with  spaces', '*.log']);
  });

  it('should ignore empty lines', () => {
    const content = `
        pattern1

        pattern2

        pattern3
      `;

    const patterns = parseIgnoreContent(content);
    expect(patterns).toEqual(['pattern1', 'pattern2', 'pattern3']);
  });
});

describe('searchFiles - Complex Scenarios', () => {
  it('should handle complex gitignore patterns', async () => {
    const mockConfig = createMockConfig({
      ignore: {
        useGitignore: true,
        customPatterns: [],
      },
    });

    // Mock .gitignore content with complex patterns
    vi.mocked(fs.readFile).mockResolvedValue(`
        # Node
        node_modules/

        # Build
        dist/
        build/

        # Logs
        *.log
        logs/

        # IDEs
        .idea/
        .vscode/

        # OS
        .DS_Store
        Thumbs.db

        # Specific files
        config.local.js
        !config.example.js
      `);

    vi.mocked(globby).mockResolvedValue([
      'src/index.js',
      'config.example.js',
      'src/components/Button.jsx',
    ]);

    const result = await searchFiles('/test/dir', mockConfig);

    expect(result).toEqual([
      'config.example.js',
      'src/components/Button.jsx',
      'src/index.js',
    ]);
  });

  it('should handle nested repofmignore files', async () => {
    const mockConfig = createMockConfig({
      include: ['**/*'],
      ignore: {
        useGitignore: true,
        useDefaultPatterns: true,
      },
    });

    // Mock root .repofmignore
    vi.mocked(fs.readFile).mockImplementation(async (path) => {
      if (path.toString().endsWith('/.repofmignore')) {
        return 'root-ignored/';
      }
      return '';
    });

    vi.mocked(globby).mockResolvedValue([
      'src/index.js',
      'src/components/Button.jsx',
      'root-ignored/file.js',
    ]);

    const result = await searchFiles('/test/dir', mockConfig);

    expect(result).not.toContain('root-ignored/file.js');
    expect(result).toContain('src/index.js');
    expect(result).toContain('src/components/Button.jsx');
  });

  it('should handle include patterns with negation', async () => {
    const mockConfig = createMockConfig({
      include: ['**/*.js', '!**/*.test.js'],
      ignore: {
        useGitignore: true,
      },
    });

    vi.mocked(globby).mockResolvedValue([
      'src/index.js',
      'src/utils.js',
      'src/utils.test.js',
      'tests/index.test.js',
    ]);

    const result = await searchFiles('/test/dir', mockConfig);

    expect(result).toContain('src/index.js');
    expect(result).toContain('src/utils.js');
    expect(result).not.toContain('src/utils.test.js');
    expect(result).not.toContain('tests/index.test.js');
  });

  it('should handle large directory structures', async () => {
    const mockConfig = createMockConfig();
    const mockFiles = Array.from({ length: 1000 }, (_, i) =>
      `src/module${Math.floor(i / 10)}/component${i}.js`
    );

    vi.mocked(globby).mockResolvedValue(mockFiles);
    vi.mocked(fs.stat).mockResolvedValue({
      isFile: () => true,
    } as fs.Stats);

    const result = await searchFiles('/test/dir', mockConfig);

    expect(result).toHaveLength(1000);
    expect(result).toBeSorted(); // Verify files are sorted
  });

  it('should handle file permission errors gracefully', async () => {
    const mockConfig = createMockConfig();

    vi.mocked(globby).mockImplementation(() => {
      throw new Error('EPERM: permission denied');
    });

    await expect(searchFiles('/test/dir', mockConfig)).rejects.toThrow(PermissionError);
    expect(logger.error).toHaveBeenCalled();
  });

  it('should handle network paths', async () => {
    const mockConfig = createMockConfig();
    const networkPath = process.platform === 'win32'
      ? '\\\\server\\share\\folder'
      : '/mnt/network/folder';

    vi.mocked(fs.stat).mockResolvedValue({
      isFile: () => true,
    } as fs.Stats);

    vi.mocked(globby).mockResolvedValue([
      'file1.js',
      'file2.js',
    ]);

    await searchFiles(networkPath, mockConfig);

    expect(globby).toHaveBeenCalledWith(
      expect.any(Array),
      expect.objectContaining({
        cwd: networkPath,
      }),
    );
  });

  it('should handle errors during gitignore parsing', async () => {
    const mockConfig = createMockConfig({
      ignore: {
        useGitignore: true,
      },
    });

    vi.mocked(fs.readFile).mockRejectedValue(new Error('Failed to read gitignore'));
    vi.mocked(globby).mockResolvedValue(['file1.js', 'file2.js']);

    const result = await searchFiles('/test/dir', mockConfig);

    expect(result).toEqual(['file1.js', 'file2.js']);
    expect(logger.warn).toHaveBeenCalled();
  });
});
});

================
File: tests/core/file/fileTreeGenerate.test.ts
================
// tests/core/file/fileTreeGenerate.test.ts

import path from 'node:path';
import { describe, expect, test } from 'vitest';
import { generateFileTree, generateTreeString, treeToString, buildTree } from '../../../src/core/file/fileTreeGenerate.js';

describe('fileTreeGenerate', () => {
  const sep = path.sep;

  describe('generateFileTree', () => {
    test('should generate correct tree structure for flat files', () => {
      const files = [
        'file1.txt',
        'file2.js',
        'file3.css',
      ];

      const tree = generateFileTree(files);

      expect(tree.name).toBe('root');
      expect(tree.isDirectory).toBe(true);
      expect(tree.children).toHaveLength(3);
      expect(tree.children.map(c => c.name)).toEqual(['file1.txt', 'file2.js', 'file3.css']);
      expect(tree.children.every(c => !c.isDirectory)).toBe(true);
    });

    test('should generate correct tree structure for nested files', () => {
      const files = [
        `src${sep}index.js`,
        `src${sep}utils${sep}helper.js`,
        `tests${sep}test.js`,
      ];

      const tree = generateFileTree(files);

      expect(tree.name).toBe('root');
      expect(tree.children).toHaveLength(2); // src and tests

      // Check src directory
      const src = tree.children.find(c => c.name === 'src');
      expect(src?.isDirectory).toBe(true);
      expect(src?.children).toHaveLength(2); // index.js and utils

      // Check utils directory
      const utils = src?.children.find(c => c.name === 'utils');
      expect(utils?.isDirectory).toBe(true);
      expect(utils?.children).toHaveLength(1); // helper.js
    });

    test('should handle empty input', () => {
      const tree = generateFileTree([]);

      expect(tree.name).toBe('root');
      expect(tree.isDirectory).toBe(true);
      expect(tree.children).toHaveLength(0);
    });

    test('should handle deep directory structure', () => {
      const files = [
        `a${sep}b${sep}c${sep}d${sep}file.txt`,
      ];

      const tree = generateFileTree(files);

      let current = tree;
      ['a', 'b', 'c', 'd'].forEach(dir => {
        const child = current.children.find(c => c.name === dir);
        expect(child).toBeDefined();
        expect(child?.isDirectory).toBe(true);
        current = child!;
      });

      expect(current.children[0].name).toBe('file.txt');
      expect(current.children[0].isDirectory).toBe(false);
    });
  });

  describe('treeToString', () => {
    test('should generate correct string representation for flat structure', () => {
      const files = [
        'file1.txt',
        'file2.js',
        'file3.css',
      ];

      const tree = generateFileTree(files);
      const result = treeToString(tree);

      const expected = [
        'file1.txt',
        'file2.js',
        'file3.css',
      ].join('\n');

      expect(result).toBe(expected);
    });

    test('should generate correct string representation for nested structure', () => {
      const files = [
        `src${sep}index.js`,
        `src${sep}utils${sep}helper.js`,
        `tests${sep}test.js`,
      ];

      const tree = generateFileTree(files);
      const result = treeToString(tree);

      const expected = [
        'src/',
        '  index.js',
        '  utils/',
        '    helper.js',
        'tests/',
        '  test.js',
      ].join('\n');

      expect(result).toBe(expected);
    });

    test('should handle empty tree', () => {
      const tree = generateFileTree([]);
      const result = treeToString(tree);

      expect(result).toBe('');
    });

    test('should handle deep nesting', () => {
      const files = [
        `a${sep}b${sep}c${sep}d${sep}file.txt`,
      ];

      const tree = generateFileTree(files);
      const result = treeToString(tree);

      const expected = [
        'a/',
        '  b/',
        '    c/',
        '      d/',
        '        file.txt',
      ].join('\n');

      expect(result).toBe(expected);
    });
  });

  describe('generateTreeString', () => {
    test('should generate complete tree string for mixed structure', () => {
      const files = [
        'root.txt',
        `src${sep}index.js`,
        `src${sep}components${sep}Button.jsx`,
        `src${sep}utils${sep}helper.js`,
        `tests${sep}unit${sep}test.js`,
        `tests${sep}integration${sep}test.js`,
        'package.json',
      ];

      const result = generateTreeString(files);

      const expected = [
        'package.json',
        'root.txt',
        'src/',
        '  components/',
        '    Button.jsx',
        '  index.js',
        '  utils/',
        '    helper.js',
        'tests/',
        '  integration/',
        '    test.js',
        '  unit/',
        '    test.js',
      ].join('\n');

      expect(result).toBe(expected);
    });

    test('should sort directories before files', () => {
      const files = [
        'file.txt',
        `dir${sep}file.txt`,
        'another.txt',
      ];

      const result = generateTreeString(files);

      const expected = [
        'dir/',
        '  file.txt',
        'another.txt',
        'file.txt',
      ].join('\n');

      expect(result).toBe(expected);
    });

    test('should sort files alphabetically within directories', () => {
      const files = [
        `dir${sep}c.txt`,
        `dir${sep}a.txt`,
        `dir${sep}b.txt`,
      ];

      const result = generateTreeString(files);

      const expected = [
        'dir/',
        '  a.txt',
        '  b.txt',
        '  c.txt',
      ].join('\n');

      expect(result).toBe(expected);
    });
  });

  describe('Edge Cases', () => {
    test('should handle files with special characters in names', () => {
      const files = [
        'file with spaces.txt',
        'file-with-dashes.txt',
        'file_with_underscores.txt',
        'file.with.dots.txt',
      ];

      const result = generateTreeString(files);

      const expected = [
        'file with spaces.txt',
        'file-with-dashes.txt',
        'file.with.dots.txt',
        'file_with_underscores.txt',
      ].join('\n');

      expect(result).toBe(expected);
    });

    test('should handle files with unicode characters', () => {
      const files = [
        '文件.txt',
        'ファイル.txt',
        'файл.txt',
        '파일.txt',
      ];

      const result = generateTreeString(files);

      expect(result.split('\n')).toHaveLength(4);
      expect(result).toContain('文件.txt');
      expect(result).toContain('ファイル.txt');
      expect(result).toContain('файл.txt');
      expect(result).toContain('파일.txt');
    });

    test('should handle files with same names in different directories', () => {
      const files = [
        `dir1${sep}file.txt`,
        `dir2${sep}file.txt`,
        `dir1${sep}subdir${sep}file.txt`,
      ];

      const result = generateTreeString(files);

      const expected = [
        'dir1/',
        '  subdir/',
        '    file.txt',
        '  file.txt',
        'dir2/',
        '  file.txt',
      ].join('\n');

      expect(result).toBe(expected);
    });

    test('should handle hidden files and directories', () => {
      const files = [
        '.gitignore',
        '.env',
        `${sep}.config${sep}file.txt`,
        '.hidden-file.txt',
      ];

      const result = generateTreeString(files);

      const expected = [
        '.config/',
        '  file.txt',
        '.env',
        '.gitignore',
        '.hidden-file.txt',
      ].join('\n');

      expect(result).toBe(expected);
    });

    test('should handle mixed case filenames', () => {
      const files = [
        'File.txt',
        'file.txt',
        'FILE.txt',
        'FiLe.txt',
      ];

      const result = generateTreeString(files);

      expect(result.split('\n')).toHaveLength(4);
      files.forEach(file => {
        expect(result).toContain(file);
      });
    });

    test('should handle extremely deep directory structures', () => {
      const depth = 50;
      const pathParts = Array(depth).fill('dir');
      const files = [
        pathParts.join(sep) + `${sep}file.txt`,
      ];

      const result = generateTreeString(files);

      expect(result.split('\n')).toHaveLength(depth + 1); // dirs + file
      expect(result).toContain('file.txt');
      expect(result.match(/dir\//g)).toHaveLength(depth);
    });

    test('should handle large number of files and directories', () => {
      const numFiles = 1000;
      const files = Array.from({ length: numFiles }, (_, i) =>
        i % 2 === 0 ? `dir${i}${sep}file${i}.txt` : `file${i}.txt`
      );

      const result = generateTreeString(files);

      const lines = result.split('\n');
      expect(lines.length).toBe(numFiles + numFiles / 2); // files + directories
    });
  });

  describe('buildTree', () => {
    it('should build correct tree structure', () => {
      const files = [
        'src/components/Button.jsx',
        'src/utils/helper.js',
        'src/index.js',
        'package.json',
        'README.md'
      ];

      const tree = buildTree(files);
      expect(tree).toEqual({
        name: '',
        isDirectory: true,
        children: [
          {
            name: 'package.json',
            isDirectory: false,
            children: []
          },
          {
            name: 'README.md',
            isDirectory: false,
            children: []
          },
          {
            name: 'src',
            isDirectory: true,
            children: [
              {
                name: 'components',
                isDirectory: true,
                children: [
                  {
                    name: 'Button.jsx',
                    isDirectory: false,
                    children: []
                  }
                ]
              },
              {
                name: 'index.js',
                isDirectory: false,
                children: []
              },
              {
                name: 'utils',
                isDirectory: true,
                children: [
                  {
                    name: 'helper.js',
                    isDirectory: false,
                    children: []
                  }
                ]
              }
            ]
          }
        ]
      });
    });

    it('should handle empty file list', () => {
      const tree = buildTree([]);
      expect(tree).toEqual({
        name: '',
        isDirectory: true,
        children: []
      });
    });
  });

  describe('treeToString', () => {
    it('should generate correct string representation', () => {
      const tree = {
        name: '',
        isDirectory: true,
        children: [
          {
            name: 'dir',
            isDirectory: true,
            children: [
              {
                name: 'file.txt',
                isDirectory: false,
                children: []
              }
            ]
          },
          {
            name: 'root.txt',
            isDirectory: false,
            children: []
          }
        ]
      };

      const result = treeToString(tree);
      const expected = [
        'dir/',
        '  file.txt',
        'root.txt'
      ].join('\n');

      expect(result).toBe(expected);
    });

    it('should sort directories before files', () => {
      const files = [
        'file.txt',
        'dir/subfile.txt',
        'another.txt'
      ];

      const result = generateTreeString(files);
      const expected = [
        'dir/',
        '  subfile.txt',
        'another.txt',
        'file.txt'
      ].join('\n');

      expect(result).toBe(expected);
    });

    it('should handle deep nesting', () => {
      const files = [
        'a/b/c/d/file.txt'
      ];

      const result = generateTreeString(files);
      const expected = [
        'a/',
        '  b/',
        '    c/',
        '      d/',
        '        file.txt'
      ].join('\n');

      expect(result).toBe(expected);
    });
  });

  describe('generateTreeString', () => {
    it('should handle mixed structure', () => {
      const files = [
        'package.json',
        'root.txt',
        'src/components/Button.jsx',
        'src/utils/helper.js',
        'src/index.js',
        'tests/unit/test.js',
        'tests/integration/test.js'
      ];

      const result = generateTreeString(files);
      const expected = [
        'src/',
        '  components/',
        '    Button.jsx',
        '  utils/',
        '    helper.js',
        '  index.js',
        'tests/',
        '  integration/',
        '    test.js',
        '  unit/',
        '    test.js',
        'package.json',
        'root.txt'
      ].join('\n');

      expect(result).toBe(expected);
    });

    it('should handle empty input', () => {
      const result = generateTreeString([]);
      expect(result).toBe('');
    });

    it('should handle single file', () => {
      const result = generateTreeString(['file.txt']);
      expect(result).toBe('file.txt');
    });

    it('should handle single directory', () => {
      const result = generateTreeString(['dir/']);
      expect(result).toBe('dir/');
    });
  });
});

================
File: tests/core/file/packageJsonParse.test.ts
================
import { getVersion, clearVersionCache, getPackageVersion } from '../../../src/core/file/packageJsonParse';
import { logger } from '../../../src/utils/logger';
import * as fs from 'node:fs/promises';

jest.mock('node:fs/promises');
jest.mock('../../../src/utils/logger');

describe('packageJsonParse', () => {
  beforeEach(() => {
    jest.clearAllMocks();
    clearVersionCache();
  });

  describe('Version Reading', () => {
    it('should read version correctly', async () => {
      (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify({ version: '1.2.3' }));
      const version = await getVersion();
      expect(version).toBe('1.2.3');
    });

    it('should cache version value', async () => {
      (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify({ version: '1.2.3' }));

      const version1 = await getVersion();
      const version2 = await getVersion();

      expect(version1).toBe('1.2.3');
      expect(version2).toBe('1.2.3');
      expect(fs.readFile).toHaveBeenCalledTimes(1);
    });
  });

  describe('Error Handling', () => {
    it('should handle non-existent package.json', async () => {
      (fs.readFile as jest.Mock).mockRejectedValue(new Error('ENOENT'));

      const version = await getVersion();
      expect(version).toBe('unknown');
      expect(logger.warn).toHaveBeenCalledWith('Package.json not found');
    });

    it('should handle malformed JSON', async () => {
      (fs.readFile as jest.Mock).mockResolvedValue('invalid json');

      const version = await getVersion();
      expect(version).toBe('unknown');
      expect(logger.error).toHaveBeenCalled();
    });

    it('should handle missing version field', async () => {
      (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify({}));

      const version = await getVersion();
      expect(version).toBe('unknown');
      expect(logger.warn).toHaveBeenCalledWith('Version field not found in package.json');
    });
  });

  describe('Version Format Handling', () => {
    it('should handle numeric version', async () => {
      (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify({ version: 123 }));

      const version = await getVersion();
      expect(version).toBe('123');
    });

    it('should handle version with invalid characters', async () => {
      (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify({ version: '1.2.3$invalid' }));

      const version = await getVersion();
      expect(version).toBe('1.2.3$invalid');
    });

    it('should handle undefined version', async () => {
      (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify({ version: undefined }));

      const version = await getVersion();
      expect(version).toBe('unknown');
    });
  });

  describe('Cache Management', () => {
    it('should clear cache correctly', async () => {
      (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify({ version: '1.2.3' }));

      const version1 = await getVersion();
      clearVersionCache();
      const version2 = await getVersion();

      expect(version1).toBe('1.2.3');
      expect(version2).toBe('1.2.3');
      expect(fs.readFile).toHaveBeenCalledTimes(2);
    });
  });
});

================
File: tests/core/file/permissionCheck.test.ts
================
// tests/core/file/permissionCheck.test.ts

import * as fs from 'node:fs/promises';
import os from 'node:os';
import path from 'node:path';
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { PermissionError, checkDirectoryPermissions } from '../../../src/core/file/permissionCheck.js';
import { logger } from '../../../src/shared/logger.js';

vi.mock('node:fs/promises');
vi.mock('node:os');
vi.mock('../../../src/shared/logger');

describe('permissionCheck', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  afterEach(() => {
    vi.resetAllMocks();
  });

  describe('Basic Permission Checks', () => {
    it('should return true for directory with all permissions', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(result.details).toEqual({
        read: true,
        write: true,
        execute: true,
      });
    });

    it('should handle missing permissions', async () => {
      // Mock access to fail for write permission
      vi.mocked(fs.access)
        .mockResolvedValueOnce(undefined) // Read OK
        .mockRejectedValueOnce(new Error('EACCES')) // Write Failed
        .mockResolvedValueOnce(undefined); // Execute OK

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.details).toEqual({
        read: true,
        write: false,
        execute: true,
      });
    });

    it('should handle completely inaccessible directory', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('EACCES: permission denied'));
      vi.mocked(fs.readdir).mockRejectedValue(new Error('EACCES: permission denied'));

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(false);
      expect(result.error).toBeInstanceOf(PermissionError);
      expect(result.details).toEqual({
        read: false,
        write: false,
        execute: false,
      });
    });
  });

  describe('Platform-Specific Behavior', () => {
    it('should handle Windows permissions', async () => {
      vi.mocked(os.platform).mockReturnValue('win32');
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(fs.readdir).mockResolvedValue([]);

      const result = await checkDirectoryPermissions('C:\\test\\dir');

      expect(result.hasPermission).toBe(true);
      expect(result.details).toBeDefined();
    });

    it('should handle macOS permissions', async () => {
      vi.mocked(os.platform).mockReturnValue('darwin');
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(fs.readdir).mockResolvedValue([]);

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(result.details).toBeDefined();
    });

    it('should handle Linux permissions', async () => {
      vi.mocked(os.platform).mockReturnValue('linux');
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(fs.readdir).mockResolvedValue([]);

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(result.details).toBeDefined();
    });
  });

  describe('Error Handling', () => {
    it('should handle ENOENT error', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('ENOENT: no such file or directory'));

      const result = await checkDirectoryPermissions('/nonexistent/dir');

      expect(result.hasPermission).toBe(false);
      expect(result.error?.message).toContain('no such file or directory');
    });

    it('should handle EPERM error', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('EPERM: operation not permitted'));

      const result = await checkDirectoryPermissions('/protected/dir');

      expect(result.hasPermission).toBe(false);
      expect(result.error).toBeInstanceOf(PermissionError);
    });

    it('should handle unexpected errors', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('Unexpected error'));

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(false);
      expect(logger.debug).toHaveBeenCalled();
    });
  });

  describe('Directory Content Access', () => {
    it('should check subdirectory permissions', async () => {
      const mockFiles = ['file1', 'file2', 'subdir'];
      const mockStats = { isDirectory: () => false };

      vi.mocked(fs.readdir).mockResolvedValue(mockFiles as any);
      vi.mocked(fs.stat).mockResolvedValue(mockStats as any);
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(fs.readdir).toHaveBeenCalled();
    });

    it('should handle partial access to subdirectories', async () => {
      vi.mocked(fs.readdir).mockResolvedValue(['accessible', 'inaccessible'] as any);
      vi.mocked(fs.stat).mockResolvedValue({ isDirectory: () => true } as any);
      vi.mocked(fs.access)
        .mockResolvedValueOnce(undefined) // Root directory
        .mockResolvedValueOnce(undefined) // Accessible directory
        .mockRejectedValueOnce(new Error('EACCES')); // Inaccessible directory

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(logger.debug).toHaveBeenCalled();
    });
  });

  describe('Symbolic Links', () => {
    it('should handle symbolic links', async () => {
      vi.mocked(fs.stat).mockResolvedValue({
        isDirectory: () => false,
        isSymbolicLink: () => true,
      } as any);
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/test/link');

      expect(result.hasPermission).toBe(true);
    });

    it('should handle broken symbolic links', async () => {
      vi.mocked(fs.stat).mockResolvedValue({
        isDirectory: () => false,
        isSymbolicLink: () => true,
      } as any);
      vi.mocked(fs.access).mockRejectedValue(new Error('ENOENT'));

      const result = await checkDirectoryPermissions('/test/broken-link');

      expect(result.hasPermission).toBe(false);
      expect(result.error).toBeDefined();
    });
  });

  describe('Special Cases', () => {
    it('should handle root directory', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/');

      expect(result.hasPermission).toBe(true);
    });

    it('should handle home directory', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(os.homedir).mockReturnValue('/home/user');

      const result = await checkDirectoryPermissions('~/test');

      expect(result.hasPermission).toBe(true);
    });

    it('should handle relative paths', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('./test');

      expect(result.hasPermission).toBe(true);
      expect(fs.access).toHaveBeenCalledWith(
        expect.stringContaining('test'),
        expect.any(Number)
      );
    });

    it('should handle network paths', async () => {
      const networkPath = process.platform === 'win32'
        ? '\\\\server\\share'
        : '/mnt/network';

      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions(networkPath);

      expect(result.hasPermission).toBe(true);
    });

    it('should handle paths with spaces', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/path with spaces/test');

      expect(result.hasPermission).toBe(true);
    });
  });

  describe('Permission Error Details', () => {
    it('should provide detailed error messages for macOS', async () => {
      vi.mocked(os.platform).mockReturnValue('darwin');
      vi.mocked(fs.access).mockRejectedValue(new Error('EACCES'));

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.error).toBeInstanceOf(PermissionError);
      expect(result.error?.message).toContain('System Settings');
      expect(result.error?.message).toContain('Privacy & Security');
    });

    it('should provide basic error messages for non-macOS platforms', async () => {
      vi.mocked(os.platform).mockReturnValue('linux');
      vi.mocked(fs.access).mockRejectedValue(new Error('EACCES'));

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.error).toBeInstanceOf(PermissionError);
      expect(result.error?.message).not.toContain('System Settings');
    });

    it('should include path information in error messages', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('EACCES'));

      const testPath = '/test/dir';
      const result = await checkDirectoryPermissions(testPath);

      // First verify error exists and has message
      expect(result.error).toBeDefined();
      expect(result.error?.message).toBeDefined();

      // Then check message content
      expect(result.error?.message).toContain(testPath);
    });
  });

  describe('Performance', () => {
// tests/core/file/permissionCheck.test.ts

import * as fs from 'node:fs/promises';
import os from 'node:os';
import path from 'node:path';
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { PermissionError, checkDirectoryPermissions } from '../../../src/core/file/permissionCheck.js';
import { logger } from '../../../src/shared/logger.js';

vi.mock('node:fs/promises');
vi.mock('node:os');
vi.mock('../../../src/shared/logger');

describe('permissionCheck', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  afterEach(() => {
    vi.resetAllMocks();
  });

  describe('Basic Permission Checks', () => {
    it('should return true for directory with all permissions', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(result.details).toEqual({
        read: true,
        write: true,
        execute: true,
      });
    });

    it('should handle missing permissions', async () => {
      // Mock access to fail for write permission
      vi.mocked(fs.access)
        .mockResolvedValueOnce(undefined) // Read OK
        .mockRejectedValueOnce(new Error('EACCES')) // Write Failed
        .mockResolvedValueOnce(undefined); // Execute OK

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.details).toEqual({
        read: true,
        write: false,
        execute: true,
      });
    });

    it('should handle completely inaccessible directory', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('EACCES: permission denied'));
      vi.mocked(fs.readdir).mockRejectedValue(new Error('EACCES: permission denied'));

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(false);
      expect(result.error).toBeInstanceOf(PermissionError);
      expect(result.details).toEqual({
        read: false,
        write: false,
        execute: false,
      });
    });
  });

  describe('Platform-Specific Behavior', () => {
    it('should handle Windows permissions', async () => {
      vi.mocked(os.platform).mockReturnValue('win32');
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(fs.readdir).mockResolvedValue([]);

      const result = await checkDirectoryPermissions('C:\\test\\dir');

      expect(result.hasPermission).toBe(true);
      expect(result.details).toBeDefined();
    });

    it('should handle macOS permissions', async () => {
      vi.mocked(os.platform).mockReturnValue('darwin');
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(fs.readdir).mockResolvedValue([]);

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(result.details).toBeDefined();
    });

    it('should handle Linux permissions', async () => {
      vi.mocked(os.platform).mockReturnValue('linux');
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(fs.readdir).mockResolvedValue([]);

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(result.details).toBeDefined();
    });
  });

  describe('Error Handling', () => {
    it('should handle ENOENT error', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('ENOENT: no such file or directory'));

      const result = await checkDirectoryPermissions('/nonexistent/dir');

      expect(result.hasPermission).toBe(false);
      expect(result.error?.message).toContain('no such file or directory');
    });

    it('should handle EPERM error', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('EPERM: operation not permitted'));

      const result = await checkDirectoryPermissions('/protected/dir');

      expect(result.hasPermission).toBe(false);
      expect(result.error).toBeInstanceOf(PermissionError);
    });

    it('should handle unexpected errors', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('Unexpected error'));

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(false);
      expect(logger.debug).toHaveBeenCalled();
    });
  });

  describe('Directory Content Access', () => {
    it('should check subdirectory permissions', async () => {
      const mockFiles = ['file1', 'file2', 'subdir'];
      const mockStats = { isDirectory: () => false };

      vi.mocked(fs.readdir).mockResolvedValue(mockFiles as any);
      vi.mocked(fs.stat).mockResolvedValue(mockStats as any);
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(fs.readdir).toHaveBeenCalled();
    });

    it('should handle partial access to subdirectories', async () => {
      vi.mocked(fs.readdir).mockResolvedValue(['accessible', 'inaccessible'] as any);
      vi.mocked(fs.stat).mockResolvedValue({ isDirectory: () => true } as any);
      vi.mocked(fs.access)
        .mockResolvedValueOnce(undefined) // Root directory
        .mockResolvedValueOnce(undefined) // Accessible directory
        .mockRejectedValueOnce(new Error('EACCES')); // Inaccessible directory

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.hasPermission).toBe(true);
      expect(logger.debug).toHaveBeenCalled();
    });
  });

  describe('Symbolic Links', () => {
    it('should handle symbolic links', async () => {
      vi.mocked(fs.stat).mockResolvedValue({
        isDirectory: () => false,
        isSymbolicLink: () => true,
      } as any);
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/test/link');

      expect(result.hasPermission).toBe(true);
    });

    it('should handle broken symbolic links', async () => {
      vi.mocked(fs.stat).mockResolvedValue({
        isDirectory: () => false,
        isSymbolicLink: () => true,
      } as any);
      vi.mocked(fs.access).mockRejectedValue(new Error('ENOENT'));

      const result = await checkDirectoryPermissions('/test/broken-link');

      expect(result.hasPermission).toBe(false);
      expect(result.error).toBeDefined();
    });
  });

  describe('Special Cases', () => {
    it('should handle root directory', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/');

      expect(result.hasPermission).toBe(true);
    });

    it('should handle home directory', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(os.homedir).mockReturnValue('/home/user');

      const result = await checkDirectoryPermissions('~/test');

      expect(result.hasPermission).toBe(true);
    });

    it('should handle relative paths', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('./test');

      expect(result.hasPermission).toBe(true);
      expect(fs.access).toHaveBeenCalledWith(
        expect.stringContaining('test'),
        expect.any(Number)
      );
    });

    it('should handle network paths', async () => {
      const networkPath = process.platform === 'win32'
        ? '\\\\server\\share'
        : '/mnt/network';

      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions(networkPath);

      expect(result.hasPermission).toBe(true);
    });

    it('should handle paths with spaces', async () => {
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const result = await checkDirectoryPermissions('/path with spaces/test');

      expect(result.hasPermission).toBe(true);
    });
  });

  describe('Permission Error Details', () => {
    it('should provide detailed error messages for macOS', async () => {
      vi.mocked(os.platform).mockReturnValue('darwin');
      vi.mocked(fs.access).mockRejectedValue(new Error('EACCES'));

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.error).toBeInstanceOf(PermissionError);
      expect(result.error?.message).toContain('System Settings');
      expect(result.error?.message).toContain('Privacy & Security');
    });

    it('should provide basic error messages for non-macOS platforms', async () => {
      vi.mocked(os.platform).mockReturnValue('linux');
      vi.mocked(fs.access).mockRejectedValue(new Error('EACCES'));

      const result = await checkDirectoryPermissions('/test/dir');

      expect(result.error).toBeInstanceOf(PermissionError);
      expect(result.error?.message).not.toContain('System Settings');
    });

    it('should include path information in error messages', async () => {
      vi.mocked(fs.access).mockRejectedValue(new Error('EACCES'));

      const testPath = '/test/dir';
      const result = await checkDirectoryPermissions(testPath);

      expect(result.error?.message).toContain(testPath);
    });
  });

  describe('Performance', () => {
    it('should handle directories with many files efficiently', async () => {
      const manyFiles = Array.from({ length: 10000 }, (_, i) => `file${i}`);
      vi.mocked(fs.readdir).mockResolvedValue(manyFiles as any);
      vi.mocked(fs.access).mockResolvedValue(undefined);
      vi.mocked(fs.stat).mockResolvedValue({ isDirectory: () => false } as any);

      const startTime = Date.now();
      await checkDirectoryPermissions('/test/dir');
      const endTime = Date.now();

      expect(endTime - startTime).toBeLessThan(1000); // Should complete in less than 1 second
    });

    it('should handle deeply nested directories efficiently', async () => {
      const deepPath = path.join(...Array(50).fill('subdir')); // Very deep path
      vi.mocked(fs.access).mockResolvedValue(undefined);

      const startTime = Date.now();
      await checkDirectoryPermissions(deepPath);
      const endTime = Date.now();

      expect(endTime - startTime).toBeLessThan(1000);
    });
  });
});

================
File: tests/core/output/outputStyles/markdownStyle.test.ts
================
import process from 'node:process';
import { beforeEach, describe, expect, test, vi } from 'vitest';
import { generateOutput } from '../../../../src/core/output/outputGenerate.js';
import { createMockConfig } from '../../../testing/testUtils.js';

vi.mock('fs/promises');

describe('markdownStyle', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  test('generateOutput for md should include user-provided header text', async () => {
    const mockConfig = createMockConfig({
      output: {
        filePath: 'output.md',
        style: 'markdown',
        headerText: 'Custom header text',
        topFilesLength: 2,
        showLineNumbers: false,
        removeComments: false,
        removeEmptyLines: false,
      },
    });

    const output = await generateOutput(process.cwd(), mockConfig, [], []);

    expect(output).toContain('# File Summary');
    expect(output).toContain('# Repository Structure');
    expect(output).toContain('# Repository Files');
  });
});

================
File: tests/core/output/outputStyles/plainStyle.test.ts
================
import process from 'node:process';
import { beforeEach, describe, expect, test, vi } from 'vitest';
import { generateOutput } from '../../../../src/core/output/outputGenerate.js';
import { createMockConfig } from '../../../testing/testUtils.js';

vi.mock('fs/promises');

describe('plainStyle', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  test('generateOutput for plain should include user-provided header text', async () => {
    const mockConfig = createMockConfig({
      output: {
        filePath: 'output.txt',
        style: 'plain',
        headerText: 'Custom header text',
        topFilesLength: 2,
        showLineNumbers: false,
        removeComments: false,
        removeEmptyLines: false,
      },
    });

    const output = await generateOutput(process.cwd(), mockConfig, [], []);

    expect(output).toContain('File Summary');
    expect(output).toContain('Repository Structure');
    expect(output).toContain('Custom header text');
    expect(output).toContain('Repository Files');
  });
});

================
File: tests/core/output/outputStyles/xmlStyle.test.ts
================
import process from 'node:process';
import { beforeEach, describe, expect, test, vi } from 'vitest';
import { generateOutput } from '../../../../src/core/output/outputGenerate.js';
import { createMockConfig } from '../../../testing/testUtils.js';

vi.mock('fs/promises');

describe('xmlStyle', () => {
  beforeEach(() => {
    vi.resetAllMocks();
  });

  test('generateOutput for xml should include user-provided header text', async () => {
    const mockConfig = createMockConfig({
      output: {
        filePath: 'output.txt',
        style: 'xml',
        headerText: 'Custom header text',
        topFilesLength: 2,
        showLineNumbers: false,
        removeComments: false,
        removeEmptyLines: false,
      },
    });

    const output = await generateOutput(process.cwd(), mockConfig, [], []);

    expect(output).toContain('file_summary');
    expect(output).toContain('repository_structure');
    expect(output).toContain('Custom header text');
    expect(output).toContain('repository_files');
  });
});

================
File: tests/core/output/outputGenerate.test.ts
================
import process from 'node:process';
import { describe, expect, test } from 'vitest';
import type { ProcessedFile } from '../../../src/core/file/fileTypes.js';
import { generateOutput } from '../../../src/core/output/outputGenerate.js';
import { createMockConfig } from '../../testing/testUtils.js';
// tests/core/output/outputGenerate.test.ts

import * as fs from 'node:fs/promises';
import { afterEach, beforeEach, it, vi } from 'vitest';
import { buildOutputGeneratorContext } from '../../../src/core/output/outputGenerate.js';
import { repofmError } from '../../../src/shared/errorHandle.js';

describe('outputGenerate', () => {
  test('generateOutput should write correct content to file', async () => {
    const mockConfig = createMockConfig({
      output: {
        filePath: 'output.txt',
        style: 'plain',
        topFilesLength: 2,
        showLineNumbers: false,
        removeComments: false,
        removeEmptyLines: false,
      },
    });
    const mockProcessedFiles: ProcessedFile[] = [
      { path: 'file1.txt', content: 'content1' },
      { path: 'dir/file2.txt', content: 'content2' },
    ];

    const output = await generateOutput(process.cwd(), mockConfig, mockProcessedFiles, []);

    expect(output).toContain('File Summary');
    expect(output).toContain('File: file1.txt');
    expect(output).toContain('content1');
    expect(output).toContain('File: dir/file2.txt');
    expect(output).toContain('content2');
  });
});




vi.mock('fs/promises');
vi.mock('node:process', () => ({
  default: {
    cwd: vi.fn(),
  },
}));

describe('outputGenerate', () => {
  beforeEach(() => {
    vi.resetAllMocks();
    vi.mocked(process.cwd).mockReturnValue('/test/dir');
  });

  afterEach(() => {
    vi.restoreAllMocks();
  });

  describe('Basic Output Generation', () => {
    it('should generate plain text output', async () => {
      const config = createMockConfig({
        output: {
          style: 'plain',
          headerText: 'Test Project',
        },
      });

      const files = [
        { path: 'file1.txt', content: 'Content 1' },
        { path: 'file2.txt', content: 'Content 2' },
      ];

      const output = await generateOutput('/test/dir', config, files, ['file1.txt', 'file2.txt']);

      expect(output).toContain('Test Project');
      expect(output).toContain('file1.txt');
      expect(output).toContain('Content 1');
      expect(output).toContain('file2.txt');
      expect(output).toContain('Content 2');
      expect(output).toContain('Repository Structure');
    });

    it('should generate XML output', async () => {
      const config = createMockConfig({
        output: {
          style: 'xml',
          headerText: 'Test Project',
        },
      });

      const files = [
        { path: 'file1.txt', content: 'Content 1' },
        { path: 'file2.txt', content: 'Content 2' },
      ];

      const output = await generateOutput('/test/dir', config, files, ['file1.txt', 'file2.txt']);

      expect(output).toContain('<?xml');
      expect(output).toContain('<file path="file1.txt">');
      expect(output).toContain('Content 1');
      expect(output).toContain('</file>');
      expect(output).toContain('<repository_structure>');
    });

    it('should generate markdown output', async () => {
      const config = createMockConfig({
        output: {
          style: 'markdown',
          headerText: 'Test Project',
        },
      });

      const files = [
        { path: 'file1.txt', content: 'Content 1' },
        { path: 'file2.txt', content: 'Content 2' },
      ];

      const output = await generateOutput('/test/dir', config, files, ['file1.txt', 'file2.txt']);

      expect(output).toContain('# File Summary');
      expect(output).toContain('## File: file1.txt');
      expect(output).toContain('```');
      expect(output).toContain('Content 1');
      expect(output).toContain('# Repository Structure');
    });
  });

  describe('Header and Instructions', () => {
    it('should include custom header text', async () => {
      const config = createMockConfig({
        output: {
          headerText: 'Custom Project Header',
        },
      });

      const files = [{ path: 'file.txt', content: 'content' }];
      const output = await generateOutput('/test/dir', config, files, ['file.txt']);

      expect(output).toContain('Custom Project Header');
    });

    it('should include instruction file content', async () => {
      const config = createMockConfig({
        output: {
          instructionFilePath: 'instructions.md',
        },
      });

      vi.mocked(fs.readFile).mockResolvedValue('Custom Instructions');

      const files = [{ path: 'file.txt', content: 'content' }];
      const output = await generateOutput('/test/dir', config, files, ['file.txt']);

      expect(output). toContain('Custom Instructions');
    });

    it('should handle missing instruction file', async () => {
      const config = createMockConfig({
        output: {
          instructionFilePath: 'missing.md',
        },
      });

      vi.mocked(fs.readFile).mockRejectedValue(new Error('File not found'));

      const files = [{ path: 'file.txt', content: 'content' }];

      await expect(generateOutput('/test/dir', config, files, ['file.txt']))
        .rejects.toThrow(repofmError);
    });
  });

  describe('File Content Handling', () => {
    it('should handle special characters in content', async () => {
      const config = createMockConfig();
      const files = [{
        path: 'special.txt',
        content: '< > & " \' \n \t \r',
      }];

      const output = await generateOutput('/test/dir', config, files, ['special.txt']);

      expect(output).toContain('< > & " \' \n \t \r');
    });

    it('should handle empty files', async () => {
      const config = createMockConfig();
      const files = [{ path: 'empty.txt', content: '' }];

      const output = await generateOutput('/test/dir', config, files, ['empty.txt']);

      expect(output).toContain('empty.txt');
      expect(output).not.toContain(undefined);
    });

    it('should handle large files', async () => {
      const config = createMockConfig();
      const largeContent = 'a'.repeat(1024 * 1024); // 1MB content
      const files = [{ path: 'large.txt', content: largeContent }];

      const output = await generateOutput('/test/dir', config, files, ['large.txt']);

      expect(output).toContain('large.txt');
      expect(output).toContain(largeContent);
    });
  });

  describe('Repository Structure', () => {
    it('should generate correct structure for nested files', async () => {
      const config = createMockConfig();
      const files = [
        { path: 'src/index.js', content: 'code' },
        { path: 'src/utils/helper.js', content: 'helper' },
        { path: 'tests/test.js', content: 'test' },
      ];

      const allPaths = ['src/index.js', 'src/utils/helper.js', 'tests/test.js'];
      const output = await generateOutput('/test/dir', config, files, allPaths);

      expect(output).toContain('src/');
      expect(output).toContain('utils/');
      expect(output).toContain('tests/');
    });

    it('should handle empty directories', async () => {
      const config = createMockConfig();
      const files: any[] = [];
      const allPaths: string[] = [];

      const output = await generateOutput('/test/dir', config, files, allPaths);

      expect(output).toContain('Repository Structure');
      expect(output).not.toContain(undefined);
    });
  });

  describe('Error Handling', () => {
    it('should handle file path errors', async () => {
      const config = createMockConfig();
      const files = [{ path: '../outside.txt', content: 'content' }];

      const output = await generateOutput('/test/dir', config, files, ['../outside.txt']);

      expect(output).toContain('../outside.txt');
    });

    it('should handle invalid file paths', async () => {
      const config = createMockConfig();
      const files = [{ path: '', content: 'content' }];

      const output = await generateOutput('/test/dir', config, files, ['']);

      expect(output).toBeDefined();
      expect(output).not.toContain(undefined);
    });
  });

  describe('Context Building', () => {
    it('should build correct context with instruction file', async () => {
      const config = createMockConfig({
        output: {
          instructionFilePath: 'instructions.md',
        },
      });

      vi.mocked(fs.readFile).mockResolvedValue('Instructions Content');

      const context = await buildOutputGeneratorContext(
        '/test/dir',
        config,
        ['file.txt'],
        [{ path: 'file.txt', content: 'content' }]
      );

      expect(context.instruction).toBe('Instructions Content');
      expect(context.config).toBe(config);
      expect(context.processedFiles).toHaveLength(1);
    });

    it('should handle missing instruction file', async () => {
      const config = createMockConfig({
        output: {
          instructionFilePath: 'missing.md',
        },
      });

      vi.mocked(fs.readFile).mockRejectedValue(new Error('File not found'));

      await expect(buildOutputGeneratorContext(
        '/test/dir',
        config,
        ['file.txt'],
        [{ path: 'file.txt', content: 'content' }]
      )).rejects.toThrow(repofmError);
    });
  });

  describe('Performance', () => {
    it('should handle large number of files efficiently', async () => {
      const config = createMockConfig();
      const files = Array.from({ length: 1000 }, (_, i) => ({
        path: `file${i}.txt`,
        content: `content ${i}`,
      }));

      const allPaths = files.map(f => f.path);

      const startTime = Date.now();
      await generateOutput('/test/dir', config, files, allPaths);
      const endTime = Date.now();

      expect(endTime - startTime).toBeLessThan(5000); // Should complete within 5 seconds
    });

    it('should handle deep directory structures efficiently', async () => {
      const config = createMockConfig();
      const depth = 20;
      const files = Array.from({ length: depth }, (_, i) => ({
        path: Array(i + 1).fill('dir').join('/') + '/file.txt',
        content: 'content',
      }));

      const allPaths = files.map(f => f.path);

      const startTime = Date.now();
      await generateOutput('/test/dir', config, files, allPaths);
      const endTime = Date.now();

      expect(endTime - startTime).toBeLessThan(1000); // Should complete within 1 second
    });
  });

  describe('File Extensions', () => {
    it('should handle various file extensions correctly in markdown', async () => {
      const config = createMockConfig({
        output: {
          style: 'markdown',
        },
      });

      const files = [
        { path: 'script.js', content: 'javascript code' },
        { path: 'style.css', content: 'css code' },
        { path: 'template.html', content: 'html code' },
        { path: 'data.json', content: 'json data' },
      ];

      const output = await generateOutput('/test/dir', config, files, files.map(f => f.path));

      expect(output).toContain('```javascript\n');
      expect(output).toContain('```css\n');
      expect(output).toContain('```html\n');
      expect(output).toContain('```json\n');
    });
  });
});

================
File: tests/core/tokenCount/tokenCount.test.ts
================
import { afterAll, beforeAll, describe, expect, test } from 'vitest';
import { TokenCounter } from '../../../src/core/tokenCount/tokenCount.js';
import { it, vi } from 'vitest';
import { logger } from '../../../src/shared/logger.js';
vi.mock('../../../src/shared/logger');
describe('tokenCount', () => {
  let tokenCounter: TokenCounter;

  beforeAll(() => {
    tokenCounter = new TokenCounter();
  });

  afterAll(() => {
    tokenCounter.free();
  });

  test('should correctly count tokens', () => {
    const testCases = [
      { input: 'Hello, world!', expectedTokens: 4 },
      { input: 'This is a longer sentence with more tokens.', expectedTokens: 9 },
      { input: 'Special characters like !@#$%^&*() should be handled correctly.', expectedTokens: 15 },
      { input: 'Numbers 123 and symbols @#$ might affect tokenization.', expectedTokens: 12 },
      { input: 'Multi-line\ntext\nshould\nwork\ntoo.', expectedTokens: 11 },
    ];

    for (const { input, expectedTokens } of testCases) {
      const tokenCount = tokenCounter.countTokens(input);
      expect(tokenCount).toBe(expectedTokens);
    }
  });

  test('should handle empty input', () => {
    const tokenCount = tokenCounter.countTokens('');
    expect(tokenCount).toBe(0);
  });

  test('should handle very long input', () => {
    const longText = 'a'.repeat(1000);
    const tokenCount = tokenCounter.countTokens(longText);
    expect(tokenCount).toBeGreaterThan(0);
  });
});



describe('TokenCounter', () => {
  let tokenCounter: TokenCounter;

  beforeEach(() => {
    tokenCounter = new TokenCounter();
    vi.clearAllMocks();
  });

  afterEach(() => {
    tokenCounter.free();
  });

  describe('Basic Token Counting', () => {
    it('should count tokens in simple English text', () => {
      const text = 'Hello, world!';
      const count = tokenCounter.countTokens(text);

      expect(count).toBeGreaterThan(0);
      expect(Number.isInteger(count)).toBe(true);
    });

    it('should count tokens in multi-line text', () => {
      const text = `
        First line
        Second line
        Third line
      `;
      const count = tokenCounter.countTokens(text);

      expect(count).toBeGreaterThan(0);
      expect(Number.isInteger(count)).toBe(true);
    });

    it('should handle empty text', () => {
      const count = tokenCounter.countTokens('');
      expect(count).toBe(0);
    });

    it('should handle whitespace-only text', () => {
      const text = '    \n    \t    ';
      const count = tokenCounter.countTokens(text);
      expect(count).toBe(0);
    });
  });

  describe('Code Token Counting', () => {
    it('should count tokens in JavaScript code', () => {
      const code = `
        function greet(name) {
          console.log(\`Hello, \${name}!\`);
          return true;
        }
      `;

      const count = tokenCounter.countTokens(code);
      expect(count).toBeGreaterThan(0);
    });

    it('should count tokens in HTML markup', () => {
      const html = `
        <div class="container">
          <h1>Title</h1>
          <p>Some content</p>
        </div>
      `;

      const count = tokenCounter.countTokens(html);
      expect(count).toBeGreaterThan(0);
    });

    it('should count tokens in CSS', () => {
      const css = `
        .class {
          color: red;
          font-size: 16px;
          margin: 10px;
        }
      `;

      const count = tokenCounter.countTokens(css);
      expect(count).toBeGreaterThan(0);
    });
  });

  describe('Language Support', () => {
    it('should handle unicode characters', () => {
      const texts = [
        '你好，世界！', // Chinese
        'こんにちは、世界！', // Japanese
        '안녕하세요, 세계!', // Korean
        'Привет, мир!', // Russian
        'مرحبا العالم!', // Arabic
        'γεια σας κόσμο!', // Greek
      ];

      for (const text of texts) {
        const count = tokenCounter.countTokens(text);
        expect(count).toBeGreaterThan(0);
      }
    });

    it('should handle emojis', () => {
      const text = 'Hello 👋 World 🌍 !';
      const count = tokenCounter.countTokens(text);
      expect(count).toBeGreaterThan(0);
    });

    it('should handle special characters', () => {
      const text = '!@#$%^&*()_+-=[]{}|;:,.<>?`~';
      const count = tokenCounter.countTokens(text);
      expect(count).toBeGreaterThan(0);
    });
  });

  describe('Performance', () => {
    it('should handle large text efficiently', async () => {
      const veryLargeText = 'a '.repeat(10000);
      const startTime = Date.now();
      const count = tokenCounter.countTokens(veryLargeText);
      const endTime = Date.now();

      expect(count).toBeGreaterThan(0);
      expect(endTime - startTime).toBeLessThan(2000);
    });

    it('should handle repeated token counting', () => {
      const text = 'test text';

      const startTime = Date.now();
      for (let i = 0; i < 1000; i++) {
        tokenCounter.countTokens(text);
      }
      const endTime = Date.now();

      expect(endTime - startTime).toBeLessThan(1000); // Should complete 1000 counts within 1 second
    });
  });

  describe('Error Handling', () => {
    it('should handle invalid input types', () => {
      const invalidInputs = [null, undefined, [], {}, 123, true] as any[];

      for (const input of invalidInputs) {
        const count = tokenCounter.countTokens(input);
        expect(count).toBe(0);
        expect(logger.warn).toHaveBeenCalled();
      }
    });

    it('should handle malformed UTF-8', () => {
      const malformedText = Buffer.from([0xFF, 0xFE, 0xFD]).toString();
      const count = tokenCounter.countTokens(malformedText);

      expect(count).toBeGreaterThan(0);
    });

    it('should handle maximum string length', () => {
      const veryLargeText = 'a'.repeat(1000000);
      const count = tokenCounter.countTokens(veryLargeText);
      expect(count).toBeGreaterThan(0);
    });
  });

  describe('Resource Management', () => {
    it('should free resources when done', () => {
      const localCounter = new TokenCounter();
      const text = 'test text';

      const count = localCounter.countTokens(text);
      expect(count).toBeGreaterThan(0);

      // Should not throw when freeing resources
      expect(() => localCounter.free()).not.toThrow();
    });

    it('should handle multiple instances', () => {
      const counter1 = new TokenCounter();
      const counter2 = new TokenCounter();

      const text = 'test text';
      const count1 = counter1.countTokens(text);
      const count2 = counter2.countTokens(text);

      expect(count1).toBe(count2);

      counter1.free();
      counter2.free();
    });
  });

  describe('Content Types', () => {
    it('should handle different line endings', () => {
      const testText = 'Hello World\nThis is a test';
      const variants = [
        testText,                              // LF
        testText.replace(/\n/g, '\r\n'),      // CRLF
        testText.replace(/\n/g, '\r'),        // CR
      ];

      const counts = variants.map(content => ({
        content,
        count: tokenCounter.countTokens(content)
      }));

      // 所有变体应该产生相同的token数量
      const baseCount = counts[0].count;
      counts.forEach(({ count }, index) => {
        expect(count).toBe(baseCount,
          `Line ending variant ${index} produced different token count`);
      });
    });

    it('should handle empty lines consistently', () => {
      const inputs = [
        'Hello\n\nWorld',
        'Hello\r\n\r\nWorld',
        'Hello\r\rWorld'
      ];

      const counts = inputs.map(input => tokenCounter.countTokens(input));

      // 所有输入应该产生相同的token数量
      expect(new Set(counts).size).toBe(1);
    });

    it('should handle mixed line endings', () => {
      const input = 'Hello\nWorld\r\nTest\rEnd';
      const normalized = 'Hello\nWorld\nTest\nEnd';

      const inputCount = tokenCounter.countTokens(input);
      const normalizedCount = tokenCounter.countTokens(normalized);

      expect(inputCount).toBe(normalizedCount);
    });

    it('should count tokens in XML/JSON data', () => {
      const xmlData = `
        <?xml version="1.0" encoding="UTF-8"?>
        <root>
          <item id="1">First Item</item>
          <item id="2">Second Item</item>
        </root>
      `;

      const jsonData = `
        {
          "items": [
            {"id": 1, "name": "First Item"},
            {"id": 2, "name": "Second Item"}
          ]
        }
      `;

      const xmlCount = tokenCounter.countTokens(xmlData);
      const jsonCount = tokenCounter.countTokens(jsonData);

      expect(xmlCount).toBeGreaterThan(0);
      expect(jsonCount).toBeGreaterThan(0);
    });

    it('should handle markdown content', () => {
      const markdown = `
        # Heading 1
        ## Heading 2

        - List item 1
        - List item 2

        \`\`\`javascript
        const code = "example";
        \`\`\`

        **Bold** and *italic* text
      `;

      const count = tokenCounter.countTokens(markdown);
      expect(count).toBeGreaterThan(0);
    });
  });

  describe('Token Consistency', () => {
    it('should give consistent results for same input', () => {
      const text = 'Some test text for consistency checking';
      const counts = Array.from({ length: 10 }, () => tokenCounter.countTokens(text));

      // All counts should be identical
      expect(new Set(counts).size).toBe(1);
    });

    it('should count tokens similarly for equivalent text', () => {
      const text1 = 'Hello  World';  // Two spaces
      const text2 = 'Hello World';   // One space
      const text3 = 'Hello\tWorld';  // Tab

      const count1 = tokenCounter.countTokens(text1);
      const count2 = tokenCounter.countTokens(text2);
      const count3 = tokenCounter.countTokens(text3);

      // Should be similar counts despite different whitespace
      expect(Math.abs(count1 - count2)).toBeLessThanOrEqual(1);
      expect(Math.abs(count2 - count3)).toBeLessThanOrEqual(1);
    });
  });
});

================
File: tests/core/packager.test.ts
================
import * as fs from 'node:fs/promises';
import path from 'node:path';
import clipboardy from 'clipboardy';
import { beforeEach, describe, expect, test, vi } from 'vitest';
import { type PackDependencies, pack } from '../../src/core/packager.js';
import { TokenCounter } from '../../src/core/tokenCount/tokenCount.js';
import { createMockConfig } from '../testing/testUtils.js';

vi.mock('node:fs/promises');
vi.mock('fs/promises');
vi.mock('../../src/core/security/securityCheck');
vi.mock('../../src/core/tokenCount/tokenCount');
vi.mock('clipboardy', () => ({
  default: {
    write: vi.fn(),
  },
}));

describe('packager', () => {
  let mockDeps: PackDependencies;

  beforeEach(() => {
    vi.resetAllMocks();
    const file2Path = path.join('dir1', 'file2.txt');
    mockDeps = {
      searchFiles: vi.fn().mockResolvedValue(['file1.txt', file2Path]),
      collectFiles: vi.fn().mockResolvedValue([
        { path: 'file1.txt', content: 'raw content 1' },
        { path: file2Path, content: 'raw content 2' },
      ]),
      processFiles: vi.fn().mockReturnValue([
        { path: 'file1.txt', content: 'processed content 1' },
        { path: file2Path, content: 'processed content 2' },
      ]),
      runSecurityCheck: vi.fn().mockResolvedValue([]),
      generateOutput: vi.fn().mockResolvedValue('mock output'),
    };

    vi.mocked(TokenCounter.prototype.countTokens).mockReturnValue(10);
  });

  test('pack should process files and generate output', async () => {
    const mockConfig = createMockConfig();

    const result = await pack('root', mockConfig, () => {}, mockDeps);

    const file2Path = path.join('dir1', 'file2.txt');

    expect(mockDeps.searchFiles).toHaveBeenCalledWith('root', mockConfig);
    expect(mockDeps.collectFiles).toHaveBeenCalledWith(['file1.txt', file2Path], 'root');
    expect(mockDeps.runSecurityCheck).toHaveBeenCalled();
    expect(mockDeps.processFiles).toHaveBeenCalled();
    expect(mockDeps.generateOutput).toHaveBeenCalled();
    expect(fs.writeFile).toHaveBeenCalled();

    expect(mockDeps.processFiles).toHaveBeenCalledWith(
      [
        expect.objectContaining({
          content: 'raw content 1',
          path: 'file1.txt',
        }),
        expect.objectContaining({
          content: 'raw content 2',
          path: file2Path,
        }),
      ],
      mockConfig,
    );
    expect(mockDeps.generateOutput).toHaveBeenCalledWith(
      'root',
      mockConfig,
      [
        expect.objectContaining({
          content: 'processed content 1',
          path: 'file1.txt',
        }),
        expect.objectContaining({
          content: 'processed content 2',
          path: file2Path,
        }),
      ],
      ['file1.txt', file2Path],
    );

    // Check the result of pack function
    expect(result.totalFiles).toBe(2);
    expect(result.totalCharacters).toBe(38);
    expect(result.totalTokens).toBe(20);
    expect(result.fileCharCounts).toEqual({
      'file1.txt': 19,
      [file2Path]: 19,
    });
    expect(result.fileTokenCounts).toEqual({
      'file1.txt': 10,
      [file2Path]: 10,
    });
  });

  test('pack should handle security check and filter out suspicious files', async () => {
    const mockConfig = createMockConfig();
    const suspiciousFile = 'suspicious.txt';
    const file2Path = path.join('dir1', 'file2.txt');
    vi.mocked(mockDeps.searchFiles).mockResolvedValue(['file1.txt', file2Path, suspiciousFile]);
    vi.mocked(mockDeps.collectFiles).mockResolvedValue([
      { path: 'file1.txt', content: 'raw content 1' },
      { path: file2Path, content: 'raw content 2' },
      { path: suspiciousFile, content: 'suspicious content' },
    ]);

    // Mock the runSecurityCheck to return a suspicious file result
    vi.mocked(mockDeps.runSecurityCheck).mockResolvedValue([
      {
        filePath: path.join('root', suspiciousFile),
        messages: ['Suspicious content detected'],
      },
    ]);

    const result = await pack('root', mockConfig, () => {}, mockDeps);

    expect(mockDeps.searchFiles).toHaveBeenCalledWith('root', mockConfig);
    expect(mockDeps.processFiles).toHaveBeenCalledWith(
      [
        expect.objectContaining({
          content: 'raw content 1',
          path: 'file1.txt',
        }),
        expect.objectContaining({
          content: 'raw content 2',
          path: file2Path,
        }),
        expect.objectContaining({
          content: 'suspicious content',
          path: 'suspicious.txt',
        }),
      ],
      mockConfig,
    );

    expect(result.suspiciousFilesResults).toHaveLength(1);
    expect(result.suspiciousFilesResults[0].filePath).toContain(suspiciousFile);
    expect(result.totalFiles).toBe(2); // Only safe files should be counted
  });

  test('pack should skip security check when disabled', async () => {
    const mockConfig = createMockConfig({
      security: {
        enableSecurityCheck: false,
      },
    });

    const result = await pack('root', mockConfig, () => {}, mockDeps);

    expect(mockDeps.runSecurityCheck).not.toHaveBeenCalled();
    expect(result.suspiciousFilesResults).toEqual([]);
    expect(result.totalFiles).toBe(2); // All files should be included
  });

  test('pack should perform security check when enabled', async () => {
    const mockConfig = createMockConfig({
      security: {
        enableSecurityCheck: true,
      },
    });

    const suspiciousFile = { filePath: 'suspicious.txt', messages: ['Suspicious content detected'] };
    vi.mocked(mockDeps.runSecurityCheck).mockResolvedValue([suspiciousFile]);

    const result = await pack('root', mockConfig, () => {}, mockDeps);

    expect(mockDeps.runSecurityCheck).toHaveBeenCalled();
    expect(result.suspiciousFilesResults).toEqual([suspiciousFile]);
    expect(result.totalFiles).toBe(2); // All files should still be included in the result
  });

  test('pack should copy to clipboard when enabled', async () => {
    const mockConfig = createMockConfig({
      output: {
        copyToClipboard: true,
      },
    });

    await pack('root', mockConfig, () => {}, mockDeps);
    expect(clipboardy.write).toHaveBeenCalled();
  });
});

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/build/test.js
================
// this file should be ignored

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/resources/.repofmignore
================
ignored-data.txt

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/resources/data.txt
================
dummy data

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/resources/ignored-data.txt
================
dummy data

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/src/build/test.js
================
// this file should be ignored

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/src/index.js
================
const { greet } = require('./utils');

function main() {
  console.log(greet('World'));
}

main();

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/src/utils.js
================
function greet(name) {
  return `Hello, ${name}!`;
}

module.exports = {
  greet,
};

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/.repofmignore
================
**/build/**

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/package.json
================
{
  "name": "simple-project",
  "version": "1.0.0",
  "description": "A simple project for testing repofm",
  "main": "src/index.js",
  "scripts": {
    "start": "node src/index.js"
  },
  "keywords": ["simple", "test"],
  "author": "Test Author",
  "license": "MIT"
}

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/README.md
================
# Simple Project

This is a simple project used for testing repofm.

## Usage

To run the project:

```
npm start
```

This will output a greeting message to the console.

================
File: tests/integration-tests/fixtures/packager/inputs/simple-project/repofm.config.json
================
{
  "output": {
    "filePath": "repofm-output.txt",
    "headerText": "This repository is simple-project",
    "removeComments": false,
    "removeEmptyLines": false,
    "topFilesLength": 5,
    "showLineNumbers": false
  },
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  }
}

================
File: tests/integration-tests/fixtures/packager/outputs/simple-project-output.txt
================
This file is a merged representation of the entire codebase, combining all repository files into a single document.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.

Notes:
------
- Some files may have been excluded based on .gitignore rules and repofm's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------
User Provided Header:
-----------------------
This repository is simple-project

For more information about repofm, visit: https://github.com/chenxingqiang/repofm

================================================================
Repository Structure
================================================================
resources/
  .repofmignore
  data.txt
src/
  index.js
  utils.js
.repofmignore
package.json
README.md
repofm.config.json

================================================================
Repository Files
================================================================

================
File: resources/.repofmignore
================
ignored-data.txt

================
File: resources/data.txt
================
dummy data

================
File: src/index.js
================
const { greet } = require('./utils');

function main() {
  console.log(greet('World'));
}

main();

================
File: src/utils.js
================
function greet(name) {
  return `Hello, ${name}!`;
}

module.exports = {
  greet,
};

================
File: .repofmignore
================
**/build/**

================
File: package.json
================
{
  "name": "simple-project",
  "version": "1.0.0",
  "description": "A simple project for testing repofm",
  "main": "src/index.js",
  "scripts": {
    "start": "node src/index.js"
  },
  "keywords": ["simple", "test"],
  "author": "Test Author",
  "license": "MIT"
}

================
File: README.md
================
# Simple Project

This is a simple project used for testing repofm.

## Usage

To run the project:

```
npm start
```

This will output a greeting message to the console.

================
File: repofm.config.json
================
{
  "output": {
    "filePath": "repofm-output.txt",
    "headerText": "This repository is simple-project",
    "removeComments": false,
    "removeEmptyLines": false,
    "topFilesLength": 5,
    "showLineNumbers": false
  },
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  }
}

================
File: tests/integration-tests/fixtures/packager/outputs/simple-project-output.xml
================
This file is a merged representation of the entire codebase, combining all repository files into a single document.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and repofm's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>
<user_provided_header>
This repository is simple-project
</user_provided_header>

For more information about repofm, visit: https://github.com/chenxingqiang/repofm
</additional_info>

</file_summary>

<repository_structure>
resources/
  .repofmignore
  data.txt
src/
  index.js
  utils.js
.repofmignore
package.json
README.md
repofm.config.json
</repository_structure>

<repository_files>
This section contains the contents of the repository's files.

<file path="resources/.repofmignore">
ignored-data.txt
</file>

<file path="resources/data.txt">
dummy data
</file>

<file path="src/index.js">
const { greet } = require('./utils');

function main() {
  console.log(greet('World'));
}

main();
</file>

<file path="src/utils.js">
function greet(name) {
  return `Hello, ${name}!`;
}

module.exports = {
  greet,
};
</file>

<file path=".repofmignore">
**/build/**
</file>

<file path="package.json">
{
  "name": "simple-project",
  "version": "1.0.0",
  "description": "A simple project for testing repofm",
  "main": "src/index.js",
  "scripts": {
    "start": "node src/index.js"
  },
  "keywords": ["simple", "test"],
  "author": "Test Author",
  "license": "MIT"
}
</file>

<file path="README.md">
# Simple Project

This is a simple project used for testing repofm.

## Usage

To run the project:

```
npm start
```

This will output a greeting message to the console.
</file>

<file path="repofm.config.json">
{
  "output": {
    "filePath": "repofm-output.txt",
    "headerText": "This repository is simple-project",
    "removeComments": false,
    "removeEmptyLines": false,
    "topFilesLength": 5,
    "showLineNumbers": false
  },
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  }
}
</file>

</repository_files>

================
File: tests/integration-tests/packager.test.ts
================
import fs from 'node:fs/promises';
import os from 'node:os';
import path from 'node:path';
import process from 'node:process';
import { afterEach, beforeEach, describe, expect, test } from 'vitest';
import { loadFileConfig, mergeConfigs } from '../../src/config/configLoad.js';
import type { repofmConfigFile, repofmConfigMerged, repofmOutputStyle } from '../../src/config/configSchema.js';
import { pack } from '../../src/core/packager.js';
import { isWindows } from '../testing/testUtils.js';




const fixturesDir = path.join(__dirname, 'fixtures', 'packager');
const inputsDir = path.join(fixturesDir, 'inputs');
const outputsDir = path.join(fixturesDir, 'outputs');

describe.runIf(!isWindows)('packager integration', () => {
  const testCases = [
    { desc: 'simple plain style', input: 'simple-project', output: 'simple-project-output.txt', config: {} },
    {
      desc: 'simple xml style',
      input: 'simple-project',
      output: 'simple-project-output.xml',
      config: { output: { style: 'xml', filePath: 'simple-project-output.xml' } },
    },
  ];

  let tempDir: string;

  beforeEach(async () => {
    // Create a temporary directory for each test
    tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'repofm-test-'));
  });

  afterEach(async () => {
    // Clean up the temporary directory after each test
    await fs.rm(tempDir, { recursive: true, force: true });
  });

  for (const { desc, input, output, config } of testCases) {
    test(`should correctly pack ${desc}`, async () => {
      const inputDir = path.join(inputsDir, input);
      const expectedOutputPath = path.join(outputsDir, output);
      const actualOutputPath = path.join(tempDir, output);

      const fileConfig: repofmConfigFile = await loadFileConfig(inputDir, null);
      const mergedConfig: repofmConfigMerged = mergeConfigs(process.cwd(), fileConfig, {
        output: {
          filePath: actualOutputPath,
          style: (config.output?.style || 'plain') as repofmOutputStyle,
        },
      });

      // Run the pack function
      await pack(inputDir, mergedConfig);

      // Read the actual and expected outputs
      let actualOutput = await fs.readFile(actualOutputPath, 'utf-8');
      let expectedOutput = await fs.readFile(expectedOutputPath, 'utf-8');

      actualOutput = actualOutput.replace(/^Generated by repofm on:.*\n/gm, '');
      expectedOutput = expectedOutput.replace(/^Generated by repofm on:.*\n/gm, '');

      // Compare the outputs
      expect(actualOutput).toBe(expectedOutput);

      // Optionally, update the expected output if explicitly requested
      if (process.env.UPDATE_EXPECTED_OUTPUT) {
        await fs.writeFile(expectedOutputPath, actualOutput);
        console.log(`Updated expected output for ${desc}`);
      }
    });
  }
});


// tests/integration-tests/packager.test.ts


describe('packager integration', () => {
  let tempDir: string;
  let fixturesDir: string;
  let inputsDir: string;
  let outputsDir: string;

  beforeEach(async () => {
    // 设置测试目录
    fixturesDir = path.join(__dirname, 'fixtures', 'packager');
    inputsDir = path.join(fixturesDir, 'inputs');
    outputsDir = path.join(fixturesDir, 'outputs');
    // 创建临时目录
    tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'repofm-test-'));
  });

  afterEach(async () => {
    // 清理临时目录
    await fs.rm(tempDir, { recursive: true, force: true });
  });

  describe('Basic Project Packing', () => {
    test('should pack simple project with default settings', async () => {
      // 复制简单项目到临时目录
      await copyDirectory(
        path.join(inputsDir, 'simple-project'),
        tempDir
      );

      // 加载配置
      const fileConfig: repofmConfigFile = await loadFileConfig(tempDir, null);
      const config: repofmConfigMerged = mergeConfigs(process.cwd(), fileConfig, {
        output: {
          filePath: path.join(tempDir, 'repofm-output.txt'),
          style: 'plain',
        },
      });

      // 执行打包
      await pack(tempDir, config);

      // 验证输出文件
      const output = await fs.readFile(path.join(tempDir, 'repofm-output.txt'), 'utf-8');
      const expected = await fs.readFile(
        path.join(outputsDir, 'simple-project-output.txt'),
        'utf-8'
      );

      // 清除时间戳等动态内容进行比较
      expect(normalizeOutput(output)).toBe(normalizeOutput(expected));
    });

    test('should pack simple project as XML', async () => {
      await copyDirectory(
        path.join(inputsDir, 'simple-project'),
        tempDir
      );

      const fileConfig: repofmConfigFile = await loadFileConfig(tempDir, null);
      const config: repofmConfigMerged = mergeConfigs(process.cwd(), fileConfig, {
        output: {
          filePath: path.join(tempDir, 'repofm-output.xml'),
          style: 'xml',
        },
      });

      await pack(tempDir, config);

      const output = await fs.readFile(path.join(tempDir, 'repofm-output.xml'), 'utf-8');
      const expected = await fs.readFile(
        path.join(outputsDir, 'simple-project-output.xml'),
        'utf-8'
      );

      expect(normalizeOutput(output)).toBe(normalizeOutput(expected));
    });

    test('should handle files with different encodings', async () => {
      // 创建测试文件
      await fs.writeFile(
        path.join(tempDir, 'utf8.txt'),
        'UTF-8 content'
      );
      await fs.writeFile(
        path.join(tempDir, 'gbk.txt'),
        Buffer.from('GBK content', 'utf8')  // 模拟GBK编码
      );

      const config = mergeConfigs(process.cwd(), {}, {});
      await pack(tempDir, config);

      const output = await fs.readFile(path.join(tempDir, config.output.filePath), 'utf-8');
      expect(output).toContain('UTF-8 content');
      expect(output).toContain('GBK content');
    });
  });

  describe('File Filtering', () => {
    test('should respect .gitignore patterns', async () => {
      // 创建测试项目结构
      await fs.mkdir(path.join(tempDir, 'src'), { recursive: true });
      await fs.writeFile(path.join(tempDir, 'src/index.js'), 'console.log("Hello");');
      await fs.writeFile(path.join(tempDir, '.gitignore'), 'node_modules/\n*.log');
      await fs.mkdir(path.join(tempDir, 'node_modules'), { recursive: true });
      await fs.writeFile(path.join(tempDir, 'node_modules/package.json'), '{}');
      await fs.writeFile(path.join(tempDir, 'app.log'), 'log content');

      const config = mergeConfigs(process.cwd(), {}, {});
      await pack(tempDir, config);

      const output = await fs.readFile(path.join(tempDir, config.output.filePath), 'utf-8');
      expect(output).toContain('src/index.js');
      expect(output).not.toContain('node_modules/package.json');
      expect(output).not.toContain('app.log');
    });

    test('should respect .repofmignore patterns', async () => {
      await fs.writeFile(path.join(tempDir, '.repofmignore'), 'ignored/\n*.test.js');
      await fs.mkdir(path.join(tempDir, 'ignored'), { recursive: true });
      await fs.writeFile(path.join(tempDir, 'ignored/file.js'), 'ignored content');
      await fs.writeFile(path.join(tempDir, 'app.test.js'), 'test content');
      await fs.writeFile(path.join(tempDir, 'app.js'), 'main content');

      const config = mergeConfigs(process.cwd(), {}, {});
      await pack(tempDir, config);

      const output = await fs.readFile(path.join(tempDir, config.output.filePath), 'utf-8');
      expect(output).toContain('app.js');
      expect(output).not.toContain('ignored/file.js');
      expect(output).not.toContain('app.test.js');
    });
  });

  describe('Security Checks', () => {
    test('should detect and exclude sensitive files', async () => {
      await fs.writeFile(
        path.join(tempDir, '.env'),
        'API_KEY=secret123\nDB_PASSWORD=password123'
      );
      await fs.writeFile(
        path.join(tempDir, 'config.js'),
        'export const apiKey = "secret456";'
      );

      const config = mergeConfigs(process.cwd(), {}, {
        security: {
          enableSecurityCheck: true,
        },
      });

      const { suspiciousFilesResults } = await pack(tempDir, config);

      expect(suspiciousFilesResults).toHaveLength(2);
      expect(suspiciousFilesResults[0].filePath).toContain('.env');
      expect(suspiciousFilesResults[1].filePath).toContain('config.js');
    });

    test('should respect security check disable option', async () => {
      await fs.writeFile(
        path.join(tempDir, '.env'),
        'API_KEY=secret123'
      );

      const config = mergeConfigs(process.cwd(), {}, {
        security: {
          enableSecurityCheck: false,
        },
      });

      const { suspiciousFilesResults } = await pack(tempDir, config);
      expect(suspiciousFilesResults).toHaveLength(0);
    });
  });

  describe('Large Projects', () => {
    test('should handle projects with many files', async () => {
      // 创建大量文件
      for (let i = 0; i < 1000; i++) {
        await fs.mkdir(path.join(tempDir, `dir${i}`), { recursive: true });
        await fs.writeFile(
          path.join(tempDir, `dir${i}`, `file${i}.js`),
          `console.log(${i});`
        );
      }

      const config = mergeConfigs(process.cwd(), {}, {});
      const { totalFiles } = await pack(tempDir, config);

      expect(totalFiles).toBe(1000);
    });

    test('should handle files with large content', async () => {
      const largeContent = 'x'.repeat(1024 * 1024); // 1MB content
      await fs.writeFile(path.join(tempDir, 'large.txt'), largeContent);

      const config = mergeConfigs(process.cwd(), {}, {});
      await pack(tempDir, config);

      const output = await fs.readFile(path.join(tempDir, config.output.filePath), 'utf-8');
      expect(output).toContain('large.txt');
      expect(output.length).toBeGreaterThan(1024 * 1024);
    });
  });

  describe('Custom Instructions', () => {
    test('should include custom instructions in output', async () => {
      await fs.writeFile(
        path.join(tempDir, 'instructions.md'),
        '# Custom Instructions\nFollow these steps...'
      );

      const config = mergeConfigs(process.cwd(), {}, {
        output: {
          instructionFilePath: 'instructions.md',
        },
      });

      await pack(tempDir, config);

      const output = await fs.readFile(path.join(tempDir, config.output.filePath), 'utf-8');
      expect(output).toContain('Custom Instructions');
      expect(output).toContain('Follow these steps');
    });
  });

  describe('Error Handling', () => {
    test('should handle permission errors gracefully', async () => {
      // 创建只读目录
      const readOnlyDir = path.join(tempDir, 'readonly');
      await fs.mkdir(readOnlyDir, { recursive: true });
      await fs.chmod(readOnlyDir, 0o444);

      const config = mergeConfigs(process.cwd(), {}, {});
      await expect(pack(readOnlyDir, config)).rejects.toThrow();
    });

    test('should handle invalid file paths', async () => {
      const config = mergeConfigs(process.cwd(), {}, {});
      await expect(pack('/nonexistent/dir', config)).rejects.toThrow();
    });
  });
});

// 辅助函数

async function copyDirectory(src: string, dest: string): Promise<void> {
  await fs.mkdir(dest, { recursive: true });
  const entries = await fs.readdir(src, { withFileTypes: true });

  for (const entry of entries) {
    const srcPath = path.join(src, entry.name);
    const destPath = path.join(dest, entry.name);

    if (entry.isDirectory()) {
      await copyDirectory(srcPath, destPath);
    } else {
      await fs.copyFile(srcPath, destPath);
    }
  }
}

function normalizeOutput(output: string): string {
  return output
    .replace(/Generated by repofm on: .*\n/g, '')
    .replace(/\r\n/g, '\n')
    .trim();
}

================
File: tests/shared/errorHandle.test.ts
================
// tests/shared/errorHandle.test.ts

import { z } from 'zod';
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { handleError, repofmConfigValidationError, repofmError, rethrowValidationErrorIfZodError } from '../../src/shared/errorHandle';
import { logger } from '../../src/shared/logger';

vi.mock('../../src/shared/logger');

describe('errorHandle', () => {
    beforeEach(() => {
        vi.resetAllMocks();
    });

    afterEach(() => {
        vi.clearAllMocks();
    });

    describe('handleError', () => {
        it('should handle repofmError correctly', () => {
            const error = new repofmError('Custom repofm error');
            handleError(error);
            expect(logger.error).toHaveBeenCalledWith('Error: Custom repofm error');
        });

        it('should handle general Error', () => {
            const error = new Error('General error');
            handleError(error);
            expect(logger.error).toHaveBeenCalledWith('Unexpected error: General error');
            expect(logger.debug).toHaveBeenCalledWith('Stack trace:', error.stack);
        });

        it('should handle unknown error types', () => {
            const error = 'String error';
            handleError(error);
            expect(logger.error).toHaveBeenCalledWith('An unknown error occurred');
        });

        it('should handle error with no message', () => {
            const error = new Error();
            handleError(error);
            expect(logger.error).toHaveBeenCalledWith('Unexpected error: ');
        });

        it('should handle undefined error', () => {
            handleError(undefined);
            expect(logger.error).toHaveBeenCalledWith('An unknown error occurred');
        });

        it('should handle null error', () => {
            handleError(null);
            expect(logger.error).toHaveBeenCalledWith('An unknown error occurred');
        });

        it('should handle error with custom properties', () => {
            const error = new Error('Custom error');
            (error as any).code = 'CUSTOM_CODE';
            (error as any).details = { foo: 'bar' };

            handleError(error);
            expect(logger.error).toHaveBeenCalledWith('Unexpected error: Custom error');
            expect(logger.debug).toHaveBeenCalledWith('Stack trace:', expect.any(String));
        });
    });

    describe('rethrowValidationErrorIfZodError', () => {
        it('should rethrow Zod error with custom message', () => {
            const zodError = new z.ZodError([
                {
                    code: z.ZodIssueCode.invalid_type,
                    expected: 'string',
                    received: 'number',
                    path: ['field'],
                    message: 'Expected string, received number'
                }
            ]);

            expect(() =>
                rethrowValidationErrorIfZodError(zodError, 'Configuration error')
            ).toThrow(repofmConfigValidationError);
        });

        it('should format multiple Zod errors correctly', () => {
            const zodError = new z.ZodError([
                {
                    code: z.ZodIssueCode.invalid_type,
                    expected: 'string',
                    received: 'number',
                    path: ['field1'],
                    message: 'Error 1'
                },
                {
                    code: z.ZodIssueCode.invalid_type,
                    expected: 'boolean',
                    received: 'string',
                    path: ['field2'],
                    message: 'Error 2'
                }
            ]);

            try {
                rethrowValidationErrorIfZodError(zodError, 'Multiple errors');
            } catch (error) {
                expect(error).toBeInstanceOf(repofmConfigValidationError);
                expect(error.message).toContain('Error 1');
                expect(error.message).toContain('Error 2');
            }
        });

        it('should handle nested path in Zod errors', () => {
            const zodError = new z.ZodError([
                {
                    code: z.ZodIssueCode.invalid_type,
                    expected: 'string',
                    received: 'number',
                    path: ['parent', 'child', 'field'],
                    message: 'Invalid field'
                }
            ]);

            try {
                rethrowValidationErrorIfZodError(zodError, 'Nested error');
            } catch (error) {
                expect(error.message).toContain('parent.child.field');
            }
        });

        it('should not rethrow non-Zod errors', () => {
            const error = new Error('Regular error');
            rethrowValidationErrorIfZodError(error, 'Test message');
            expect(logger.error).not.toHaveBeenCalled();
        });
    });

    describe('repofmError', () => {
        it('should create custom error with correct name', () => {
            const error = new repofmError('Custom message');
            expect(error.name).toBe('repofmError');
            expect(error.message).toBe('Custom message');
        });

        it('should support error inheritance', () => {
            const error = new repofmError('Test');
            expect(error).toBeInstanceOf(Error);
        });

        it('should maintain stack trace', () => {
            const error = new repofmError('Test');
            expect(error.stack).toBeDefined();
        });
    });

    describe('repofmConfigValidationError', () => {
        it('should create validation error with correct name', () => {
            const error = new repofmConfigValidationError('Validation failed');
            expect(error.name).toBe('repofmConfigValidationError');
            expect(error.message).toBe('Validation failed');
        });

        it('should inherit from repofmError', () => {
            const error = new repofmConfigValidationError('Test');
            expect(error).toBeInstanceOf(repofmError);
        });
    });

    describe('Error Integration', () => {
        it('should handle configuration validation errors properly', () => {
            const schema = z.object({
                field: z.string(),
            });

            try {
                const result = schema.parse({ field: 123 });
            } catch (error) {
                rethrowValidationErrorIfZodError(error, 'Config validation');
            }

            expect(logger.error).not.toHaveBeenCalled();
        });

        it('should provide helpful error messages', () => {
            const schema = z.object({
                output: z.object({
                    style: z.enum(['plain', 'xml', 'markdown']),
                }),
            });

            try {
                schema.parse({ output: { style: 'invalid' } });
            } catch (error) {
                try {
                    rethrowValidationErrorIfZodError(error, 'Style validation');
                } catch (validationError) {
                    expect(validationError.message).toContain('Style validation');
                    expect(validationError.message).toContain('output.style');
                }
            }
        });

        it('should handle errors in async context', async () => {
            const asyncOperation = async () => {
                throw new repofmError('Async error');
            };

            try {
                await asyncOperation();
            } catch (error) {
                handleError(error);
            }

            expect(logger.error).toHaveBeenCalledWith('Error: Async error');
        });

        it('should handle errors with circular references', () => {
            const circularObj: any = { foo: 'bar' };
            circularObj.self = circularObj;
            const error = new Error('Circular error');
            error.custom = circularObj;

            handleError(error);
            expect(logger.error).toHaveBeenCalledWith('Unexpected error: Circular error');
        });
    });

    describe('Error Context', () => {
        it('should include application version in error context', () => {
            const appVersion = '1.0.0';
            process.env.npm_package_version = appVersion;
            handleError(new Error('Test error'));
            expect(logger.info).toHaveBeenCalledWith(
                expect.stringContaining('https://github.com/chenxingqiang/repofm/issues')
            );
        });

        it('should handle missing application version', () => {
            delete process.env.npm_package_version;
            handleError(new Error('Test error'));
            expect(logger.error).toHaveBeenCalled();
        });
    });

    describe('Error Recovery', () => {
        it('should suggest recovery actions for common errors', () => {
            const errorCases = [
                {
                    error: new Error('ENOENT: no such file or directory'),
                    contains: 'file or directory'
                },
                {
                    error: new Error('EACCES: permission denied'),
                    contains: 'permission denied'
                },
                {
                    error: new Error('ETIMEDOUT: operation timed out'),
                    contains: 'timed out'
                }
            ];

            errorCases.forEach(({ error, contains }) => {
                handleError(error);
                expect(logger.error).toHaveBeenCalledWith(
                    expect.stringContaining(contains)
                );
            });
        });

        it('should handle chain of errors', () => {
            const originalError = new Error('Original error');
            const wrappedError = new repofmError(`Wrapped: ${originalError.message}`);

            handleError(wrappedError);
            expect(logger.error).toHaveBeenCalledWith(
                expect.stringContaining('Original error')
            );
        });
    });
});

================
File: tests/shared/logger.test.ts
================
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { logger } from '../../src/shared/logger.js';

vi.mock('picocolors', () => ({
  default: {
    red: vi.fn((str) => `RED:${str}`),
    yellow: vi.fn((str) => `YELLOW:${str}`),
    green: vi.fn((str) => `GREEN:${str}`),
    cyan: vi.fn((str) => `CYAN:${str}`),
    dim: vi.fn((str) => `DIM:${str}`),
    blue: vi.fn((str) => `BLUE:${str}`),
    gray: vi.fn((str) => `GRAY:${str}`),
  },
}));

describe('logger', () => {
  beforeEach(() => {
    vi.spyOn(console, 'error').mockImplementation(vi.fn());
    vi.spyOn(console, 'log').mockImplementation(vi.fn());
    logger.setVerbose(false);
  });

  afterEach(() => {
    vi.restoreAllMocks();
  });

  it('should log error messages', () => {
    logger.error('Error message');
    expect(console.error).toHaveBeenCalledWith('RED:Error message');
  });

  it('should log warning messages', () => {
    logger.warn('Warning message');
    expect(console.log).toHaveBeenCalledWith('YELLOW:Warning message');
  });

  it('should log success messages', () => {
    logger.success('Success message');
    expect(console.log).toHaveBeenCalledWith('GREEN:Success message');
  });

  it('should log info messages', () => {
    logger.info('Info message');
    expect(console.log).toHaveBeenCalledWith('CYAN:Info message');
  });

  it('should log note messages', () => {
    logger.note('Note message');
    expect(console.log).toHaveBeenCalledWith('DIM:Note message');
  });

  it('should log log messages', () => {
    logger.log('Note message');
    expect(console.log).toHaveBeenCalledWith('Note message');
  });

  it('should not log debug messages when verbose is false', () => {
    logger.debug('Debug message');
    expect(console.log).not.toHaveBeenCalled();
  });

  it('should log debug messages when verbose is true', () => {
    logger.setVerbose(true);
    logger.debug('Debug message');
    expect(console.log).toHaveBeenCalledWith('BLUE:Debug message');
  });

  it('should not log trace messages when verbose is false', () => {
    logger.trace('Trace message');
    expect(console.log).not.toHaveBeenCalled();
  });

  it('should log trace messages when verbose is true', () => {
    logger.setVerbose(true);
    logger.trace('Trace message');
    expect(console.log).toHaveBeenCalledWith('GRAY:Trace message');
  });

  it('should format object arguments correctly', () => {
    const obj = { key: 'value' };
    logger.info('Object:', obj);
    expect(console.log).toHaveBeenCalledWith(expect.stringContaining('CYAN:Object: '));
  });

  it('should handle multiple arguments', () => {
    logger.info('Multiple', 'arguments', 123);
    expect(console.log).toHaveBeenCalledWith('CYAN:Multiple arguments 123');
  });
});

================
File: tests/testing/testUtils.ts
================
import os from 'node:os';
import process from 'node:process';
import { type repofmConfigMerged, defaultConfig } from '../../src/config/configSchema.js';

type DeepPartial<T> = {
  [P in keyof T]?: T[P] extends (infer U)[]
    ? DeepPartial<U>[]
    : T[P] extends readonly (infer U)[]
      ? readonly DeepPartial<U>[]
      : T[P] extends object
        ? DeepPartial<T[P]>
        : T[P];
};

export const createMockConfig = (config: DeepPartial<repofmConfigMerged> = {}): repofmConfigMerged => {
  return {
    cwd: process.cwd(),
    output: {
      ...defaultConfig.output,
      ...config.output,
    },
    ignore: {
      ...defaultConfig.ignore,
      ...config.ignore,
      customPatterns: [...(defaultConfig.ignore.customPatterns || []), ...(config.ignore?.customPatterns || [])],
    },
    include: [...(defaultConfig.include || []), ...(config.include || [])],
    security: {
      ...defaultConfig.security,
      ...config.security,
    },
  };
};

export const isWindows = os.platform() === 'win32';
export const isMac = os.platform() === 'darwin';
export const isLinux = os.platform() === 'linux';

================
File: .codecov.yml
================
coverage:
  status:
    patch:
      default:
        target: 80%
        informational: true
    project:
      default:
        target: 75%
        threshold: 1%

================
File: .editorconfig
================
root = true

[*.*]
indent_style = space
indent_size = 2
charset = utf-8
trim_trailing_whitespace = true
insert_final_newline = true
end_of_line = lf
max_line_length = null

[*.md]
trim_trailing_whitespace = false

================
File: .env.example
================
# GitHub configuration
GITHUB_TOKEN=your_github_token_here

# Supabase configuration
SUPABASE_URL=your_supabase_url_here
SUPABASE_KEY=your_supabase_key_here

================
File: .gitignore
================
# Dependency directories
node_modules/

# Build output
lib/

# Logs
*.log

# OS generated files
.DS_Store

# Editor directories and files
.vscode/
.idea/

# Test coverage
coverage/

# Temporary files
*.tmp
*.temp

# repofm output
repofm-output.txt
repofm-output.xml
repofm-output.md

# ESLint cache
.eslintcache

# yarn
.yarn/

# biome
.biome/

# Environment variables
.env
.env.local
.env.*.local

# Node
node_modules/

# Cache
.repofm/
*.cache

# Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Editor directories and files
.idea/
.vscode/
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

================
File: .node-version
================
23.1.0

================
File: .npmignore
================
# Source files
src/

# Test files
tests/
coverage/

# Configuration files
tsconfig.json
tsconfig.build.json
.eslintrc.js
eslint.config.mjs
prettier.config.mjs
vite.config.mts
biome.json

# Git files
.gitignore
.git

# CI files
.github/

# yarn files
.yarn

# ESLint files
.eslintcache

# Config files
.editorconfig
.node-version
.tool-versions
repofm.config.js

# Editor files
.vscode/
.idea/

# Logs
*.log

# repofm output
repofm-output.txt

# Development scripts
scripts/

# Documentation files (except README and LICENSE)
docs/
CONTRIBUTING.md
CHANGELOG.md

# Temporary files
*.tmp
*.temp

# OS generated files
.DS_Store
Thumbs.db

# biome
.biome/

================
File: .repofmignore
================
node_modules
.yarn
.eslinttcache
tests/integration-tests/fixtures

================
File: .secretlintrc.json
================
{
  "rules": [
    {
      "id": "@secretlint/secretlint-rule-preset-recommend"
    }
  ]
}

================
File: .tool-versions
================
nodejs 23.1.0

================
File: biome.json
================
{
  "$schema": "https://biomejs.dev/schemas/1.8.3/schema.json",
  "files": {
    "include": [
      "./src/**",
      "./tests/**",
      "package.json",
      "biome.json",
      ".secretlintrc.json",
      "tsconfig.json",
      "tsconfig.build.json",
      "vite.config.ts",
      "repofm.config.json"
    ]
  },
  "organizeImports": {
    "enabled": true
  },
  "linter": {
    "enabled": true,
    "rules": {
      "recommended": true
    }
  },
  "formatter": {
    "enabled": true,
    "formatWithErrors": false,
    "indentStyle": "space",
    "indentWidth": 2,
    "lineWidth": 120
  },
  "javascript": {
    "formatter": {
      "quoteStyle": "single",
      "trailingCommas": "all",
      "semicolons": "always"
    }
  }
}

================
File: CODE_OF_CONDUCT.md
================
# repofm Contributor Covenant Code of Conduct

## Our Pledge

In the interest of fostering an open and welcoming environment, we, as contributors and maintainers, pledge to make participation in our project and community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.

## Our Standards

Examples of behavior that contribute to creating a positive environment include:

* Using welcoming and inclusive language
* Being respectful of differing viewpoints and experiences
* Gracefully accepting constructive criticism
* Focusing on what is best for the community
* Showing empathy towards other community members

Examples of unacceptable behavior by participants include:

* The use of sexualized language or imagery and unwelcome sexual attention or advances
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as physical or electronic addresses, without explicit permission
* Other conduct that could reasonably be considered inappropriate in a professional setting

## Our Responsibilities

Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.

Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that do not align with this Code of Conduct or to ban temporarily or permanently any contributor for behaviors that they deem inappropriate, threatening, offensive, or harmful.

## Scope

This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project email address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at [chen.xingqiang@iechor.com](mailto:chen.xingqiang@iechor.com). All complaints will be reviewed and investigated, resulting in a response deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality concerning the reporter of an incident. Further details of specific enforcement policies may be posted separately.

Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at [https://www.contributor-covenant.org/version/1/4/code-of-conduct.html](https://www.contributor-covenant.org/version/1/4/code-of-conduct.html).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this Code of Conduct, see [https://www.contributor-covenant.org/faq](https://www.contributor-covenant.org/faq).

================
File: CONTRIBUTING.md
================
# Contribution Guide

Thanks for your interest in **repofm**! 🚀 We’d love your help to make it even better. Here’s how you can get involved:

- **Create an Issue**: Spot a bug? Have an idea for a new feature? Let us know by creating an issue.
- **Submit a Pull Request**: Found something to fix or improve? Jump in and submit a PR!
- **Spread the Word**: Share your experience with repofm on social media, blogs, or with your tech community.
- **Use repofm**: The best feedback comes from real-world usage, so feel free to integrate repofm into your own projects!

## Maintainers

repofm is maintained by Yamadashy ([@chenxingqiang](https://github.com/chenxingqiang)). While all contributions are welcome, please understand that not every suggestion may be accepted if they don't align with the project's goals or coding standards.

---

## Pull Requests

Before submitting a Pull Request, please ensure:

1. Your code passes all tests: Run `npm run test`
2. Your code adheres to our linting standards: Run `npm run lint`
3. You have updated relevant documentation (especially README.md) if you've added or changed functionality.

## Local Development

To set up repofm for local development:

```bash
git clone https://github.com/chenxingqiang/repofm.git
cd repofm
npm install
```

To run repofm locally:

```bash
npm run cli-run
```

### Coding Style

We use [Biome](https://biomejs.dev/) for linting and formatting. Please make sure your code follows the style guide by running:

```bash
npm run lint
```

### Testing

We use [Vitest](https://vitest.dev/) for testing. To run the tests:

```bash
npm run test
```

For test coverage:

```bash
npm run test-coverage
```

### Documentation

When adding new features or making changes, please update the relevant documentation in the README.md file.

## Releasing

New versions are managed by the maintainer. If you think a release is needed, open an issue to discuss it

Thank you for contributing to repofm!

================
File: LICENSE
================
Copyright 2024 Chen Xingqiang

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

================
File: package.json
================
{
  "name": "repofm",
  "version": "0.1.0",
  "description": "A tool to pack repository contents to single file for AI consumption",
  "main": "./lib/index.js",
  "types": "./lib/index.d.ts",
  "exports": {
    ".": {
      "types": "./lib/index.d.ts"
    }
  },
  "bin": "./bin/repofm.cjs",
  "scripts": {
    "clean": "rimraf lib",
    "build": "npm run clean && tsc -p tsconfig.build.json --sourceMap --declaration",
    "lint": "npm run lint-biome && npm run lint-ts && npm run lint-secretlint",
    "lint-biome": "biome check --write",
    "lint-ts": "tsc --noEmit",
    "lint-secretlint": "secretlint \"**/*\" --secretlintignore .gitignore",
    "test": "vitest",
    "test-coverage": "vitest run --coverage",
    "cli-run": "npm run build && node --trace-warnings bin/repofm",
    "npm-publish": "npm run lint && npm run test-coverage && npm run build && npm publish",
    "npm-release-patch": "npm version patch && npm run npm-publish",
    "npm-release-minor": "npm version minor && npm run npm-publish",
    "npm-release-prerelease": "npm version prerelease && npm run npm-publish"
  },
  "keywords": [
    "repository",
    "generative-ai",
    "ai",
    "llm",
    "source-code",
    "code-analysis",
    "codebase-packer",
    "development-tool",
    "ai-assistant",
    "code-review"
  ],
  "repository": {
    "type": "git",
    "url": "git://github.com/chenxingqiang/repofm.git"
  },
  "bugs": {
    "url": "https://github.com/chenxingqiang/repofm/issues"
  },
  "author": "Chen Xingqiang chen.xingqinag@iechor.com",
  "homepage": "https://github.com/chenxingqiang/repofm",
  "license": "MIT",
  "publishConfig": {
    "access": "public"
  },
  "type": "module",
  "dependencies": {
    "@clack/prompts": "^0.7.0",
    "@secretlint/core": "^9.0.0",
    "@secretlint/secretlint-rule-preset-recommend": "^9.0.0",
    "cli-spinners": "^2.9.2",
    "clipboardy": "^4.0.0",
    "commander": "^12.1.0",
    "dotenv": "^16.4.5",
    "globby": "^14.0.2",
    "handlebars": "^4.7.8",
    "iconv-lite": "^0.6.3",
    "istextorbinary": "^9.5.0",
    "jschardet": "^3.1.4",
    "log-update": "^6.1.0",
    "p-map": "^7.0.2",
    "picocolors": "^1.1.1",
    "strip-comments": "^2.0.1",
    "tiktoken": "^1.0.17",
    "zod": "^3.23.8"
  },
  "devDependencies": {
    "@biomejs/biome": "^1.9.4",
    "@secretlint/types": "^9.0.0",
    "@types/node": "^22.9.0",
    "@types/strip-comments": "^2.0.4",
    "@vitest/coverage-v8": "^2.1.4",
    "minimatch": "^10.0.1",
    "rimraf": "^6.0.1",
    "secretlint": "^9.0.0",
    "typescript": "^5.6.3",
    "vitest": "^2.1.4"
  },
  "engines": {
    "node": ">=16.0.0",
    "yarn": ">=1.22.22"
  }
}

================
File: README.md
================
# 📦 repofm

[![Actions Status](https://github.com/chenxingqiang/repofm/actions/workflows/ci.yml/badge.svg)](https://github.com/chenxingqiang/repofm/actions?query=workflow%3A"ci")
[![npm](https://img.shields.io/npm/v/repofm.svg?maxAge=1000)](https://www.npmjs.com/package/repofm)
[![npm](https://img.shields.io/npm/d18m/repofm)](https://www.npmjs.com/package/repofm)
[![npm](https://img.shields.io/npm/l/repofm.svg?maxAge=1000)](https://github.com/chenxingqiang/repofm/blob/main/LICENSE)
[![node](https://img.shields.io/node/v/repofm.svg?maxAge=1000)](https://www.npmjs.com/package/repofm)

repofm is a powerful tool that packs your entire repository into a single, AI-friendly file.
It is perfect for when you need to feed your codebase to Large Language Models (LLMs) or other AI tools like Claude, ChatGPT, and Gemini.

## 📢 Important Notice: Project Renamed to repofm

> [!NOTE]
> Due to legal considerations, this project has been renamed from "Repofm" to "repofm". Only the name is changing; repofm all functionality and maintainer ([@chenxingqiang](https://github.com/chenxingqiang)) remain the same.
> We are committed to ensuring a smooth transition for all users.

### Migration Guide

To continue using the tool, simply install the new package:

```bash
# Install new package
npm install -g repofm

# Or use directly with npx
npx repofm
```

Optionally, you can also uninstall the old package:

```bash
npm uninstall -g repofm
```

#### Configuration Files

Your existing configuration files (`repofm.config.json` and `.repofmignore`) will continue to work during the transition period.
`repofm` will automatically detect these files and offer to migrate them to the new format (`repofm.config.json` and `.repofmignore`).

#### Timeline

- Current: Transition period begins
- December 1st, 2024: Ownership of the [repofm npm package](https://npmjs.com/repofm) will be transferred to another party. The repofm package will continue to be maintained as usual

We appreciate your understanding and cooperation during this transition.

## 🌟 Features

- **AI-Optimized**: Formats your codebase in a way that's easy for AI to understand and process.
- **Token Counting**: Provides token counts for each file and the entire repository, useful for LLM context limits.
- **Simple to Use**: You need just one command to pack your entire repository.
- **Customizable**: Easily configure what to include or exclude.
- **Git-Aware**: Automatically respects your .gitignore files.
- **Security-Focused**: Incorporates [Secretlint](https://github.com/secretlint/secretlint) for robust security checks to detect and prevent inclusion of sensitive information.

## 🚀 Quick Start

You can try repofm instantly in your project directory without installation:

```bash
npx repofm
```

Or install globally for repeated use:

```bash
# Install using npm
npm install -g repofm

# Alternatively using yarn
yarn global add repofm

# Alternatively using Homebrew (macOS)
brew install repofm

# Then run in any project directory
repofm
```

That's it! repofm will generate a `repofm-output.txt` file in your current directory, containing your entire repository in an AI-friendly format.

## 📊 Usage

To pack your entire repository:

```bash
repofm
```

To pack a specific directory:

```bash
repofm path/to/directory
```

To pack specific files or directories using [glob patterns](https://github.com/mrmlnc/fast-glob?tab=readme-ov-file#pattern-syntax):

```bash
repofm --include "src/**/*.ts,**/*.md"
```

To exclude specific files or directories:

```bash
repofm --ignore "**/*.log,tmp/"
```

To pack a remote repository:

```bash
repofm --remote https://github.com/chenxingqiang/repofm

# You can also use GitHub shorthand:
repofm --remote chenxingqiang/repofm
```

To initialize a new configuration file (`repofm.config.json`):

```bash
repofm --init
```

Once you have generated the packed file, you can use it with Generative AI tools like Claude, ChatGPT, and Gemini.

### Prompt Examples

Once you have generated the packed file with repofm, you can use it with AI tools like Claude, ChatGPT, and Gemini. Here are some example prompts to get you started:

#### Code Review and Refactoring

For a comprehensive code review and refactoring suggestions:

```
This file contains my entire codebase. Please review the overall structure and suggest any improvements or refactoring opportunities, focusing on maintainability and scalability.
```

#### Documentation Generation

To generate project documentation:

```
Based on the codebase in this file, please generate a detailed README.md that includes an overview of the project, its main features, setup instructions, and usage examples.
```

#### Test Case Generation

For generating test cases:

```
Analyze the code in this file and suggest a comprehensive set of unit tests for the main functions and classes. Include edge cases and potential error scenarios.
```

#### Code Quality Assessment

Evaluate code quality and adherence to best practices:

```
Review the codebase for adherence to coding best practices and industry standards. Identify areas where the code could be improved in terms of readability, maintainability, and efficiency. Suggest specific changes to align the code with best practices.
```

#### Library Overview

Get a high-level understanding of the library

```
This file contains the entire codebase of library. Please provide a comprehensive overview of the library, including its main purpose, key features, and overall architecture.
```

Feel free to modify these prompts based on your specific needs and the capabilities of the AI tool you're using.

### Community Discussion

Check out our [community discussion](https://github.com/chenxingqiang/repofm/discussions/154) where users share:

- Which AI tools they're using with repofm
- Effective prompts they've discovered
- How repofm has helped them
- Tips and tricks for getting the most out of AI code analysis

Feel free to join the discussion and share your own experiences! Your insights could help others make better use of repofm.

### Output File Format

repofm generates a single file with clear separators between different parts of your codebase.
To enhance AI comprehension, the output file begins with an AI-oriented explanation, making it easier for AI models to understand the context and structure of the packed repository.

#### Plain Text Format (default)

```text
This file is a merged representation of the entire codebase, combining all repository files into a single document.

================================================================
File Summary
================================================================
(Metadata and usage AI instructions)

================================================================
Repository Structure
================================================================
src/
  cli/
    cliOutput.ts
    index.ts
  config/
    configLoader.ts

(...remaining directories)

================================================================
Repository Files
================================================================

================
File: src/index.js
================
// File contents here

================
File: src/utils.js
================
// File contents here

(...remaining files)

================================================================
Instruction
================================================================
(Custom instructions from `output.instructionFilePath`)
```

#### XML Format

To generate output in XML format, use the `--style xml` option:

```bash
repofm --style xml
```

The XML format structures the content in a hierarchical manner:

```xml
This file is a merged representation of the entire codebase, combining all repository files into a single document.

<file_summary>
(Metadata and usage AI instructions)
</file_summary>

<repository_structure>
src/
  cli/
    cliOutput.ts
    index.ts

(...remaining directories)
</repository_structure>

<repository_files>
<file path="src/index.js">
// File contents here
</file>

(...remaining files)
</repository_files>

<instruction>
(Custom instructions from `output.instructionFilePath`)
</instruction>
```

For those interested in the potential of XML tags in AI contexts:
<https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags>

> When your prompts involve multiple components like context, instructions, and examples, XML tags can be a game-changer. They help Claude parse your prompts more accurately, leading to higher-quality outputs.

This means that the XML output from repofm is not just a different format, but potentially a more effective way to feed your codebase into AI systems for analysis, code review, or other tasks.

#### Markdown Format

To generate output in Markdown format, use the `--style markdown` option:

```bash
repofm --style markdown
```

The Markdown format structures the content in a hierarchical manner:

````markdown
This file is a merged representation of the entire codebase, combining all repository files into a single document.

# File Summary
(Metadata and usage AI instructions)

# Repository Structure
```
src/
  cli/
    cliOutput.ts
    index.ts
```
(...remaining directories)

# Repository Files

## File: src/index.js
```
// File contents here
```

(...remaining files)

# Instruction
(Custom instructions from `output.instructionFilePath`)
````

This format provides a clean, readable structure that is both human-friendly and easily parseable by AI systems.

### Command Line Options

- `-v, --version`: Show tool version
- `-o, --output <file>`: Specify the output file name
- `--include <patterns>`: List of include patterns (comma-separated)
- `-i, --ignore <patterns>`: Additional ignore patterns (comma-separated)
- `-c, --config <path>`: Path to a custom config file
- `--style <style>`: Specify the output style (`plain`, `xml`, `markdown`)
- `--top-files-len <number>`: Number of top files to display in the summary
- `--output-show-line-numbers`: Show line numbers in the output
- `--copy`: Additionally copy generated output to system clipboard
- `--remote <url>`: Process a remote Git repository
- `--verbose`: Enable verbose logging

Examples:

```bash
repofm -o custom-output.txt
repofm -i "*.log,tmp" -v
repofm -c ./custom-config.json
repofm --style xml
repofm --remote https://github.com/user/repo.git
npx repofm src
```

### Updating repofm

To update a globally installed repofm:

```bash
# Using npm
npm update -g repofm

# Using yarn
yarn global upgrade repofm
```

Using `npx repofm` is generally more convenient as it always uses the latest version.

### Remote Repository Processing

repofm supports processing remote Git repositories without the need for manual cloning. This feature allows you to quickly analyze any public Git repository with a single command.

To process a remote repository, use the `--remote` option followed by the repository URL:

```bash
repofm --remote https://github.com/user/repo.git
```

You can also use GitHub's shorthand format:

```bash
repofm --remote user/repo
```

## ⚙️ Configuration

Create a `repofm.config.json` file in your project root for custom configurations.

```bash
repofm --init
```

Here's an explanation of the configuration options:

| Option | Description | Default |
|--------|-------------|---------|
|`output.filePath`| The name of the output file | `"repofm-output.txt"` |
|`output.style`| The style of the output (`plain`, `xml`, `markdown`) |`"plain"`|
|`output.headerText`| Custom text to include in the file header |`null`|
|`output.instructionFilePath`| Path to a file containing detailed custom instructions |`null`|
|`output.removeComments`| Whether to remove comments from supported file types | `false` |
|`output.removeEmptyLines`| Whether to remove empty lines from the output | `false` |
|`output.showLineNumbers`| Whether to add line numbers to each line in the output |`false`|
|`output.copyToClipboard`| Whether to copy the output to system clipboard in addition to saving the file |`false`|
|`output.topFilesLength`| Number of top files to display in the summary. If set to 0, no summary will be displayed |`5`|
|`include`| Patterns of files to include (using [glob patterns](https://github.com/mrmlnc/fast-glob?tab=readme-ov-file#pattern-syntax)) |`[]`|
|`ignore.useGitignore`| Whether to use patterns from the project's `.gitignore` file |`true`|
|`ignore.useDefaultPatterns`| Whether to use default ignore patterns |`true`|
|`ignore.customPatterns`| Additional patterns to ignore (using [glob patterns](https://github.com/mrmlnc/fast-glob?tab=readme-ov-file#pattern-syntax)) |`[]`|
|`security.enableSecurityCheck`| Whether to perform security checks on files |`true`|

Example configuration:

```json
{
  "output": {
    "filePath": "repofm-output.xml",
    "style": "xml",
    "headerText": "Custom header information for the packed file.",
    "removeComments": false,
    "removeEmptyLines": false,
    "showLineNumbers": false,
    "copyToClipboard": true,
    "topFilesLength": 5
  },
  "include": ["**/*"],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": ["additional-folder", "**/*.log"]
  },
  "security": {
    "enableSecurityCheck": true
  }
}
```

### Global Configuration

To create a global configuration file:

```bash
repofm --init --global
```

The global configuration file will be created in:

- Windows: `%LOCALAPPDATA%\repofm\repofm.config.json`
- macOS/Linux: `$XDG_CONFIG_HOME/repofm/repofm.config.json` or `~/.config/repofm/repofm.config.json`

Note: Local configuration (if present) takes precedence over global configuration.

### Include and Ignore

#### Include Patterns

repofm now supports specifying files to include using [glob patterns](https://github.com/mrmlnc/fast-glob?tab=readme-ov-file#pattern-syntax). This allows for more flexible and powerful file selection:

- Use `**/*.js` to include all JavaScript files in any directory
- Use `src/**/*` to include all files within the `src` directory and its subdirectories
- Combine multiple patterns like `["src/**/*.js", "**/*.md"]` to include JavaScript files in `src` and all Markdown files

#### Ignore Patterns

repofm offers multiple methods to set ignore patterns for excluding specific files or directories during the packing process:

- **.gitignore**: By default, patterns listed in your project's `.gitignore` file are used. This behavior can be controlled with the `ignore.useGitignore` setting.
- **Default patterns**: repofm includes a default list of commonly excluded files and directories (e.g., node_modules, .git, binary files). This feature can be controlled with the `ignore.useDefaultPatterns` setting. Please see [defaultIgnore.ts](src/config/defaultIgnore.ts) for more details.
- **.repofmignore**: You can create a `.repofmignore` file in your project root to define repofm-specific ignore patterns. This file follows the same format as `.gitignore`.
- **Custom patterns**: Additional ignore patterns can be specified using the `ignore.customPatterns` option in the configuration file. You can overwrite this setting with the `-i, --ignore` command line option.

Priority Order (from highest to lowest):

1. Custom patterns `ignore.customPatterns`
2. `.repofmignore`
3. `.gitignore` (if `ignore.useGitignore` is true)
4. Default patterns (if `ignore.useDefaultPatterns` is true)

This approach allows for flexible file exclusion configuration based on your project's needs. It helps optimize the size of the generated pack file by ensuring the exclusion of security-sensitive files and large binary files, while preventing the leakage of confidential information.

Note: Binary files are not included in the packed output by default, but their paths are listed in the "Repository Structure" section of the output file. This provides a complete overview of the repository structure while keeping the packed file efficient and text-based.

### Custom Instruction

The `output.instructionFilePath` option allows you to specify a separate file containing detailed instructions or context about your project. This allows AI systems to understand the specific context and requirements of your project, potentially leading to more relevant and tailored analysis or suggestions.

Here's an example of how you might use this feature:

1. Create a file named `repofm-instruction.md` in your project root:

```markdown
# Coding Guidelines
- Follow the Airbnb JavaScript Style Guide
- Suggest splitting files into smaller, focused units when appropriate
- Add comments for non-obvious logic. Keep all text in English
- All new features should have corresponding unit tests

# Generate Comprehensive Output
- Include all content without abbreviation, unless specified otherwise
- Optimize for handling large codebases while maintaining output quality
```

2. In your `repofm.config.json`, add the `instructionFilePath` option:

```json5
{
  "output": {
    "instructionFilePath": "repofm-instruction.md",
    // other options...
  }
}
```

When repofm generates the output, it will include the contents of `repofm-instruction.md` in a dedicated section.

Note: The instruction content is appended at the end of the output file. This placement can be particularly effective for AI systems. For those interested in understanding why this might be beneficial, Anthropic provides some insights in their documentation:
<https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips>

> Put long-form data at the top: Place your long documents and inputs (~20K+ tokens) near the top of your prompt, above your query, instructions, and examples. This can significantly improve Claude's performance across all models.
> Queries at the end can improve response quality by up to 30% in tests, especially with complex, multi-document inputs.

### Comment Removal

When `output.removeComments` is set to `true`, repofm will attempt to remove comments from supported file types. This feature can help reduce the size of the output file and focus on the essential code content.

Supported languages include:
HTML, CSS, JavaScript, TypeScript, Vue, Svelte, Python, PHP, Ruby, C, C#, Java, Go, Rust, Swift, Kotlin, Dart, Shell, and YAML.

Note: The comment removal process is conservative to avoid accidentally removing code. In complex cases, some comments might be retained.

## 🔍 Security Check

repofm includes a security check feature that uses [Secretlint](https://github.com/secretlint/secretlint) to detect potentially sensitive information in your files. This feature helps you identify possible security risks before sharing your packed repository.

The security check results will be displayed in the CLI output after the packing process is complete. If any suspicious files are detected, you'll see a list of these files along with a warning message.

Example output:

```
🔍 Security Check:
──────────────────
2 suspicious file(s) detected:
1. src/utils/test.txt
2. tests/utils/secretLintUtils.test.ts

Please review these files for potentially sensitive information.
```

By default, repofm's security check feature is enabled. You can disable it by setting `security.enableSecurityCheck` to `false` in your configuration file:

```json
{
  "security": {
    "enableSecurityCheck": false
  }
}
```

## 🤝 Contribution

We welcome contributions from the community! To get started, please refer to our [Contributing Guide](CONTRIBUTING.md).

### Contributors

<a href="https://github.com/chenxingqiang/repofm/graphs/contributors">
  <img alt="contributors" src="https://contrib.rocks/image?repo=chenxingqiang/repofm"/>
</a>

## 📜 License

This project is licensed under the [MIT License](LICENSE).

<p align="center">
  &nbsp;&nbsp;&nbsp;
  <a href="#-repofm" target="_blank">
    Back To Top
  </a>

</p>

## Setup

1. Copy `.env.example` to `.env.local`
2. Fill in your environment variables:
   - `GITHUB_TOKEN`: Your GitHub Personal Access Token
   - `SUPABASE_URL`: Your Supabase URL
   - `SUPABASE_KEY`: Your Supabase Key

================
File: repofm.config.json
================
{
  "output": {
    "filePath": "repofm-output.xml",
    "style": "xml",
    "headerText": "This repository contains the source code for the repofm tool.\nrepofm is designed to pack repository contents into a single file,\nmaking it easier for AI systems to analyze and process the codebase.\n\nKey Features:\n- Configurable ignore patterns\n- Custom header text support\n- Efficient file processing and packing\n\nPlease refer to the README.md file for more detailed information on usage and configuration.\n",
    "instructionFilePath": "repofm-instruction.md",
    "removeComments": false,
    "removeEmptyLines": false,
    "topFilesLength": 5,
    "showLineNumbers": false
  },
  "include": [],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  },
  "security": {
    "enableSecurityCheck": true
  },
  "github": {
    "token": ""
  },
  "supabase": {
    "url": "",
    "key": ""
  },
  "context": {
    "outputFormat": "markdown",
    "maxDepth": 2,
    "includeImports": true,
    "includeExports": true,
    "maxContextLines": 100,
    "excludePatterns": ["node_modules", ".git"],
    "cacheEnabled": true,
    "cachePath": ".repofm/context-cache"
  },
  "autoCommit": {
    "ui": {
      "showTimeline": true,
      "showDiff": true,
      "colorOutput": true,
      "icons": true,
      "useEmoji": true
    },
    "commit": {
      "separateByDefault": true,
      "pushByDefault": true,
      "requireConfirmation": true,
      "breakingChangePrompt": true,
      "conventionalCommits": true
    },
    "analysis": {
      "checkBreakingChanges": true,
      "suggestScope": true,
      "detectFileTypes": true,
      "scanForKeywords": true,
      "maxDiffLines": 500
    },
    "templates": {
      "feature": {
        "add": "feat({}): add {} functionality",
        "update": "feat({}): update {} implementation"
      }
    },
    "fileTypes": {
      "react": {
        "pattern": "\\.jsx?$",
        "folders": ["components", "pages"],
        "keywords": ["React", "useState"]
      }
    },
    "customPatterns": {
      "jira": "([A-Z]+-\\d+)",
      "version": "(v\\d+\\.\\d+\\.\\d+)"
    }
  }
}

================
File: SECURITY.md
================
# Security Policy

## Reporting a Vulnerability

To securely report a vulnerability, please [open an advisory on GitHub](https://github.com/chenxingqiang/repofm/security/advisories/new) or report it by sending an email to `chen.xingqiang@iechor.com`.

================
File: tsconfig.build.json
================
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "rootDir": "./src"
  },
  "include": ["./src/**/*"]
}

================
File: tsconfig.json
================
{
  "compileOnSave": false,
  "compilerOptions": {
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "target": "es2016",
    "outDir": "./lib",
    "rootDir": ".",
    "strict": true,
    "esModuleInterop": true,
    "noImplicitAny": true,
    "skipLibCheck": true,
    "lib": ["es2022"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "types": ["node", "picocolors"]
  },
  "include": ["src/**/*", "tests/**/*"],
  "exclude": ["tests/integration-tests/fixtures"]
}

================
File: vitest.config.ts
================
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    include: ['tests/**/*.test.ts'],
    coverage: {
      include: ['src/**/*'],
      reporter: ['text', 'json', 'html'],
    },
  },
});
